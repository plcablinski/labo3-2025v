{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1dd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d03193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar de df_full las filas donde la columna A_PREDECIR sea 'N'\n",
    "df_full = df_full[df_full['A_PREDECIR'] != 'N']\n",
    "df_full = df_full.drop(columns=['A_PREDECIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba02f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservar las siguientes columnas\n",
    "columns_to_keep = ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1',\n",
    "       'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID',\n",
    "       'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY',\n",
    "       'CUST_REQUEST_TN', 'TN', 'CLASE', 'CLASE_DELTA',\n",
    "       'ORDINAL', 'ANTIG_CLIENTE',\n",
    "       'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER']\n",
    "# Filtrar el DataFrame para conservar solo las columnas deseadas \n",
    "df_full = df_full[columns_to_keep]\n",
    "df_full['DIAS_EN_MES'] = pd.to_datetime(df_full['PERIODO'], format='%Y%m').dt.days_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9d63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ordenar correctamente\n",
    "df_full = df_full.sort_values(by=['PRODUCT_ID', 'CUSTOMER_ID', 'ORDINAL'], ascending=True)\n",
    "\n",
    "# 2. Crear los LAGs y DELTAs\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "\n",
    "    df_full[lag_col] = df_full.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])['TN'].shift(lag)\n",
    "    df_full[delta_col] = df_full['TN'] - df_full[lag_col]\n",
    "\n",
    "# 3. Crear las variaciones porcentuales SIN fragmentar\n",
    "delta_pct_cols = {}\n",
    "\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "    delta_pct_col = f'TN_DELTA_{lag:02d}_PORC'\n",
    "\n",
    "    delta_pct_cols[delta_pct_col] = np.where(\n",
    "        df_full[lag_col] == 0,\n",
    "        np.nan,\n",
    "        df_full[delta_col] / df_full[lag_col]\n",
    "    )\n",
    "\n",
    "# 4. Concatenar todas las columnas nuevas en un solo paso\n",
    "df_porcentajes = pd.DataFrame(delta_pct_cols, index=df_full.index)\n",
    "df_full = pd.concat([df_full, df_porcentajes], axis=1)\n",
    "\n",
    "# 5. (Opcional) Defragmentar para mejorar rendimiento\n",
    "df_full = df_full.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un DataFrame de Polars\n",
    "df_full = pl.from_pandas(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bf055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtrar columnas relevantes\n",
    "columnas_a_normalizar = [\n",
    "    col for col in df_full.columns\n",
    "    if ('TN' in col or 'DELTA' in col or 'CLASE' in col or 'LAG' in col)\n",
    "    and 'PORC' not in col\n",
    "]\n",
    "\n",
    "# 2. Inicializar DataFrame con combinaciones únicas\n",
    "medias_y_desvios = df_full.select(['PRODUCT_ID', 'CUSTOMER_ID']).unique()\n",
    "\n",
    "# 3. Calcular medias y desvíos por columna\n",
    "resultados = []\n",
    "for col in columnas_a_normalizar:\n",
    "    if col in df_full.columns:\n",
    "        resumen = (\n",
    "            df_full\n",
    "            .select(['PRODUCT_ID', 'CUSTOMER_ID', col])\n",
    "            .group_by(['PRODUCT_ID', 'CUSTOMER_ID'])\n",
    "            .agg([\n",
    "                pl.col(col).mean().alias(f'{col}_MEDIA'),\n",
    "                pl.col(col).std().alias(f'{col}_DESVIO')\n",
    "            ])\n",
    "        )\n",
    "        resultados.append(resumen)\n",
    "\n",
    "# 4. Combinar todos los resultados\n",
    "medias_y_desvios = reduce(\n",
    "    lambda df1, df2: df1.join(df2, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left'), \n",
    "    resultados\n",
    ")\n",
    "# Convertir los nulos en ceros\n",
    "medias_y_desvios = medias_y_desvios.fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23988a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las columnas de medias y desvíos\n",
    "print(medias_y_desvios.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_zscore_con_join(\n",
    "    df_full: pl.DataFrame,\n",
    "    medias_y_desvios: pl.DataFrame,\n",
    "    columnas_a_normalizar: List[str],\n",
    "    conservar_auxiliares: bool = False,\n",
    "    epsilon: float = 1e-6,\n",
    "    clip_value: float = 5.0,\n",
    "    agregar_clip: bool = False\n",
    ") -> pl.DataFrame:\n",
    "    # 1. Armar columnas necesarias\n",
    "    columnas_media = [f'{col}_MEDIA' for col in columnas_a_normalizar if f'{col}_MEDIA' in medias_y_desvios.columns]\n",
    "    columnas_desvio = [f'{col}_DESVIO' for col in columnas_a_normalizar if f'{col}_DESVIO' in medias_y_desvios.columns]\n",
    "    columnas_join = ['PRODUCT_ID', 'CUSTOMER_ID'] + columnas_media + columnas_desvio\n",
    "\n",
    "    # 2. Join\n",
    "    df_aux = medias_y_desvios.select(columnas_join)\n",
    "    df_full = df_full.join(df_aux, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left')\n",
    "\n",
    "    # 3. Calcular ZSCOREs\n",
    "    zscore_exprs = []\n",
    "    for col in columnas_a_normalizar:\n",
    "        media_col = f\"{col}_MEDIA\"\n",
    "        desvio_col = f\"{col}_DESVIO\"\n",
    "        z_col = f\"{col}_ZSCORE\"\n",
    "        if media_col in df_full.columns and desvio_col in df_full.columns:\n",
    "            expr = (\n",
    "                (pl.col(col) - pl.col(media_col)) /\n",
    "                (pl.col(desvio_col) + epsilon)\n",
    "            ).alias(z_col)\n",
    "            zscore_exprs.append(expr)\n",
    "            print(f\"✅ Normalizando: {col} -> {z_col}\")\n",
    "\n",
    "    df_full = df_full.with_columns(zscore_exprs)\n",
    "\n",
    "    # 4. Clipping (después de que los zscores existen)\n",
    "    if agregar_clip:\n",
    "        clip_exprs = [\n",
    "            pl.col(f\"{col}_ZSCORE\").clip(-clip_value, clip_value).alias(f\"{col}_ZSCORE_CLIP\")\n",
    "            for col in columnas_a_normalizar\n",
    "            if f\"{col}_ZSCORE\" in df_full.columns\n",
    "        ]\n",
    "        df_full = df_full.with_columns(clip_exprs)\n",
    "\n",
    "    # 5. Eliminar auxiliares si no se quieren\n",
    "    if not conservar_auxiliares:\n",
    "        df_full = df_full.drop(columnas_media + columnas_desvio)\n",
    "\n",
    "    return df_full\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = normalizar_zscore_con_join(\n",
    "    df_full=df_full,\n",
    "    medias_y_desvios=medias_y_desvios,\n",
    "    columnas_a_normalizar=columnas_a_normalizar,\n",
    "    conservar_auxiliares=False,\n",
    "    epsilon=1e-6,\n",
    "    clip_value=5.0,\n",
    "    agregar_clip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas originales de df_full que fueron normalizadas\n",
    "# son las que están en columnas_a_normalizar\n",
    "df_full = df_full.drop(columnas_a_normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir de nuevo a DataFrame de Pandas\n",
    "df_full = df_full.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cálculo de features por grupo ---\n",
    "def calcular_pendientes_grupo(group, periodos_list):\n",
    "    group = group.sort_values(by='PERIODO').copy()\n",
    "    n = len(group)\n",
    "    y_series = pd.Series(group['TN_ZSCORE'].values)\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for cant in periodos_list:\n",
    "        x = np.arange(cant)\n",
    "        rolling = y_series.rolling(window=cant, min_periods=1)\n",
    "\n",
    "        # Medidas estadísticas\n",
    "        mean_vals = rolling.mean().values\n",
    "        std_vals = rolling.std().values\n",
    "        median_vals = rolling.median().values\n",
    "        min_vals = rolling.min().values\n",
    "        max_vals = rolling.max().values\n",
    "        ewma_vals = y_series.ewm(span=cant, adjust=False).mean().values\n",
    "\n",
    "        new_cols[f'TN_MEAN_ZSCORE_{cant}'] = mean_vals\n",
    "        new_cols[f'TN_STD_ZSCORE_{cant}'] = std_vals\n",
    "        new_cols[f'TN_MEDIAN_ZSCORE_{str(cant).zfill(2)}'] = median_vals\n",
    "        new_cols[f'TN_MIN_ZSCORE_{str(cant).zfill(2)}'] = min_vals\n",
    "        new_cols[f'TN_MAX_ZSCORE_{str(cant).zfill(2)}'] = max_vals\n",
    "        new_cols[f'TN_EWMA_ZSCORE_{str(cant).zfill(2)}'] = ewma_vals\n",
    "\n",
    "        # Pendiente de regresión lineal\n",
    "        if n >= cant:\n",
    "            y_rolling = np.lib.stride_tricks.sliding_window_view(y_series.values, window_shape=cant)\n",
    "            X = np.vstack([x, np.ones(cant)]).T\n",
    "            XTX_inv_XT = np.linalg.pinv(X)\n",
    "            betas = XTX_inv_XT @ y_rolling.T\n",
    "            pendientes = np.full(n, np.nan)\n",
    "            pendientes[cant - 1:] = betas[0]\n",
    "        else:\n",
    "            pendientes = np.full(n, np.nan)\n",
    "        new_cols[f'PENDIENTE_TENDENCIA_ZSCORE_{cant}'] = pendientes\n",
    "\n",
    "        # Medidas de variabilidad respecto a la media\n",
    "        abs_diff = np.abs(y_series.values - mean_vals)\n",
    "        cv_vals = std_vals / np.where(mean_vals == 0, np.nan, mean_vals)\n",
    "\n",
    "        new_cols[f'TN_ABS_DIFF_MEAN_ZSCORE_{cant}'] = abs_diff\n",
    "        new_cols[f'TN_CV_ZSCORE_{cant}'] = cv_vals\n",
    "\n",
    "    df_features = pd.DataFrame(new_cols, index=group.index)\n",
    "    group = pd.concat([group, df_features], axis=1)\n",
    "    return group\n",
    "\n",
    "# --- Procesar un chunk de grupos ---\n",
    "def procesar_chunk(chunk, periodos_list):\n",
    "    return pd.concat([calcular_pendientes_grupo(g, periodos_list) for g in chunk], ignore_index=True)\n",
    "\n",
    "# --- Paralelización eficiente ---\n",
    "def calcular_pendientes_parallel_optimizado(df, periodos_list, n_jobs=28, chunk_size=100):\n",
    "    df = df.copy()  # conserva todas las columnas originales\n",
    "    grupos = [group for _, group in df.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])]\n",
    "    chunks = list(chunked(grupos, chunk_size))\n",
    "\n",
    "    resultados = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
    "        delayed(procesar_chunk)(chunk, periodos_list) for chunk in chunks\n",
    "    )\n",
    "\n",
    "    df_final = pd.concat(resultados, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "# --- Script principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    df_full = calcular_pendientes_parallel_optimizado(\n",
    "        df_full,\n",
    "        periodos_list=[2, 3, 6, 9, 12, 13, 15, 18],\n",
    "        n_jobs=28,\n",
    "        chunk_size=200\n",
    "    )\n",
    "\n",
    "    print(f\"Tiempo total: {time.time() - start:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adf11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral: proporción máxima permitida (ej. 0.4 = 40%)\n",
    "umbral_faltantes = 0.8\n",
    "\n",
    "# Diccionario para almacenar estadísticas\n",
    "estadisticas_columnas = []\n",
    "\n",
    "# Recorremos las columnas del DataFrame\n",
    "for col in df_full.columns:\n",
    "    total = len(df_full[col])\n",
    "    nulls = df_full[col].isnull().sum()\n",
    "    nans = df_full[col].isna().sum()\n",
    "    infs = np.isinf(df_full[col]).sum()\n",
    "    \n",
    "    total_faltantes = nulls + infs  # NaN está incluido en nulls/isna\n",
    "    \n",
    "    porcentaje = total_faltantes / total\n",
    "    \n",
    "    estadisticas_columnas.append({\n",
    "        'columna': col,\n",
    "        'nulls': nulls,\n",
    "        'NaNs': nans,\n",
    "        'infs': infs,\n",
    "        'porcentaje_faltantes': porcentaje\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_faltantes = pd.DataFrame(estadisticas_columnas)\n",
    "\n",
    "# Filtrar columnas que superen el umbral\n",
    "columnas_a_eliminar = df_faltantes[df_faltantes['porcentaje_faltantes'] > umbral_faltantes]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(f\"\\nSe eliminarán {len(columnas_a_eliminar)} columnas con más del {umbral_faltantes*100:.0f}% de valores faltantes o infinitos:\")\n",
    "for _, row in columnas_a_eliminar.iterrows():\n",
    "    print(f\"- {row['columna']}: {row['porcentaje_faltantes']*100:.2f}% (nulls={row['nulls']}, infs={row['infs']})\")\n",
    "\n",
    "# Eliminar columnas del DataFrame\n",
    "df_full = df_full.drop(columns=columnas_a_eliminar['columna'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_resultado una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_full['MES_PROBLEMATICO'] = df_full['PERIODO'].apply(lambda x: True if x in [201906, 201908] else False)\n",
    "df_full['PLAN_PRECIOS_CUIDADOS'] = df_full['PLAN_PRECIOS_CUIDADOS'].map({1 : True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame resultante en un archivo parquet\n",
    "df_full.to_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet', index=False)\n",
    "medias_y_desvios_pd = medias_y_desvios.to_pandas()\n",
    "medias_y_desvios_pd.to_parquet('./data/medias_y_desvios.parquet', engine='fastparquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
