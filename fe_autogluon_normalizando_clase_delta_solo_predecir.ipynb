{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n",
    "from functools import reduce\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1dd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d03193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar de df_full las filas donde la columna A_PREDECIR sea 'N'\n",
    "df_full = df_full[df_full['A_PREDECIR'] != 'N']\n",
    "df_full = df_full.drop(columns=['A_PREDECIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba02f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservar las siguientes columnas\n",
    "columns_to_keep = ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1',\n",
    "       'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID',\n",
    "       'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY',\n",
    "       'CUST_REQUEST_TN', 'TN', 'CLASE', 'CLASE_DELTA',\n",
    "       'ORDINAL', 'ANTIG_CLIENTE',\n",
    "       'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER']\n",
    "# Filtrar el DataFrame para conservar solo las columnas deseadas \n",
    "df_full = df_full[columns_to_keep]\n",
    "df_full['DIAS_EN_MES'] = pd.to_datetime(df_full['PERIODO'], format='%Y%m').dt.days_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9d63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ordenar correctamente\n",
    "df_full = df_full.sort_values(by=['PRODUCT_ID', 'CUSTOMER_ID', 'ORDINAL'], ascending=True)\n",
    "\n",
    "# 2. Crear los LAGs y DELTAs\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "\n",
    "    df_full[lag_col] = df_full.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])['TN'].shift(lag)\n",
    "    df_full[delta_col] = df_full['TN'] - df_full[lag_col]\n",
    "\n",
    "# 3. Crear las variaciones porcentuales SIN fragmentar\n",
    "delta_pct_cols = {}\n",
    "\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "    delta_pct_col = f'TN_DELTA_{lag:02d}_PORC'\n",
    "\n",
    "    delta_pct_cols[delta_pct_col] = np.where(\n",
    "        df_full[lag_col] == 0,\n",
    "        np.nan,\n",
    "        df_full[delta_col] / df_full[lag_col]\n",
    "    )\n",
    "\n",
    "# 4. Concatenar todas las columnas nuevas en un solo paso\n",
    "df_porcentajes = pd.DataFrame(delta_pct_cols, index=df_full.index)\n",
    "df_full = pd.concat([df_full, df_porcentajes], axis=1)\n",
    "del df_porcentajes\n",
    "gc.collect()\n",
    "\n",
    "# 5. (Opcional) Defragmentar para mejorar rendimiento\n",
    "df_full = df_full.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un DataFrame de Polars\n",
    "df_full = pl.from_pandas(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987bf055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Filtrar columnas relevantes\n",
    "columnas_a_normalizar = [\n",
    "    col for col in df_full.columns\n",
    "    if ('TN' in col or 'DELTA' in col or 'CLASE' in col or 'LAG' in col)\n",
    "    and 'PORC' not in col\n",
    "]\n",
    "\n",
    "# 2. Inicializar DataFrame con combinaciones únicas\n",
    "medias_y_desvios = df_full.select(['PRODUCT_ID', 'CUSTOMER_ID']).unique()\n",
    "\n",
    "# 3. Calcular medias y desvíos por columna\n",
    "resultados = []\n",
    "for col in columnas_a_normalizar:\n",
    "    if col in df_full.columns:\n",
    "        resumen = (\n",
    "            df_full\n",
    "            .select(['PRODUCT_ID', 'CUSTOMER_ID', col])\n",
    "            .group_by(['PRODUCT_ID', 'CUSTOMER_ID'])\n",
    "            .agg([\n",
    "                pl.col(col).mean().alias(f'{col}_MEDIA'),\n",
    "                pl.col(col).std().alias(f'{col}_DESVIO')\n",
    "            ])\n",
    "        )\n",
    "        resultados.append(resumen)\n",
    "\n",
    "# 4. Combinar todos los resultados\n",
    "medias_y_desvios = reduce(\n",
    "    lambda df1, df2: df1.join(df2, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left'), \n",
    "    resultados\n",
    ")\n",
    "# Convertir los nulos en ceros\n",
    "medias_y_desvios = medias_y_desvios.fill_null(0)\n",
    "\n",
    "del resumen, resultados\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_zscore_con_join(\n",
    "    df_full: pl.DataFrame,\n",
    "    medias_y_desvios: pl.DataFrame,\n",
    "    columnas_a_normalizar: List[str],\n",
    "    conservar_auxiliares: bool = False,\n",
    "    epsilon: float = 1e-6,\n",
    "    clip_value: float = 5.0,\n",
    "    agregar_clip: bool = False\n",
    ") -> pl.DataFrame:\n",
    "    # 1. Armar columnas necesarias\n",
    "    columnas_media = [f'{col}_MEDIA' for col in columnas_a_normalizar if f'{col}_MEDIA' in medias_y_desvios.columns]\n",
    "    columnas_desvio = [f'{col}_DESVIO' for col in columnas_a_normalizar if f'{col}_DESVIO' in medias_y_desvios.columns]\n",
    "    columnas_join = ['PRODUCT_ID', 'CUSTOMER_ID'] + columnas_media + columnas_desvio\n",
    "\n",
    "    # 2. Join\n",
    "    df_aux = medias_y_desvios.select(columnas_join)\n",
    "    df_full = df_full.join(df_aux, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left')\n",
    "\n",
    "    # 3. Calcular ZSCOREs\n",
    "    zscore_exprs = []\n",
    "    for col in columnas_a_normalizar:\n",
    "        media_col = f\"{col}_MEDIA\"\n",
    "        desvio_col = f\"{col}_DESVIO\"\n",
    "        z_col = f\"{col}_ZSCORE\"\n",
    "        if media_col in df_full.columns and desvio_col in df_full.columns:\n",
    "            expr = (\n",
    "                (pl.col(col) - pl.col(media_col)) /\n",
    "                (pl.col(desvio_col) + epsilon)\n",
    "            ).alias(z_col)\n",
    "            zscore_exprs.append(expr)\n",
    "            print(f\"✅ Normalizando: {col} -> {z_col}\")\n",
    "\n",
    "    df_full = df_full.with_columns(zscore_exprs)\n",
    "\n",
    "    # 4. Clipping (después de que los zscores existen)\n",
    "    if agregar_clip:\n",
    "        clip_exprs = [\n",
    "            pl.col(f\"{col}_ZSCORE\").clip(-clip_value, clip_value).alias(f\"{col}_ZSCORE_CLIP\")\n",
    "            for col in columnas_a_normalizar\n",
    "            if f\"{col}_ZSCORE\" in df_full.columns\n",
    "        ]\n",
    "        df_full = df_full.with_columns(clip_exprs)\n",
    "\n",
    "    # 5. Eliminar auxiliares si no se quieren\n",
    "    if not conservar_auxiliares:\n",
    "        df_full = df_full.drop(columnas_media + columnas_desvio)\n",
    "\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb0c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalizando: CUST_REQUEST_TN -> CUST_REQUEST_TN_ZSCORE\n",
      "✅ Normalizando: TN -> TN_ZSCORE\n",
      "✅ Normalizando: CLASE -> CLASE_ZSCORE\n",
      "✅ Normalizando: CLASE_DELTA -> CLASE_DELTA_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01 -> TN_LAG_01_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01 -> TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02 -> TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02 -> TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03 -> TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03 -> TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_04 -> TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_04 -> TN_DELTA_04_ZSCORE\n",
      "✅ Normalizando: TN_LAG_05 -> TN_LAG_05_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_05 -> TN_DELTA_05_ZSCORE\n",
      "✅ Normalizando: TN_LAG_06 -> TN_LAG_06_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_06 -> TN_DELTA_06_ZSCORE\n",
      "✅ Normalizando: TN_LAG_07 -> TN_LAG_07_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_07 -> TN_DELTA_07_ZSCORE\n",
      "✅ Normalizando: TN_LAG_08 -> TN_LAG_08_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_08 -> TN_DELTA_08_ZSCORE\n",
      "✅ Normalizando: TN_LAG_09 -> TN_LAG_09_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_09 -> TN_DELTA_09_ZSCORE\n",
      "✅ Normalizando: TN_LAG_10 -> TN_LAG_10_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_10 -> TN_DELTA_10_ZSCORE\n",
      "✅ Normalizando: TN_LAG_11 -> TN_LAG_11_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_11 -> TN_DELTA_11_ZSCORE\n",
      "✅ Normalizando: TN_LAG_12 -> TN_LAG_12_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_12 -> TN_DELTA_12_ZSCORE\n",
      "✅ Normalizando: TN_LAG_13 -> TN_LAG_13_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_13 -> TN_DELTA_13_ZSCORE\n",
      "✅ Normalizando: TN_LAG_14 -> TN_LAG_14_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_14 -> TN_DELTA_14_ZSCORE\n",
      "✅ Normalizando: TN_LAG_15 -> TN_LAG_15_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_15 -> TN_DELTA_15_ZSCORE\n",
      "✅ Normalizando: TN_LAG_16 -> TN_LAG_16_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_16 -> TN_DELTA_16_ZSCORE\n",
      "✅ Normalizando: TN_LAG_17 -> TN_LAG_17_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_17 -> TN_DELTA_17_ZSCORE\n",
      "✅ Normalizando: TN_LAG_18 -> TN_LAG_18_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_18 -> TN_DELTA_18_ZSCORE\n",
      "✅ Normalizando: TN_LAG_19 -> TN_LAG_19_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_19 -> TN_DELTA_19_ZSCORE\n",
      "✅ Normalizando: TN_LAG_20 -> TN_LAG_20_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_20 -> TN_DELTA_20_ZSCORE\n",
      "✅ Normalizando: TN_LAG_21 -> TN_LAG_21_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_21 -> TN_DELTA_21_ZSCORE\n",
      "✅ Normalizando: TN_LAG_22 -> TN_LAG_22_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_22 -> TN_DELTA_22_ZSCORE\n",
      "✅ Normalizando: TN_LAG_23 -> TN_LAG_23_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_23 -> TN_DELTA_23_ZSCORE\n",
      "✅ Normalizando: TN_LAG_24 -> TN_LAG_24_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_24 -> TN_DELTA_24_ZSCORE\n",
      "✅ Normalizando: TN_LAG_25 -> TN_LAG_25_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_25 -> TN_DELTA_25_ZSCORE\n",
      "✅ Normalizando: TN_LAG_26 -> TN_LAG_26_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_26 -> TN_DELTA_26_ZSCORE\n",
      "✅ Normalizando: TN_LAG_27 -> TN_LAG_27_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_27 -> TN_DELTA_27_ZSCORE\n",
      "✅ Normalizando: TN_LAG_28 -> TN_LAG_28_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_28 -> TN_DELTA_28_ZSCORE\n",
      "✅ Normalizando: TN_LAG_29 -> TN_LAG_29_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_29 -> TN_DELTA_29_ZSCORE\n",
      "✅ Normalizando: TN_LAG_30 -> TN_LAG_30_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_30 -> TN_DELTA_30_ZSCORE\n",
      "✅ Normalizando: TN_LAG_31 -> TN_LAG_31_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_31 -> TN_DELTA_31_ZSCORE\n",
      "✅ Normalizando: TN_LAG_32 -> TN_LAG_32_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_32 -> TN_DELTA_32_ZSCORE\n",
      "✅ Normalizando: TN_LAG_33 -> TN_LAG_33_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_33 -> TN_DELTA_33_ZSCORE\n",
      "✅ Normalizando: TN_LAG_34 -> TN_LAG_34_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_34 -> TN_DELTA_34_ZSCORE\n",
      "✅ Normalizando: TN_LAG_35 -> TN_LAG_35_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_35 -> TN_DELTA_35_ZSCORE\n"
     ]
    }
   ],
   "source": [
    "df_full = normalizar_zscore_con_join(\n",
    "    df_full=df_full,\n",
    "    medias_y_desvios=medias_y_desvios,\n",
    "    columnas_a_normalizar=columnas_a_normalizar,\n",
    "    conservar_auxiliares=False,\n",
    "    epsilon=1e-6,\n",
    "    clip_value=5.0,\n",
    "    agregar_clip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas originales de df_full que fueron normalizadas\n",
    "# son las que están en columnas_a_normalizar\n",
    "df_full = df_full.drop(columnas_a_normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03e51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir de nuevo a DataFrame de Pandas\n",
    "df_full = df_full.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a27aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=28)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done   5 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=28)]: Done  16 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=28)]: Done  29 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=28)]: Done  42 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=28)]: Done  57 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=28)]: Done  72 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=28)]: Done  89 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=28)]: Done 106 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=28)]: Done 125 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=28)]: Done 144 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=28)]: Done 165 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=28)]: Done 186 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=28)]: Done 209 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=28)]: Done 232 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=28)]: Done 257 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=28)]: Done 282 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=28)]: Done 309 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=28)]: Done 336 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=28)]: Done 365 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=28)]: Done 394 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=28)]: Done 425 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=28)]: Done 456 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=28)]: Done 489 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=28)]: Done 522 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=28)]: Done 557 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=28)]: Done 592 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=28)]: Done 629 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=28)]: Done 666 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=28)]: Done 705 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=28)]: Done 744 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=28)]: Done 785 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=28)]: Done 826 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=28)]: Done 869 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=28)]: Done 912 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=28)]: Done 957 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=28)]: Done 1002 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=28)]: Done 1049 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=28)]: Done 1096 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=28)]: Done 1145 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=28)]: Done 1194 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=28)]: Done 1245 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=28)]: Done 1296 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=28)]: Done 1349 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=28)]: Done 1402 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=28)]: Done 1457 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=28)]: Done 1512 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=28)]: Done 1569 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=28)]: Done 1626 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=28)]: Done 1685 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=28)]: Done 1744 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=28)]: Done 1805 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=28)]: Done 1866 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=28)]: Done 1929 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=28)]: Done 1992 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=28)]: Done 2057 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=28)]: Done 2122 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=28)]: Done 2189 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=28)]: Done 2256 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=28)]: Done 2329 out of 2329 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total: 206.82 segundos\n"
     ]
    }
   ],
   "source": [
    "# --- Cálculo de features por grupo ---\n",
    "def calcular_pendientes_grupo(group, periodos_list):\n",
    "    group = group.sort_values(by='PERIODO').copy()\n",
    "    n = len(group)\n",
    "    y_series = pd.Series(group['TN_ZSCORE'].values)\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for cant in periodos_list:\n",
    "        x = np.arange(cant)\n",
    "        rolling = y_series.rolling(window=cant, min_periods=1)\n",
    "\n",
    "        # Medidas estadísticas\n",
    "        mean_vals = rolling.mean().values\n",
    "        std_vals = rolling.std().values\n",
    "        median_vals = rolling.median().values\n",
    "        min_vals = rolling.min().values\n",
    "        max_vals = rolling.max().values\n",
    "        ewma_vals = y_series.ewm(span=cant, adjust=False).mean().values\n",
    "\n",
    "        new_cols[f'TN_MEAN_ZSCORE_{cant}'] = mean_vals\n",
    "        new_cols[f'TN_STD_ZSCORE_{cant}'] = std_vals\n",
    "        new_cols[f'TN_MEDIAN_ZSCORE_{str(cant).zfill(2)}'] = median_vals\n",
    "        new_cols[f'TN_MIN_ZSCORE_{str(cant).zfill(2)}'] = min_vals\n",
    "        new_cols[f'TN_MAX_ZSCORE_{str(cant).zfill(2)}'] = max_vals\n",
    "        new_cols[f'TN_EWMA_ZSCORE_{str(cant).zfill(2)}'] = ewma_vals\n",
    "\n",
    "        # Pendiente de regresión lineal\n",
    "        if n >= cant:\n",
    "            y_rolling = np.lib.stride_tricks.sliding_window_view(y_series.values, window_shape=cant)\n",
    "            X = np.vstack([x, np.ones(cant)]).T\n",
    "            XTX_inv_XT = np.linalg.pinv(X)\n",
    "            betas = XTX_inv_XT @ y_rolling.T\n",
    "            pendientes = np.full(n, np.nan)\n",
    "            pendientes[cant - 1:] = betas[0]\n",
    "        else:\n",
    "            pendientes = np.full(n, np.nan)\n",
    "        new_cols[f'PENDIENTE_TENDENCIA_ZSCORE_{cant}'] = pendientes\n",
    "\n",
    "        # Medidas de variabilidad respecto a la media\n",
    "        abs_diff = np.abs(y_series.values - mean_vals)\n",
    "        cv_vals = std_vals / np.where(mean_vals == 0, np.nan, mean_vals)\n",
    "\n",
    "        new_cols[f'TN_ABS_DIFF_MEAN_ZSCORE_{cant}'] = abs_diff\n",
    "        new_cols[f'TN_CV_ZSCORE_{cant}'] = cv_vals\n",
    "\n",
    "    df_features = pd.DataFrame(new_cols, index=group.index)\n",
    "    group = pd.concat([group, df_features], axis=1)\n",
    "    return group\n",
    "\n",
    "# --- Procesar un chunk de grupos ---\n",
    "def procesar_chunk(chunk, periodos_list):\n",
    "    return pd.concat([calcular_pendientes_grupo(g, periodos_list) for g in chunk], ignore_index=True)\n",
    "\n",
    "# --- Paralelización eficiente ---\n",
    "def calcular_pendientes_parallel_optimizado(df, periodos_list, n_jobs=28, chunk_size=100):\n",
    "    df = df.copy()  # conserva todas las columnas originales\n",
    "    grupos = [group for _, group in df.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])]\n",
    "    chunks = list(chunked(grupos, chunk_size))\n",
    "\n",
    "    resultados = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
    "        delayed(procesar_chunk)(chunk, periodos_list) for chunk in chunks\n",
    "    )\n",
    "\n",
    "    df_final = pd.concat(resultados, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "# --- Script principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    df_full = calcular_pendientes_parallel_optimizado(\n",
    "        df_full,\n",
    "        periodos_list=[2, 3, 6, 9, 12, 13, 15, 18],\n",
    "        n_jobs=28,\n",
    "        chunk_size=200\n",
    "    )\n",
    "\n",
    "    print(f\"Tiempo total: {time.time() - start:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57adf11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Se eliminarán 71 columnas con más del 80% de valores faltantes o infinitos:\n",
      "- TN_DELTA_01_PORC: 81.72% (nulls=10013581, infs=0)\n",
      "- TN_DELTA_02_PORC: 82.26% (nulls=10080189, infs=0)\n",
      "- TN_DELTA_03_PORC: 82.82% (nulls=10149012, infs=0)\n",
      "- TN_DELTA_04_PORC: 83.42% (nulls=10222439, infs=0)\n",
      "- TN_DELTA_05_PORC: 83.91% (nulls=10282725, infs=0)\n",
      "- TN_DELTA_06_PORC: 84.51% (nulls=10355481, infs=0)\n",
      "- TN_DELTA_07_PORC: 85.10% (nulls=10427680, infs=0)\n",
      "- TN_DELTA_08_PORC: 85.62% (nulls=10491452, infs=0)\n",
      "- TN_DELTA_09_PORC: 86.15% (nulls=10557443, infs=0)\n",
      "- TN_DELTA_10_PORC: 86.76% (nulls=10631901, infs=0)\n",
      "- TN_DELTA_11_PORC: 87.31% (nulls=10698903, infs=0)\n",
      "- TN_DELTA_12_PORC: 87.76% (nulls=10753758, infs=0)\n",
      "- TN_DELTA_13_PORC: 88.22% (nulls=10810121, infs=0)\n",
      "- TN_DELTA_14_PORC: 88.69% (nulls=10868114, infs=0)\n",
      "- TN_DELTA_15_PORC: 89.20% (nulls=10930437, infs=0)\n",
      "- TN_DELTA_16_PORC: 89.67% (nulls=10988171, infs=0)\n",
      "- TN_DELTA_17_PORC: 90.22% (nulls=11056059, infs=0)\n",
      "- TN_DELTA_18_PORC: 90.71% (nulls=11115685, infs=0)\n",
      "- TN_DELTA_19_PORC: 91.28% (nulls=11184919, infs=0)\n",
      "- TN_DELTA_20_PORC: 91.80% (nulls=11249652, infs=0)\n",
      "- TN_DELTA_21_PORC: 92.31% (nulls=11311656, infs=0)\n",
      "- TN_DELTA_22_PORC: 92.92% (nulls=11386680, infs=0)\n",
      "- TN_DELTA_23_PORC: 93.43% (nulls=11449258, infs=0)\n",
      "- TN_DELTA_24_PORC: 93.91% (nulls=11507572, infs=0)\n",
      "- TN_DELTA_25_PORC: 94.38% (nulls=11565722, infs=0)\n",
      "- TN_DELTA_26_PORC: 94.93% (nulls=11632612, infs=0)\n",
      "- TN_DELTA_27_PORC: 95.48% (nulls=11699846, infs=0)\n",
      "- TN_DELTA_28_PORC: 96.02% (nulls=11765879, infs=0)\n",
      "- TN_DELTA_29_PORC: 96.55% (nulls=11831326, infs=0)\n",
      "- TN_DELTA_30_PORC: 96.99% (nulls=11884614, infs=0)\n",
      "- TN_DELTA_31_PORC: 97.53% (nulls=11951948, infs=0)\n",
      "- TN_DELTA_32_PORC: 98.08% (nulls=12018697, infs=0)\n",
      "- TN_DELTA_33_PORC: 98.55% (nulls=12076780, infs=0)\n",
      "- TN_DELTA_34_PORC: 99.08% (nulls=12141254, infs=0)\n",
      "- TN_DELTA_35_PORC: 99.55% (nulls=12198911, infs=0)\n",
      "- TN_LAG_27_ZSCORE: 81.06% (nulls=9933547, infs=0)\n",
      "- TN_DELTA_27_ZSCORE: 81.06% (nulls=9933547, infs=0)\n",
      "- TN_LAG_28_ZSCORE: 83.36% (nulls=10214947, infs=0)\n",
      "- TN_DELTA_28_ZSCORE: 83.36% (nulls=10214947, infs=0)\n",
      "- TN_LAG_29_ZSCORE: 85.61% (nulls=10491077, infs=0)\n",
      "- TN_DELTA_29_ZSCORE: 85.61% (nulls=10491077, infs=0)\n",
      "- TN_LAG_30_ZSCORE: 87.82% (nulls=10761977, infs=0)\n",
      "- TN_DELTA_30_ZSCORE: 87.82% (nulls=10761977, infs=0)\n",
      "- TN_LAG_31_ZSCORE: 89.98% (nulls=11026172, infs=0)\n",
      "- TN_DELTA_31_ZSCORE: 89.98% (nulls=11026172, infs=0)\n",
      "- TN_LAG_32_ZSCORE: 92.10% (nulls=11285750, infs=0)\n",
      "- TN_DELTA_32_ZSCORE: 92.10% (nulls=11285750, infs=0)\n",
      "- TN_LAG_33_ZSCORE: 94.20% (nulls=11542774, infs=0)\n",
      "- TN_DELTA_33_ZSCORE: 94.20% (nulls=11542774, infs=0)\n",
      "- TN_LAG_34_ZSCORE: 96.27% (nulls=11796786, infs=0)\n",
      "- TN_DELTA_34_ZSCORE: 96.27% (nulls=11796786, infs=0)\n",
      "- TN_LAG_35_ZSCORE: 98.25% (nulls=12039286, infs=0)\n",
      "- TN_DELTA_35_ZSCORE: 98.25% (nulls=12039286, infs=0)\n",
      "- TN_LAG_27_ZSCORE_CLIP: 81.06% (nulls=9933547, infs=0)\n",
      "- TN_DELTA_27_ZSCORE_CLIP: 81.06% (nulls=9933547, infs=0)\n",
      "- TN_LAG_28_ZSCORE_CLIP: 83.36% (nulls=10214947, infs=0)\n",
      "- TN_DELTA_28_ZSCORE_CLIP: 83.36% (nulls=10214947, infs=0)\n",
      "- TN_LAG_29_ZSCORE_CLIP: 85.61% (nulls=10491077, infs=0)\n",
      "- TN_DELTA_29_ZSCORE_CLIP: 85.61% (nulls=10491077, infs=0)\n",
      "- TN_LAG_30_ZSCORE_CLIP: 87.82% (nulls=10761977, infs=0)\n",
      "- TN_DELTA_30_ZSCORE_CLIP: 87.82% (nulls=10761977, infs=0)\n",
      "- TN_LAG_31_ZSCORE_CLIP: 89.98% (nulls=11026172, infs=0)\n",
      "- TN_DELTA_31_ZSCORE_CLIP: 89.98% (nulls=11026172, infs=0)\n",
      "- TN_LAG_32_ZSCORE_CLIP: 92.10% (nulls=11285750, infs=0)\n",
      "- TN_DELTA_32_ZSCORE_CLIP: 92.10% (nulls=11285750, infs=0)\n",
      "- TN_LAG_33_ZSCORE_CLIP: 94.20% (nulls=11542774, infs=0)\n",
      "- TN_DELTA_33_ZSCORE_CLIP: 94.20% (nulls=11542774, infs=0)\n",
      "- TN_LAG_34_ZSCORE_CLIP: 96.27% (nulls=11796786, infs=0)\n",
      "- TN_DELTA_34_ZSCORE_CLIP: 96.27% (nulls=11796786, infs=0)\n",
      "- TN_LAG_35_ZSCORE_CLIP: 98.25% (nulls=12039286, infs=0)\n",
      "- TN_DELTA_35_ZSCORE_CLIP: 98.25% (nulls=12039286, infs=0)\n"
     ]
    }
   ],
   "source": [
    "# Umbral: proporción máxima permitida (ej. 0.4 = 40%)\n",
    "umbral_faltantes = 0.8\n",
    "\n",
    "# Diccionario para almacenar estadísticas\n",
    "estadisticas_columnas = []\n",
    "\n",
    "# Recorremos las columnas del DataFrame\n",
    "for col in df_full.columns:\n",
    "    total = len(df_full[col])\n",
    "    nulls = df_full[col].isnull().sum()\n",
    "    nans = df_full[col].isna().sum()\n",
    "    infs = np.isinf(df_full[col]).sum()\n",
    "    \n",
    "    total_faltantes = nulls + infs  # NaN está incluido en nulls/isna\n",
    "    \n",
    "    porcentaje = total_faltantes / total\n",
    "    \n",
    "    estadisticas_columnas.append({\n",
    "        'columna': col,\n",
    "        'nulls': nulls,\n",
    "        'NaNs': nans,\n",
    "        'infs': infs,\n",
    "        'porcentaje_faltantes': porcentaje\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_faltantes = pd.DataFrame(estadisticas_columnas)\n",
    "\n",
    "# Filtrar columnas que superen el umbral\n",
    "columnas_a_eliminar = df_faltantes[df_faltantes['porcentaje_faltantes'] > umbral_faltantes]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(f\"\\nSe eliminarán {len(columnas_a_eliminar)} columnas con más del {umbral_faltantes*100:.0f}% de valores faltantes o infinitos:\")\n",
    "for _, row in columnas_a_eliminar.iterrows():\n",
    "    print(f\"- {row['columna']}: {row['porcentaje_faltantes']*100:.2f}% (nulls={row['nulls']}, infs={row['infs']})\")\n",
    "\n",
    "# Eliminar columnas del DataFrame\n",
    "df_full = df_full.drop(columns=columnas_a_eliminar['columna'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2761d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_resultado una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_full['MES_PROBLEMATICO'] = df_full['PERIODO'].apply(lambda x: True if x in [201906, 201908] else False)\n",
    "df_full['PLAN_PRECIOS_CUIDADOS'] = df_full['PLAN_PRECIOS_CUIDADOS'].map({1 : True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame resultante en un archivo parquet\n",
    "df_full.to_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet', index=False)\n",
    "medias_y_desvios_pd = medias_y_desvios.to_pandas()\n",
    "medias_y_desvios_pd.to_parquet('./data/medias_y_desvios.parquet', engine='fastparquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
