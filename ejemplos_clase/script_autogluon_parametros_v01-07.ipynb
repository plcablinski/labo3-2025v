{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae3d4bc",
   "metadata": {},
   "source": [
    "AutoGluon - Predicción de ventas (tn) por producto para febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82646ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Debe dar True\n",
    "print(torch.cuda.device_count())  # Debe mostrar tu cantidad de GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f52d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 1. Importar librerías\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67eb1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 💬 Instalar AutoGluon si es necesario\n",
    "#%pip install autogluon.timeseries\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74387549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📄 2. Cargar datasets\n",
    "\n",
    "df_sellin = pd.read_parquet('../data/l_vm_completa_train.parquet', engine='fastparquet')\n",
    "df_sellin = df_sellin[df_sellin['A_PREDECIR'] != 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1527b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 3. Preprocesamiento\n",
    "# Convertir periodo a datetime\n",
    "df_sellin['timestamp'] = pd.to_datetime(df_sellin['PERIODO'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1083376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar hasta dic 2019 y productos requeridos\n",
    "df_filtered = df_sellin[\n",
    "    (df_sellin['timestamp'] <= '2019-12-01')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3c4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar tn por periodo, cliente y producto\n",
    "df_grouped = df_filtered.groupby(['timestamp', 'CUSTOMER_ID', 'PRODUCT_ID'], as_index=False)['TN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df0c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar tn total por periodo y producto\n",
    "df_monthly_product = df_grouped.groupby(['timestamp', 'PRODUCT_ID'], as_index=False)['TN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna 'item_id' para AutoGluon\n",
    "df_monthly_product['item_id'] = df_monthly_product['PRODUCT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4e2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⏰ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_monthly_product,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdaef584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anio  mes  cantidad_filas\n",
      "0   2017    1             496\n",
      "1   2017    2             500\n",
      "2   2017    3             502\n",
      "3   2017    4             502\n",
      "4   2017    5             506\n",
      "5   2017    6             513\n",
      "6   2017    7             525\n",
      "7   2017    8             530\n",
      "8   2017    9             536\n",
      "9   2017   10             549\n",
      "10  2017   11             564\n",
      "11  2017   12             564\n",
      "12  2018    1             568\n",
      "13  2018    2             569\n",
      "14  2018    3             575\n",
      "15  2018    4             587\n",
      "16  2018    5             599\n",
      "17  2018    6             599\n",
      "18  2018    7             603\n",
      "19  2018    8             608\n",
      "20  2018    9             627\n",
      "21  2018   10             646\n",
      "22  2018   11             656\n",
      "23  2018   12             656\n",
      "24  2019    1             656\n",
      "25  2019    2             660\n",
      "26  2019    3             675\n",
      "27  2019    4             705\n",
      "28  2019    5             718\n",
      "29  2019    6             734\n",
      "30  2019    7             756\n",
      "31  2019    8             771\n",
      "32  2019    9             780\n",
      "33  2019   10             780\n",
      "34  2019   11             780\n",
      "35  2019   12             780\n"
     ]
    }
   ],
   "source": [
    "# Simplemente reseteá el índice, te devuelve un DataFrame de pandas\n",
    "df = ts_data.reset_index()\n",
    "\n",
    "# Extraer año y mes\n",
    "df['anio'] = df['timestamp'].dt.year\n",
    "df['mes'] = df['timestamp'].dt.month\n",
    "\n",
    "# Agrupar y contar filas por año y mes\n",
    "resumen = df.groupby(['anio', 'mes']).size().reset_index(name='cantidad_filas')\n",
    "\n",
    "print(resumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddac4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98426692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anio  mes  cantidad_filas\n",
      "0   2017    1             496\n",
      "1   2017    2             500\n",
      "2   2017    3             502\n",
      "3   2017    4             502\n",
      "4   2017    5             506\n",
      "5   2017    6             513\n",
      "6   2017    7             525\n",
      "7   2017    8             530\n",
      "8   2017    9             536\n",
      "9   2017   10             549\n",
      "10  2017   11             564\n",
      "11  2017   12             564\n",
      "12  2018    1             568\n",
      "13  2018    2             569\n",
      "14  2018    3             575\n",
      "15  2018    4             587\n",
      "16  2018    5             599\n",
      "17  2018    6             599\n",
      "18  2018    7             603\n",
      "19  2018    8             608\n",
      "20  2018    9             627\n",
      "21  2018   10             646\n",
      "22  2018   11             656\n",
      "23  2018   12             656\n",
      "24  2019    1             656\n",
      "25  2019    2             660\n",
      "26  2019    3             675\n",
      "27  2019    4             705\n",
      "28  2019    5             718\n",
      "29  2019    6             734\n",
      "30  2019    7             756\n",
      "31  2019    8             771\n",
      "32  2019    9             780\n",
      "33  2019   10             780\n",
      "34  2019   11             780\n",
      "35  2019   12             780\n"
     ]
    }
   ],
   "source": [
    "# Simplemente reseteá el índice, te devuelve un DataFrame de pandas\n",
    "df = ts_data.reset_index()\n",
    "\n",
    "# Extraer año y mes\n",
    "df['anio'] = df['timestamp'].dt.year\n",
    "df['mes'] = df['timestamp'].dt.month\n",
    "\n",
    "# Agrupar y contar filas por año y mes\n",
    "resumen = df.groupby(['anio', 'mes']).size().reset_index(name='cantidad_filas')\n",
    "\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b7cc7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to '/workspace/ejemplos_clase/AutogluonModels/ag-20250719_001611'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2\n",
      "CPU Count:          28\n",
      "GPU Count:          1\n",
      "Memory Avail:       101.35 GB / 125.58 GB (80.7%)\n",
      "Disk Space Avail:   143.13 GB / 543.17 GB (26.4%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': {'AutoARIMA': {},\n",
      "                     'DLinear': {},\n",
      "                     'DeepAR': {'num_batches_per_epoch': 100,\n",
      "                                'num_workers': 20},\n",
      "                     'ETS': {},\n",
      "                     'PatchTST': {'num_workers': 20},\n",
      "                     'TemporalFusionTransformer': {'num_workers': 20}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 16,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'TN',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 22375 rows, 780 time series. Median time series length is 36 (min=4, max=36). \n",
      "Time series in train_data are too short for chosen num_val_windows=16. Reducing num_val_windows to 15.\n",
      "\tRemoving 280 short time series from train_data. Only series with length >= 35 will be used for training.\n",
      "\tAfter filtering, train_data has 17996 rows, 500 time series. Median time series length is 36 (min=35, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'TN'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['PRODUCT_ID']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-19 00:16:11\n",
      "Models that will be trained: ['ETS', 'AutoARIMA', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'DLinear']\n",
      "Training timeseries model ETS. Training for up to 514.3s of the 3599.9s of remaining time.\n",
      "\tWarning: ETS/W0 failed for 500 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2156       = Validation score (-WQL)\n",
      "\t4.96    s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoARIMA. Training for up to 599.1s of the 3594.4s of remaining time.\n",
      "\t-0.2348       = Validation score (-WQL)\n",
      "\t83.91   s     = Training runtime\n",
      "\t5.39    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 726.3s of the 3505.1s of remaining time.\n",
      "\t-0.1949       = Validation score (-WQL)\n",
      "\t283.01  s     = Training runtime\n",
      "\t0.11    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 874.0s of the 3222.0s of remaining time.\n",
      "\t-0.2001       = Validation score (-WQL)\n",
      "\t568.66  s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1026.6s of the 2653.2s of remaining time.\n",
      "\t-0.1834       = Validation score (-WQL)\n",
      "\t164.07  s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model DLinear. Training for up to 1889.1s of the 2489.1s of remaining time.\n",
      "\t-0.2046       = Validation score (-WQL)\n",
      "\t117.48  s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoARIMA': 0.01, 'DeepAR': 0.16, 'ETS': 0.1, 'PatchTST': 0.57, 'TemporalFusionTransformer': 0.16}\n",
      "\t-0.1789       = Validation score (-WQL)\n",
      "\t3.76    s     = Training runtime\n",
      "\t6.24    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['ETS', 'AutoARIMA', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'DLinear', 'WeightedEnsemble']\n",
      "Total runtime: 1232.37 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x7db0a961cc40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ⚙️ 5. Definir y entrenar predictor\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=2,\n",
    "    target='TN',\n",
    "    freq='MS'\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"AutoARIMA\": {},\n",
    "    \"ETS\": {},\n",
    "    \"DeepAR\": {\"num_batches_per_epoch\": 100, \"num_workers\": 20},\n",
    "    \"PatchTST\": {\"num_workers\": 20},\n",
    "    \"TemporalFusionTransformer\": {\"num_workers\": 20},\n",
    "    \"DLinear\": {},\n",
    "    # Podés sumar otros modelos de la lista...\n",
    "}\n",
    "\n",
    "predictor.fit(\n",
    "    ts_data,\n",
    "    num_val_windows=16,\n",
    "    time_limit=60*60,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c27fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "\tWarning: ETS/W14 failed for 46 time series (5.9%). Fallback model SeasonalNaive was used for these time series.\n"
     ]
    }
   ],
   "source": [
    "# 🔮 6. Generar predicción\n",
    "forecast = predictor.predict(ts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57205cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'timestamp', 'mean'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Extraer predicción media y filtrar febrero 2020\n",
    "forecast_mean = forecast['mean'].reset_index()\n",
    "print(forecast_mean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d62a0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar solo item_id y la predicción 'mean'\n",
    "resultado = forecast['mean'].reset_index()[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# Filtrar solo febrero 2020\n",
    "resultado = forecast['mean'].reset_index()\n",
    "resultado = resultado[resultado['timestamp'] == '2020-02-01']\n",
    "\n",
    "# Renombrar columnas\n",
    "resultado = resultado[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81a9323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>1154.437290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20002</td>\n",
       "      <td>914.357926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>661.944658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20004</td>\n",
       "      <td>490.075366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20005</td>\n",
       "      <td>465.822648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           tn\n",
       "1       20001  1154.437290\n",
       "3       20002   914.357926\n",
       "5       20003   661.944658\n",
       "7       20004   490.075366\n",
       "9       20005   465.822648"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 💾 7. Guardar archivo\n",
    "resultado.to_csv(\"predicciones_febrero2020_fecha_01_07.csv\", index=False)\n",
    "resultado.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
