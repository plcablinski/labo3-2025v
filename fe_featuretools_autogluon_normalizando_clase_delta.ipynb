{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cd76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducir memoria automáticamente\n",
    "def optimizar_memoria(df):\n",
    "    for col in df.select_dtypes(include=['int64', 'int32']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include=['float64', 'float32']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e6277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recargar(path=\"tmp_intermedio.parquet\", engine=\"fastparquet\"):\n",
    "    df = pd.read_parquet(path, engine=engine)\n",
    "    df_full = optimizar_memoria(df_full)\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fbf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_y_eliminar_df(df, path=\"tmp_intermedio.parquet\", engine=\"fastparquet\"):\n",
    "    df.to_parquet(path, engine=engine, index=False)\n",
    "    del df\n",
    "    gc.collect()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1dd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d03193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar de df_full las filas donde la columna A_PREDECIR sea 'N'\n",
    "df_full = df_full[df_full['A_PREDECIR'] != 'N']\n",
    "df_full = df_full.drop(columns=['A_PREDECIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba02f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservar las siguientes columnas\n",
    "columns_to_keep = ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1',\n",
    "       'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID',\n",
    "       'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY',\n",
    "       'CUST_REQUEST_TN', 'TN', 'CLASE', 'CLASE_DELTA',\n",
    "       'ORDINAL', 'ANTIG_CLIENTE',\n",
    "       'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER']\n",
    "# Filtrar el DataFrame para conservar solo las columnas deseadas \n",
    "df_full = df_full[columns_to_keep]\n",
    "df_full['DIAS_EN_MES'] = pd.to_datetime(df_full['PERIODO'], format='%Y%m').dt.days_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a628de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = optimizar_memoria(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9d63a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ordenar correctamente\n",
    "df_full = df_full.sort_values(by=['PRODUCT_ID', 'CUSTOMER_ID', 'ORDINAL'], ascending=True)\n",
    "\n",
    "# 2. Crear los LAGs y DELTAs\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "\n",
    "    df_full[lag_col] = df_full.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])['TN'].shift(lag)\n",
    "    df_full[delta_col] = df_full['TN'] - df_full[lag_col]\n",
    "\n",
    "# 3. Crear las variaciones porcentuales SIN fragmentar\n",
    "delta_pct_cols = {}\n",
    "\n",
    "for lag in range(1, 36):\n",
    "    lag_col = f'TN_LAG_{lag:02d}'\n",
    "    delta_col = f'TN_DELTA_{lag:02d}'\n",
    "    delta_pct_col = f'TN_DELTA_{lag:02d}_PORC'\n",
    "\n",
    "    delta_pct_cols[delta_pct_col] = np.where(\n",
    "        df_full[lag_col] == 0,\n",
    "        np.nan,\n",
    "        df_full[delta_col] / df_full[lag_col]\n",
    "    )\n",
    "\n",
    "# 4. Concatenar todas las columnas nuevas en un solo paso\n",
    "df_porcentajes = pd.DataFrame(delta_pct_cols, index=df_full.index)\n",
    "df_full = pd.concat([df_full, df_porcentajes], axis=1)\n",
    "del df_porcentajes\n",
    "\n",
    "\n",
    "# 5. (Opcional) Defragmentar para mejorar rendimiento\n",
    "df_full = df_full.copy()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0ca27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = optimizar_memoria(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217cf0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas base para transformación: ['CUST_REQUEST_QTY', 'CUST_REQUEST_TN', 'TN', 'TN_LAG_01', 'TN_DELTA_01', 'TN_LAG_02', 'TN_DELTA_02', 'TN_LAG_03', 'TN_DELTA_03', 'TN_LAG_04', 'TN_DELTA_04', 'TN_LAG_05', 'TN_DELTA_05', 'TN_LAG_06', 'TN_DELTA_06', 'TN_LAG_07', 'TN_DELTA_07', 'TN_LAG_08', 'TN_DELTA_08', 'TN_LAG_09', 'TN_DELTA_09', 'TN_LAG_10', 'TN_DELTA_10', 'TN_LAG_11', 'TN_DELTA_11', 'TN_LAG_12', 'TN_DELTA_12', 'TN_LAG_13', 'TN_DELTA_13', 'TN_LAG_14', 'TN_DELTA_14', 'TN_LAG_15', 'TN_DELTA_15', 'TN_LAG_16', 'TN_DELTA_16', 'TN_LAG_17', 'TN_DELTA_17', 'TN_LAG_18', 'TN_DELTA_18', 'TN_LAG_19', 'TN_DELTA_19', 'TN_LAG_20', 'TN_DELTA_20', 'TN_LAG_21', 'TN_DELTA_21', 'TN_LAG_22', 'TN_DELTA_22', 'TN_LAG_23', 'TN_DELTA_23', 'TN_LAG_24', 'TN_DELTA_24', 'TN_LAG_25', 'TN_DELTA_25', 'TN_LAG_26', 'TN_DELTA_26', 'TN_LAG_27', 'TN_DELTA_27', 'TN_LAG_28', 'TN_DELTA_28', 'TN_LAG_29', 'TN_DELTA_29', 'TN_LAG_30', 'TN_DELTA_30', 'TN_LAG_31', 'TN_DELTA_31', 'TN_LAG_32', 'TN_DELTA_32', 'TN_LAG_33', 'TN_DELTA_33', 'TN_LAG_34', 'TN_DELTA_34', 'TN_LAG_35', 'TN_DELTA_35']\n"
     ]
    }
   ],
   "source": [
    "# Filtrar columnas numéricas recientes sobre las que vale la pena transformar\n",
    "cols_base = [col for col in df_full.columns if (\n",
    "    (col.startswith('TN_DELTA_') and not col.endswith('_PORC'))\n",
    "    or col.startswith('TN_LAG_')\n",
    "    or col == 'TN'\n",
    "    or col == 'CUST_REQUEST_TN'\n",
    "    or col == 'CUST_REQUEST_QTY'\n",
    ")]\n",
    "print(f\"Columnas base para transformación: {cols_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0968b968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQ'] = np.square(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
      "/tmp/ipykernel_125243/247404005.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n"
     ]
    }
   ],
   "source": [
    "def transformar_columna_en_memoria(df, col):\n",
    "    if col not in df.columns:\n",
    "        return None\n",
    "\n",
    "    col_data = df[col].values  # Evita overhead de pandas internamente\n",
    "\n",
    "    # Calcular cada transformación usando arrays\n",
    "    df[f'{col}_SQ'] = np.square(col_data)\n",
    "    df[f'{col}_SQRT'] = np.sqrt(np.abs(col_data)) * np.sign(col_data)\n",
    "    df[f'{col}_LOG1P'] = np.log1p(np.abs(col_data)) * np.sign(col_data)\n",
    "\n",
    "    # Liberar arrays intermedios (aunque pandas puede retenerlos por un tiempo)\n",
    "    del col_data\n",
    "    gc.collect()\n",
    "\n",
    "# Procesar columna por columna (sin crear estructuras innecesarias)\n",
    "for col in cols_base:\n",
    "    transformar_columna_en_memoria(df_full, col)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a515075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = optimizar_memoria(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9af34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CUST_REQUEST_QTY', 'CUST_REQUEST_TN', 'TN', 'TN_LAG_01', 'TN_DELTA_01']\n"
     ]
    }
   ],
   "source": [
    "print(cols_base[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b27cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n",
      "/tmp/ipykernel_125243/329459102.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "for col1, col2 in combinations(cols_base[:10], 2):  # limitar a 10 para no explotar dimensionalidad\n",
    "    df_full[f'{col1}_x_{col2}'] = df_full[col1] * df_full[col2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf402cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = optimizar_memoria(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f2f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después de transformaciones: ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1', 'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID', 'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY', 'CUST_REQUEST_TN', 'TN', 'CLASE', 'CLASE_DELTA', 'ORDINAL', 'ANTIG_CLIENTE', 'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER', 'DIAS_EN_MES', 'TN_LAG_01', 'TN_DELTA_01', 'TN_LAG_02', 'TN_DELTA_02', 'TN_LAG_03', 'TN_DELTA_03', 'TN_LAG_04', 'TN_DELTA_04', 'TN_LAG_05', 'TN_DELTA_05', 'TN_LAG_06', 'TN_DELTA_06', 'TN_LAG_07', 'TN_DELTA_07', 'TN_LAG_08', 'TN_DELTA_08', 'TN_LAG_09', 'TN_DELTA_09', 'TN_LAG_10', 'TN_DELTA_10', 'TN_LAG_11', 'TN_DELTA_11', 'TN_LAG_12', 'TN_DELTA_12', 'TN_LAG_13', 'TN_DELTA_13', 'TN_LAG_14', 'TN_DELTA_14', 'TN_LAG_15', 'TN_DELTA_15', 'TN_LAG_16', 'TN_DELTA_16', 'TN_LAG_17', 'TN_DELTA_17', 'TN_LAG_18', 'TN_DELTA_18', 'TN_LAG_19', 'TN_DELTA_19', 'TN_LAG_20', 'TN_DELTA_20', 'TN_LAG_21', 'TN_DELTA_21', 'TN_LAG_22', 'TN_DELTA_22', 'TN_LAG_23', 'TN_DELTA_23', 'TN_LAG_24', 'TN_DELTA_24', 'TN_LAG_25', 'TN_DELTA_25', 'TN_LAG_26', 'TN_DELTA_26', 'TN_LAG_27', 'TN_DELTA_27', 'TN_LAG_28', 'TN_DELTA_28', 'TN_LAG_29', 'TN_DELTA_29', 'TN_LAG_30', 'TN_DELTA_30', 'TN_LAG_31', 'TN_DELTA_31', 'TN_LAG_32', 'TN_DELTA_32', 'TN_LAG_33', 'TN_DELTA_33', 'TN_LAG_34', 'TN_DELTA_34', 'TN_LAG_35', 'TN_DELTA_35', 'TN_DELTA_01_PORC', 'TN_DELTA_02_PORC', 'TN_DELTA_03_PORC', 'TN_DELTA_04_PORC', 'TN_DELTA_05_PORC', 'TN_DELTA_06_PORC', 'TN_DELTA_07_PORC', 'TN_DELTA_08_PORC', 'TN_DELTA_09_PORC', 'TN_DELTA_10_PORC', 'TN_DELTA_11_PORC', 'TN_DELTA_12_PORC', 'TN_DELTA_13_PORC', 'TN_DELTA_14_PORC', 'TN_DELTA_15_PORC', 'TN_DELTA_16_PORC', 'TN_DELTA_17_PORC', 'TN_DELTA_18_PORC', 'TN_DELTA_19_PORC', 'TN_DELTA_20_PORC', 'TN_DELTA_21_PORC', 'TN_DELTA_22_PORC', 'TN_DELTA_23_PORC', 'TN_DELTA_24_PORC', 'TN_DELTA_25_PORC', 'TN_DELTA_26_PORC', 'TN_DELTA_27_PORC', 'TN_DELTA_28_PORC', 'TN_DELTA_29_PORC', 'TN_DELTA_30_PORC', 'TN_DELTA_31_PORC', 'TN_DELTA_32_PORC', 'TN_DELTA_33_PORC', 'TN_DELTA_34_PORC', 'TN_DELTA_35_PORC', 'CUST_REQUEST_QTY_SQ', 'CUST_REQUEST_QTY_SQRT', 'CUST_REQUEST_QTY_LOG1P', 'CUST_REQUEST_TN_SQ', 'CUST_REQUEST_TN_SQRT', 'CUST_REQUEST_TN_LOG1P', 'TN_SQ', 'TN_SQRT', 'TN_LOG1P', 'TN_LAG_01_SQ', 'TN_LAG_01_SQRT', 'TN_LAG_01_LOG1P', 'TN_DELTA_01_SQ', 'TN_DELTA_01_SQRT', 'TN_DELTA_01_LOG1P', 'TN_LAG_02_SQ', 'TN_LAG_02_SQRT', 'TN_LAG_02_LOG1P', 'TN_DELTA_02_SQ', 'TN_DELTA_02_SQRT', 'TN_DELTA_02_LOG1P', 'TN_LAG_03_SQ', 'TN_LAG_03_SQRT', 'TN_LAG_03_LOG1P', 'TN_DELTA_03_SQ', 'TN_DELTA_03_SQRT', 'TN_DELTA_03_LOG1P', 'TN_LAG_04_SQ', 'TN_LAG_04_SQRT', 'TN_LAG_04_LOG1P', 'TN_DELTA_04_SQ', 'TN_DELTA_04_SQRT', 'TN_DELTA_04_LOG1P', 'TN_LAG_05_SQ', 'TN_LAG_05_SQRT', 'TN_LAG_05_LOG1P', 'TN_DELTA_05_SQ', 'TN_DELTA_05_SQRT', 'TN_DELTA_05_LOG1P', 'TN_LAG_06_SQ', 'TN_LAG_06_SQRT', 'TN_LAG_06_LOG1P', 'TN_DELTA_06_SQ', 'TN_DELTA_06_SQRT', 'TN_DELTA_06_LOG1P', 'TN_LAG_07_SQ', 'TN_LAG_07_SQRT', 'TN_LAG_07_LOG1P', 'TN_DELTA_07_SQ', 'TN_DELTA_07_SQRT', 'TN_DELTA_07_LOG1P', 'TN_LAG_08_SQ', 'TN_LAG_08_SQRT', 'TN_LAG_08_LOG1P', 'TN_DELTA_08_SQ', 'TN_DELTA_08_SQRT', 'TN_DELTA_08_LOG1P', 'TN_LAG_09_SQ', 'TN_LAG_09_SQRT', 'TN_LAG_09_LOG1P', 'TN_DELTA_09_SQ', 'TN_DELTA_09_SQRT', 'TN_DELTA_09_LOG1P', 'TN_LAG_10_SQ', 'TN_LAG_10_SQRT', 'TN_LAG_10_LOG1P', 'TN_DELTA_10_SQ', 'TN_DELTA_10_SQRT', 'TN_DELTA_10_LOG1P', 'TN_LAG_11_SQ', 'TN_LAG_11_SQRT', 'TN_LAG_11_LOG1P', 'TN_DELTA_11_SQ', 'TN_DELTA_11_SQRT', 'TN_DELTA_11_LOG1P', 'TN_LAG_12_SQ', 'TN_LAG_12_SQRT', 'TN_LAG_12_LOG1P', 'TN_DELTA_12_SQ', 'TN_DELTA_12_SQRT', 'TN_DELTA_12_LOG1P', 'TN_LAG_13_SQ', 'TN_LAG_13_SQRT', 'TN_LAG_13_LOG1P', 'TN_DELTA_13_SQ', 'TN_DELTA_13_SQRT', 'TN_DELTA_13_LOG1P', 'TN_LAG_14_SQ', 'TN_LAG_14_SQRT', 'TN_LAG_14_LOG1P', 'TN_DELTA_14_SQ', 'TN_DELTA_14_SQRT', 'TN_DELTA_14_LOG1P', 'TN_LAG_15_SQ', 'TN_LAG_15_SQRT', 'TN_LAG_15_LOG1P', 'TN_DELTA_15_SQ', 'TN_DELTA_15_SQRT', 'TN_DELTA_15_LOG1P', 'TN_LAG_16_SQ', 'TN_LAG_16_SQRT', 'TN_LAG_16_LOG1P', 'TN_DELTA_16_SQ', 'TN_DELTA_16_SQRT', 'TN_DELTA_16_LOG1P', 'TN_LAG_17_SQ', 'TN_LAG_17_SQRT', 'TN_LAG_17_LOG1P', 'TN_DELTA_17_SQ', 'TN_DELTA_17_SQRT', 'TN_DELTA_17_LOG1P', 'TN_LAG_18_SQ', 'TN_LAG_18_SQRT', 'TN_LAG_18_LOG1P', 'TN_DELTA_18_SQ', 'TN_DELTA_18_SQRT', 'TN_DELTA_18_LOG1P', 'TN_LAG_19_SQ', 'TN_LAG_19_SQRT', 'TN_LAG_19_LOG1P', 'TN_DELTA_19_SQ', 'TN_DELTA_19_SQRT', 'TN_DELTA_19_LOG1P', 'TN_LAG_20_SQ', 'TN_LAG_20_SQRT', 'TN_LAG_20_LOG1P', 'TN_DELTA_20_SQ', 'TN_DELTA_20_SQRT', 'TN_DELTA_20_LOG1P', 'TN_LAG_21_SQ', 'TN_LAG_21_SQRT', 'TN_LAG_21_LOG1P', 'TN_DELTA_21_SQ', 'TN_DELTA_21_SQRT', 'TN_DELTA_21_LOG1P', 'TN_LAG_22_SQ', 'TN_LAG_22_SQRT', 'TN_LAG_22_LOG1P', 'TN_DELTA_22_SQ', 'TN_DELTA_22_SQRT', 'TN_DELTA_22_LOG1P', 'TN_LAG_23_SQ', 'TN_LAG_23_SQRT', 'TN_LAG_23_LOG1P', 'TN_DELTA_23_SQ', 'TN_DELTA_23_SQRT', 'TN_DELTA_23_LOG1P', 'TN_LAG_24_SQ', 'TN_LAG_24_SQRT', 'TN_LAG_24_LOG1P', 'TN_DELTA_24_SQ', 'TN_DELTA_24_SQRT', 'TN_DELTA_24_LOG1P', 'TN_LAG_25_SQ', 'TN_LAG_25_SQRT', 'TN_LAG_25_LOG1P', 'TN_DELTA_25_SQ', 'TN_DELTA_25_SQRT', 'TN_DELTA_25_LOG1P', 'TN_LAG_26_SQ', 'TN_LAG_26_SQRT', 'TN_LAG_26_LOG1P', 'TN_DELTA_26_SQ', 'TN_DELTA_26_SQRT', 'TN_DELTA_26_LOG1P', 'TN_LAG_27_SQ', 'TN_LAG_27_SQRT', 'TN_LAG_27_LOG1P', 'TN_DELTA_27_SQ', 'TN_DELTA_27_SQRT', 'TN_DELTA_27_LOG1P', 'TN_LAG_28_SQ', 'TN_LAG_28_SQRT', 'TN_LAG_28_LOG1P', 'TN_DELTA_28_SQ', 'TN_DELTA_28_SQRT', 'TN_DELTA_28_LOG1P', 'TN_LAG_29_SQ', 'TN_LAG_29_SQRT', 'TN_LAG_29_LOG1P', 'TN_DELTA_29_SQ', 'TN_DELTA_29_SQRT', 'TN_DELTA_29_LOG1P', 'TN_LAG_30_SQ', 'TN_LAG_30_SQRT', 'TN_LAG_30_LOG1P', 'TN_DELTA_30_SQ', 'TN_DELTA_30_SQRT', 'TN_DELTA_30_LOG1P', 'TN_LAG_31_SQ', 'TN_LAG_31_SQRT', 'TN_LAG_31_LOG1P', 'TN_DELTA_31_SQ', 'TN_DELTA_31_SQRT', 'TN_DELTA_31_LOG1P', 'TN_LAG_32_SQ', 'TN_LAG_32_SQRT', 'TN_LAG_32_LOG1P', 'TN_DELTA_32_SQ', 'TN_DELTA_32_SQRT', 'TN_DELTA_32_LOG1P', 'TN_LAG_33_SQ', 'TN_LAG_33_SQRT', 'TN_LAG_33_LOG1P', 'TN_DELTA_33_SQ', 'TN_DELTA_33_SQRT', 'TN_DELTA_33_LOG1P', 'TN_LAG_34_SQ', 'TN_LAG_34_SQRT', 'TN_LAG_34_LOG1P', 'TN_DELTA_34_SQ', 'TN_DELTA_34_SQRT', 'TN_DELTA_34_LOG1P', 'TN_LAG_35_SQ', 'TN_LAG_35_SQRT', 'TN_LAG_35_LOG1P', 'TN_DELTA_35_SQ', 'TN_DELTA_35_SQRT', 'TN_DELTA_35_LOG1P', 'CUST_REQUEST_QTY_x_CUST_REQUEST_TN', 'CUST_REQUEST_QTY_x_TN', 'CUST_REQUEST_QTY_x_TN_LAG_01', 'CUST_REQUEST_QTY_x_TN_DELTA_01', 'CUST_REQUEST_QTY_x_TN_LAG_02', 'CUST_REQUEST_QTY_x_TN_DELTA_02', 'CUST_REQUEST_QTY_x_TN_LAG_03', 'CUST_REQUEST_QTY_x_TN_DELTA_03', 'CUST_REQUEST_QTY_x_TN_LAG_04', 'CUST_REQUEST_TN_x_TN', 'CUST_REQUEST_TN_x_TN_LAG_01', 'CUST_REQUEST_TN_x_TN_DELTA_01', 'CUST_REQUEST_TN_x_TN_LAG_02', 'CUST_REQUEST_TN_x_TN_DELTA_02', 'CUST_REQUEST_TN_x_TN_LAG_03', 'CUST_REQUEST_TN_x_TN_DELTA_03', 'CUST_REQUEST_TN_x_TN_LAG_04', 'TN_x_TN_LAG_01', 'TN_x_TN_DELTA_01', 'TN_x_TN_LAG_02', 'TN_x_TN_DELTA_02', 'TN_x_TN_LAG_03', 'TN_x_TN_DELTA_03', 'TN_x_TN_LAG_04', 'TN_LAG_01_x_TN_DELTA_01', 'TN_LAG_01_x_TN_LAG_02', 'TN_LAG_01_x_TN_DELTA_02', 'TN_LAG_01_x_TN_LAG_03', 'TN_LAG_01_x_TN_DELTA_03', 'TN_LAG_01_x_TN_LAG_04', 'TN_DELTA_01_x_TN_LAG_02', 'TN_DELTA_01_x_TN_DELTA_02', 'TN_DELTA_01_x_TN_LAG_03', 'TN_DELTA_01_x_TN_DELTA_03', 'TN_DELTA_01_x_TN_LAG_04', 'TN_LAG_02_x_TN_DELTA_02', 'TN_LAG_02_x_TN_LAG_03', 'TN_LAG_02_x_TN_DELTA_03', 'TN_LAG_02_x_TN_LAG_04', 'TN_DELTA_02_x_TN_LAG_03', 'TN_DELTA_02_x_TN_DELTA_03', 'TN_DELTA_02_x_TN_LAG_04', 'TN_LAG_03_x_TN_DELTA_03', 'TN_LAG_03_x_TN_LAG_04', 'TN_DELTA_03_x_TN_LAG_04']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columnas después de transformaciones: {df_full.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un DataFrame de Polars\n",
    "df_full = pl.from_pandas(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987bf055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Filtrar columnas relevantes\n",
    "columnas_a_normalizar = [\n",
    "    col for col in df_full.columns\n",
    "    if ('TN' in col or 'DELTA' in col or 'CLASE' in col or 'LAG' in col)\n",
    "    and 'PORC' not in col\n",
    "]\n",
    "\n",
    "# 2. Inicializar DataFrame con combinaciones únicas\n",
    "medias_y_desvios = df_full.select(['PRODUCT_ID', 'CUSTOMER_ID']).unique()\n",
    "\n",
    "# 3. Calcular medias y desvíos por columna\n",
    "resultados = []\n",
    "for col in columnas_a_normalizar:\n",
    "    if col in df_full.columns:\n",
    "        resumen = (\n",
    "            df_full\n",
    "            .select(['PRODUCT_ID', 'CUSTOMER_ID', col])\n",
    "            .group_by(['PRODUCT_ID', 'CUSTOMER_ID'])\n",
    "            .agg([\n",
    "                pl.col(col).mean().alias(f'{col}_MEDIA'),\n",
    "                pl.col(col).std().alias(f'{col}_DESVIO')\n",
    "            ])\n",
    "        )\n",
    "        resultados.append(resumen)\n",
    "\n",
    "# 4. Combinar todos los resultados\n",
    "medias_y_desvios = reduce(\n",
    "    lambda df1, df2: df1.join(df2, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left'), \n",
    "    resultados\n",
    ")\n",
    "# Convertir los nulos en ceros\n",
    "medias_y_desvios = medias_y_desvios.fill_null(0)\n",
    "\n",
    "del resumen, resultados\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_zscore_con_join(\n",
    "    df_full: pl.DataFrame,\n",
    "    medias_y_desvios: pl.DataFrame,\n",
    "    columnas_a_normalizar: List[str],\n",
    "    conservar_auxiliares: bool = False,\n",
    "    epsilon: float = 1e-6,\n",
    "    clip_value: float = 5.0,\n",
    "    agregar_clip: bool = False\n",
    ") -> pl.DataFrame:\n",
    "    # 1. Armar columnas necesarias\n",
    "    columnas_media = [f'{col}_MEDIA' for col in columnas_a_normalizar if f'{col}_MEDIA' in medias_y_desvios.columns]\n",
    "    columnas_desvio = [f'{col}_DESVIO' for col in columnas_a_normalizar if f'{col}_DESVIO' in medias_y_desvios.columns]\n",
    "    columnas_join = ['PRODUCT_ID', 'CUSTOMER_ID'] + columnas_media + columnas_desvio\n",
    "\n",
    "    # 2. Join\n",
    "    df_aux = medias_y_desvios.select(columnas_join)\n",
    "    df_full = df_full.join(df_aux, on=['PRODUCT_ID', 'CUSTOMER_ID'], how='left')\n",
    "\n",
    "    # 3. Calcular ZSCOREs\n",
    "    zscore_exprs = []\n",
    "    for col in columnas_a_normalizar:\n",
    "        media_col = f\"{col}_MEDIA\"\n",
    "        desvio_col = f\"{col}_DESVIO\"\n",
    "        z_col = f\"{col}_ZSCORE\"\n",
    "        if media_col in df_full.columns and desvio_col in df_full.columns:\n",
    "            expr = (\n",
    "                (pl.col(col) - pl.col(media_col)) /\n",
    "                (pl.col(desvio_col) + epsilon)\n",
    "            ).alias(z_col)\n",
    "            zscore_exprs.append(expr)\n",
    "            print(f\"✅ Normalizando: {col} -> {z_col}\")\n",
    "\n",
    "    df_full = df_full.with_columns(zscore_exprs)\n",
    "\n",
    "    # 4. Clipping (después de que los zscores existen)\n",
    "    if agregar_clip:\n",
    "        clip_exprs = [\n",
    "            pl.col(f\"{col}_ZSCORE\").clip(-clip_value, clip_value).alias(f\"{col}_ZSCORE_CLIP\")\n",
    "            for col in columnas_a_normalizar\n",
    "            if f\"{col}_ZSCORE\" in df_full.columns\n",
    "        ]\n",
    "        df_full = df_full.with_columns(clip_exprs)\n",
    "\n",
    "    # 5. Eliminar auxiliares si no se quieren\n",
    "    if not conservar_auxiliares:\n",
    "        df_full = df_full.drop(columnas_media + columnas_desvio)\n",
    "\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb0c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalizando: CUST_REQUEST_TN -> CUST_REQUEST_TN_ZSCORE\n",
      "✅ Normalizando: TN -> TN_ZSCORE\n",
      "✅ Normalizando: CLASE -> CLASE_ZSCORE\n",
      "✅ Normalizando: CLASE_DELTA -> CLASE_DELTA_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01 -> TN_LAG_01_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01 -> TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02 -> TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02 -> TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03 -> TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03 -> TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_04 -> TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_04 -> TN_DELTA_04_ZSCORE\n",
      "✅ Normalizando: TN_LAG_05 -> TN_LAG_05_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_05 -> TN_DELTA_05_ZSCORE\n",
      "✅ Normalizando: TN_LAG_06 -> TN_LAG_06_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_06 -> TN_DELTA_06_ZSCORE\n",
      "✅ Normalizando: TN_LAG_07 -> TN_LAG_07_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_07 -> TN_DELTA_07_ZSCORE\n",
      "✅ Normalizando: TN_LAG_08 -> TN_LAG_08_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_08 -> TN_DELTA_08_ZSCORE\n",
      "✅ Normalizando: TN_LAG_09 -> TN_LAG_09_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_09 -> TN_DELTA_09_ZSCORE\n",
      "✅ Normalizando: TN_LAG_10 -> TN_LAG_10_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_10 -> TN_DELTA_10_ZSCORE\n",
      "✅ Normalizando: TN_LAG_11 -> TN_LAG_11_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_11 -> TN_DELTA_11_ZSCORE\n",
      "✅ Normalizando: TN_LAG_12 -> TN_LAG_12_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_12 -> TN_DELTA_12_ZSCORE\n",
      "✅ Normalizando: TN_LAG_13 -> TN_LAG_13_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_13 -> TN_DELTA_13_ZSCORE\n",
      "✅ Normalizando: TN_LAG_14 -> TN_LAG_14_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_14 -> TN_DELTA_14_ZSCORE\n",
      "✅ Normalizando: TN_LAG_15 -> TN_LAG_15_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_15 -> TN_DELTA_15_ZSCORE\n",
      "✅ Normalizando: TN_LAG_16 -> TN_LAG_16_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_16 -> TN_DELTA_16_ZSCORE\n",
      "✅ Normalizando: TN_LAG_17 -> TN_LAG_17_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_17 -> TN_DELTA_17_ZSCORE\n",
      "✅ Normalizando: TN_LAG_18 -> TN_LAG_18_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_18 -> TN_DELTA_18_ZSCORE\n",
      "✅ Normalizando: TN_LAG_19 -> TN_LAG_19_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_19 -> TN_DELTA_19_ZSCORE\n",
      "✅ Normalizando: TN_LAG_20 -> TN_LAG_20_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_20 -> TN_DELTA_20_ZSCORE\n",
      "✅ Normalizando: TN_LAG_21 -> TN_LAG_21_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_21 -> TN_DELTA_21_ZSCORE\n",
      "✅ Normalizando: TN_LAG_22 -> TN_LAG_22_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_22 -> TN_DELTA_22_ZSCORE\n",
      "✅ Normalizando: TN_LAG_23 -> TN_LAG_23_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_23 -> TN_DELTA_23_ZSCORE\n",
      "✅ Normalizando: TN_LAG_24 -> TN_LAG_24_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_24 -> TN_DELTA_24_ZSCORE\n",
      "✅ Normalizando: TN_LAG_25 -> TN_LAG_25_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_25 -> TN_DELTA_25_ZSCORE\n",
      "✅ Normalizando: TN_LAG_26 -> TN_LAG_26_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_26 -> TN_DELTA_26_ZSCORE\n",
      "✅ Normalizando: TN_LAG_27 -> TN_LAG_27_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_27 -> TN_DELTA_27_ZSCORE\n",
      "✅ Normalizando: TN_LAG_28 -> TN_LAG_28_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_28 -> TN_DELTA_28_ZSCORE\n",
      "✅ Normalizando: TN_LAG_29 -> TN_LAG_29_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_29 -> TN_DELTA_29_ZSCORE\n",
      "✅ Normalizando: TN_LAG_30 -> TN_LAG_30_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_30 -> TN_DELTA_30_ZSCORE\n",
      "✅ Normalizando: TN_LAG_31 -> TN_LAG_31_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_31 -> TN_DELTA_31_ZSCORE\n",
      "✅ Normalizando: TN_LAG_32 -> TN_LAG_32_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_32 -> TN_DELTA_32_ZSCORE\n",
      "✅ Normalizando: TN_LAG_33 -> TN_LAG_33_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_33 -> TN_DELTA_33_ZSCORE\n",
      "✅ Normalizando: TN_LAG_34 -> TN_LAG_34_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_34 -> TN_DELTA_34_ZSCORE\n",
      "✅ Normalizando: TN_LAG_35 -> TN_LAG_35_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_35 -> TN_DELTA_35_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_SQ -> CUST_REQUEST_TN_SQ_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_SQRT -> CUST_REQUEST_TN_SQRT_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_LOG1P -> CUST_REQUEST_TN_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_SQ -> TN_SQ_ZSCORE\n",
      "✅ Normalizando: TN_SQRT -> TN_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LOG1P -> TN_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_SQ -> TN_LAG_01_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_SQRT -> TN_LAG_01_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_LOG1P -> TN_LAG_01_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_SQ -> TN_DELTA_01_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_SQRT -> TN_DELTA_01_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_LOG1P -> TN_DELTA_01_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_SQ -> TN_LAG_02_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_SQRT -> TN_LAG_02_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_LOG1P -> TN_LAG_02_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_SQ -> TN_DELTA_02_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_SQRT -> TN_DELTA_02_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_LOG1P -> TN_DELTA_02_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03_SQ -> TN_LAG_03_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03_SQRT -> TN_LAG_03_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03_LOG1P -> TN_LAG_03_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03_SQ -> TN_DELTA_03_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03_SQRT -> TN_DELTA_03_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03_LOG1P -> TN_DELTA_03_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_04_SQ -> TN_LAG_04_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_04_SQRT -> TN_LAG_04_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_04_LOG1P -> TN_LAG_04_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_04_SQ -> TN_DELTA_04_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_04_SQRT -> TN_DELTA_04_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_04_LOG1P -> TN_DELTA_04_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_05_SQ -> TN_LAG_05_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_05_SQRT -> TN_LAG_05_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_05_LOG1P -> TN_LAG_05_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_05_SQ -> TN_DELTA_05_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_05_SQRT -> TN_DELTA_05_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_05_LOG1P -> TN_DELTA_05_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_06_SQ -> TN_LAG_06_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_06_SQRT -> TN_LAG_06_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_06_LOG1P -> TN_LAG_06_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_06_SQ -> TN_DELTA_06_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_06_SQRT -> TN_DELTA_06_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_06_LOG1P -> TN_DELTA_06_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_07_SQ -> TN_LAG_07_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_07_SQRT -> TN_LAG_07_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_07_LOG1P -> TN_LAG_07_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_07_SQ -> TN_DELTA_07_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_07_SQRT -> TN_DELTA_07_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_07_LOG1P -> TN_DELTA_07_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_08_SQ -> TN_LAG_08_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_08_SQRT -> TN_LAG_08_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_08_LOG1P -> TN_LAG_08_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_08_SQ -> TN_DELTA_08_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_08_SQRT -> TN_DELTA_08_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_08_LOG1P -> TN_DELTA_08_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_09_SQ -> TN_LAG_09_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_09_SQRT -> TN_LAG_09_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_09_LOG1P -> TN_LAG_09_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_09_SQ -> TN_DELTA_09_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_09_SQRT -> TN_DELTA_09_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_09_LOG1P -> TN_DELTA_09_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_10_SQ -> TN_LAG_10_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_10_SQRT -> TN_LAG_10_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_10_LOG1P -> TN_LAG_10_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_10_SQ -> TN_DELTA_10_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_10_SQRT -> TN_DELTA_10_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_10_LOG1P -> TN_DELTA_10_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_11_SQ -> TN_LAG_11_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_11_SQRT -> TN_LAG_11_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_11_LOG1P -> TN_LAG_11_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_11_SQ -> TN_DELTA_11_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_11_SQRT -> TN_DELTA_11_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_11_LOG1P -> TN_DELTA_11_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_12_SQ -> TN_LAG_12_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_12_SQRT -> TN_LAG_12_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_12_LOG1P -> TN_LAG_12_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_12_SQ -> TN_DELTA_12_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_12_SQRT -> TN_DELTA_12_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_12_LOG1P -> TN_DELTA_12_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_13_SQ -> TN_LAG_13_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_13_SQRT -> TN_LAG_13_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_13_LOG1P -> TN_LAG_13_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_13_SQ -> TN_DELTA_13_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_13_SQRT -> TN_DELTA_13_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_13_LOG1P -> TN_DELTA_13_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_14_SQ -> TN_LAG_14_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_14_SQRT -> TN_LAG_14_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_14_LOG1P -> TN_LAG_14_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_14_SQ -> TN_DELTA_14_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_14_SQRT -> TN_DELTA_14_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_14_LOG1P -> TN_DELTA_14_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_15_SQ -> TN_LAG_15_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_15_SQRT -> TN_LAG_15_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_15_LOG1P -> TN_LAG_15_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_15_SQ -> TN_DELTA_15_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_15_SQRT -> TN_DELTA_15_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_15_LOG1P -> TN_DELTA_15_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_16_SQ -> TN_LAG_16_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_16_SQRT -> TN_LAG_16_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_16_LOG1P -> TN_LAG_16_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_16_SQ -> TN_DELTA_16_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_16_SQRT -> TN_DELTA_16_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_16_LOG1P -> TN_DELTA_16_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_17_SQ -> TN_LAG_17_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_17_SQRT -> TN_LAG_17_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_17_LOG1P -> TN_LAG_17_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_17_SQ -> TN_DELTA_17_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_17_SQRT -> TN_DELTA_17_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_17_LOG1P -> TN_DELTA_17_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_18_SQ -> TN_LAG_18_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_18_SQRT -> TN_LAG_18_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_18_LOG1P -> TN_LAG_18_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_18_SQ -> TN_DELTA_18_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_18_SQRT -> TN_DELTA_18_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_18_LOG1P -> TN_DELTA_18_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_19_SQ -> TN_LAG_19_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_19_SQRT -> TN_LAG_19_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_19_LOG1P -> TN_LAG_19_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_19_SQ -> TN_DELTA_19_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_19_SQRT -> TN_DELTA_19_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_19_LOG1P -> TN_DELTA_19_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_20_SQ -> TN_LAG_20_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_20_SQRT -> TN_LAG_20_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_20_LOG1P -> TN_LAG_20_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_20_SQ -> TN_DELTA_20_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_20_SQRT -> TN_DELTA_20_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_20_LOG1P -> TN_DELTA_20_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_21_SQ -> TN_LAG_21_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_21_SQRT -> TN_LAG_21_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_21_LOG1P -> TN_LAG_21_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_21_SQ -> TN_DELTA_21_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_21_SQRT -> TN_DELTA_21_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_21_LOG1P -> TN_DELTA_21_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_22_SQ -> TN_LAG_22_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_22_SQRT -> TN_LAG_22_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_22_LOG1P -> TN_LAG_22_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_22_SQ -> TN_DELTA_22_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_22_SQRT -> TN_DELTA_22_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_22_LOG1P -> TN_DELTA_22_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_23_SQ -> TN_LAG_23_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_23_SQRT -> TN_LAG_23_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_23_LOG1P -> TN_LAG_23_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_23_SQ -> TN_DELTA_23_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_23_SQRT -> TN_DELTA_23_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_23_LOG1P -> TN_DELTA_23_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_24_SQ -> TN_LAG_24_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_24_SQRT -> TN_LAG_24_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_24_LOG1P -> TN_LAG_24_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_24_SQ -> TN_DELTA_24_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_24_SQRT -> TN_DELTA_24_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_24_LOG1P -> TN_DELTA_24_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_25_SQ -> TN_LAG_25_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_25_SQRT -> TN_LAG_25_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_25_LOG1P -> TN_LAG_25_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_25_SQ -> TN_DELTA_25_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_25_SQRT -> TN_DELTA_25_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_25_LOG1P -> TN_DELTA_25_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_26_SQ -> TN_LAG_26_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_26_SQRT -> TN_LAG_26_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_26_LOG1P -> TN_LAG_26_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_26_SQ -> TN_DELTA_26_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_26_SQRT -> TN_DELTA_26_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_26_LOG1P -> TN_DELTA_26_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_27_SQ -> TN_LAG_27_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_27_SQRT -> TN_LAG_27_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_27_LOG1P -> TN_LAG_27_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_27_SQ -> TN_DELTA_27_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_27_SQRT -> TN_DELTA_27_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_27_LOG1P -> TN_DELTA_27_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_28_SQ -> TN_LAG_28_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_28_SQRT -> TN_LAG_28_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_28_LOG1P -> TN_LAG_28_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_28_SQ -> TN_DELTA_28_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_28_SQRT -> TN_DELTA_28_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_28_LOG1P -> TN_DELTA_28_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_29_SQ -> TN_LAG_29_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_29_SQRT -> TN_LAG_29_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_29_LOG1P -> TN_LAG_29_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_29_SQ -> TN_DELTA_29_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_29_SQRT -> TN_DELTA_29_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_29_LOG1P -> TN_DELTA_29_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_30_SQ -> TN_LAG_30_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_30_SQRT -> TN_LAG_30_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_30_LOG1P -> TN_LAG_30_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_30_SQ -> TN_DELTA_30_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_30_SQRT -> TN_DELTA_30_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_30_LOG1P -> TN_DELTA_30_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_31_SQ -> TN_LAG_31_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_31_SQRT -> TN_LAG_31_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_31_LOG1P -> TN_LAG_31_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_31_SQ -> TN_DELTA_31_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_31_SQRT -> TN_DELTA_31_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_31_LOG1P -> TN_DELTA_31_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_32_SQ -> TN_LAG_32_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_32_SQRT -> TN_LAG_32_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_32_LOG1P -> TN_LAG_32_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_32_SQ -> TN_DELTA_32_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_32_SQRT -> TN_DELTA_32_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_32_LOG1P -> TN_DELTA_32_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_33_SQ -> TN_LAG_33_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_33_SQRT -> TN_LAG_33_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_33_LOG1P -> TN_LAG_33_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_33_SQ -> TN_DELTA_33_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_33_SQRT -> TN_DELTA_33_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_33_LOG1P -> TN_DELTA_33_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_34_SQ -> TN_LAG_34_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_34_SQRT -> TN_LAG_34_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_34_LOG1P -> TN_LAG_34_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_34_SQ -> TN_DELTA_34_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_34_SQRT -> TN_DELTA_34_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_34_LOG1P -> TN_DELTA_34_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_LAG_35_SQ -> TN_LAG_35_SQ_ZSCORE\n",
      "✅ Normalizando: TN_LAG_35_SQRT -> TN_LAG_35_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_LAG_35_LOG1P -> TN_LAG_35_LOG1P_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_35_SQ -> TN_DELTA_35_SQ_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_35_SQRT -> TN_DELTA_35_SQRT_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_35_LOG1P -> TN_DELTA_35_LOG1P_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_CUST_REQUEST_TN -> CUST_REQUEST_QTY_x_CUST_REQUEST_TN_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN -> CUST_REQUEST_QTY_x_TN_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_LAG_01 -> CUST_REQUEST_QTY_x_TN_LAG_01_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_DELTA_01 -> CUST_REQUEST_QTY_x_TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_LAG_02 -> CUST_REQUEST_QTY_x_TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_DELTA_02 -> CUST_REQUEST_QTY_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_LAG_03 -> CUST_REQUEST_QTY_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_DELTA_03 -> CUST_REQUEST_QTY_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_QTY_x_TN_LAG_04 -> CUST_REQUEST_QTY_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN -> CUST_REQUEST_TN_x_TN_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_LAG_01 -> CUST_REQUEST_TN_x_TN_LAG_01_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_DELTA_01 -> CUST_REQUEST_TN_x_TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_LAG_02 -> CUST_REQUEST_TN_x_TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_DELTA_02 -> CUST_REQUEST_TN_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_LAG_03 -> CUST_REQUEST_TN_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_DELTA_03 -> CUST_REQUEST_TN_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: CUST_REQUEST_TN_x_TN_LAG_04 -> CUST_REQUEST_TN_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_LAG_01 -> TN_x_TN_LAG_01_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_DELTA_01 -> TN_x_TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_LAG_02 -> TN_x_TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_DELTA_02 -> TN_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_LAG_03 -> TN_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_DELTA_03 -> TN_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_x_TN_LAG_04 -> TN_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_DELTA_01 -> TN_LAG_01_x_TN_DELTA_01_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_LAG_02 -> TN_LAG_01_x_TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_DELTA_02 -> TN_LAG_01_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_LAG_03 -> TN_LAG_01_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_DELTA_03 -> TN_LAG_01_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_01_x_TN_LAG_04 -> TN_LAG_01_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_x_TN_LAG_02 -> TN_DELTA_01_x_TN_LAG_02_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_x_TN_DELTA_02 -> TN_DELTA_01_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_x_TN_LAG_03 -> TN_DELTA_01_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_x_TN_DELTA_03 -> TN_DELTA_01_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_01_x_TN_LAG_04 -> TN_DELTA_01_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_x_TN_DELTA_02 -> TN_LAG_02_x_TN_DELTA_02_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_x_TN_LAG_03 -> TN_LAG_02_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_x_TN_DELTA_03 -> TN_LAG_02_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_02_x_TN_LAG_04 -> TN_LAG_02_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_x_TN_LAG_03 -> TN_DELTA_02_x_TN_LAG_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_x_TN_DELTA_03 -> TN_DELTA_02_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_02_x_TN_LAG_04 -> TN_DELTA_02_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03_x_TN_DELTA_03 -> TN_LAG_03_x_TN_DELTA_03_ZSCORE\n",
      "✅ Normalizando: TN_LAG_03_x_TN_LAG_04 -> TN_LAG_03_x_TN_LAG_04_ZSCORE\n",
      "✅ Normalizando: TN_DELTA_03_x_TN_LAG_04 -> TN_DELTA_03_x_TN_LAG_04_ZSCORE\n"
     ]
    }
   ],
   "source": [
    "df_full = normalizar_zscore_con_join(\n",
    "    df_full=df_full,\n",
    "    medias_y_desvios=medias_y_desvios,\n",
    "    columnas_a_normalizar=columnas_a_normalizar,\n",
    "    conservar_auxiliares=False,\n",
    "    epsilon=1e-6,\n",
    "    clip_value=5.0,\n",
    "    agregar_clip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeee3f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardo el DataFrame resultante de medias y desvios en un archivo parquet para utilizarlo en el futuro\n",
    "# (esto es útil para no tener que recalcularlo cada vez)\n",
    "# y para que otros scripts puedan usarlo sin recalcularlo.\n",
    "# Libero memoria de medias_y_desvios \n",
    "medias_y_desvios_pd = medias_y_desvios.to_pandas()\n",
    "medias_y_desvios_pd.to_parquet('./data/medias_y_desvios.parquet', engine='fastparquet', index=False)\n",
    "del medias_y_desvios_pd, medias_y_desvios\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "449684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas originales de df_full que fueron normalizadas\n",
    "# son las que están en columnas_a_normalizar\n",
    "df_full = df_full.drop(columnas_a_normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f03e51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir de nuevo a DataFrame de Pandas\n",
    "df_full = df_full.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80495a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = optimizar_memoria(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf3e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_y_eliminar_df(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e39b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full= recargar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cálculo de features por grupo ---\n",
    "def calcular_pendientes_grupo(group, periodos_list):\n",
    "    group = group.sort_values(by='PERIODO').copy()\n",
    "    n = len(group)\n",
    "    y_series = pd.Series(group['TN_ZSCORE'].values)\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for cant in periodos_list:\n",
    "        x = np.arange(cant)\n",
    "        rolling = y_series.rolling(window=cant, min_periods=1)\n",
    "\n",
    "        # Medidas estadísticas\n",
    "        mean_vals = rolling.mean().values\n",
    "        std_vals = rolling.std().values\n",
    "        median_vals = rolling.median().values\n",
    "        min_vals = rolling.min().values\n",
    "        max_vals = rolling.max().values\n",
    "        ewma_vals = y_series.ewm(span=cant, adjust=False).mean().values\n",
    "\n",
    "        new_cols[f'TN_MEAN_ZSCORE_{cant}'] = mean_vals\n",
    "        new_cols[f'TN_STD_ZSCORE_{cant}'] = std_vals\n",
    "        new_cols[f'TN_MEDIAN_ZSCORE_{str(cant).zfill(2)}'] = median_vals\n",
    "        new_cols[f'TN_MIN_ZSCORE_{str(cant).zfill(2)}'] = min_vals\n",
    "        new_cols[f'TN_MAX_ZSCORE_{str(cant).zfill(2)}'] = max_vals\n",
    "        new_cols[f'TN_EWMA_ZSCORE_{str(cant).zfill(2)}'] = ewma_vals\n",
    "\n",
    "        # Pendiente de regresión lineal\n",
    "        if n >= cant:\n",
    "            y_rolling = np.lib.stride_tricks.sliding_window_view(y_series.values, window_shape=cant)\n",
    "            X = np.vstack([x, np.ones(cant)]).T\n",
    "            XTX_inv_XT = np.linalg.pinv(X)\n",
    "            betas = XTX_inv_XT @ y_rolling.T\n",
    "            pendientes = np.full(n, np.nan)\n",
    "            pendientes[cant - 1:] = betas[0]\n",
    "        else:\n",
    "            pendientes = np.full(n, np.nan)\n",
    "        new_cols[f'PENDIENTE_TENDENCIA_ZSCORE_{cant}'] = pendientes\n",
    "\n",
    "        # Medidas de variabilidad respecto a la media\n",
    "        abs_diff = np.abs(y_series.values - mean_vals)\n",
    "        cv_vals = std_vals / np.where(mean_vals == 0, np.nan, mean_vals)\n",
    "\n",
    "        new_cols[f'TN_ABS_DIFF_MEAN_ZSCORE_{cant}'] = abs_diff\n",
    "        new_cols[f'TN_CV_ZSCORE_{cant}'] = cv_vals\n",
    "\n",
    "    df_features = pd.DataFrame(new_cols, index=group.index)\n",
    "    group = pd.concat([group, df_features], axis=1)\n",
    "    return group\n",
    "\n",
    "# --- Procesar un chunk de grupos ---\n",
    "def procesar_chunk(chunk, periodos_list):\n",
    "    return pd.concat([calcular_pendientes_grupo(g, periodos_list) for g in chunk], ignore_index=True)\n",
    "\n",
    "# --- Paralelización eficiente ---\n",
    "def calcular_pendientes_parallel_optimizado(df, periodos_list, n_jobs=28, chunk_size=100):\n",
    "    df = df.copy()  # conserva todas las columnas originales\n",
    "    grupos = [group for _, group in df.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])]\n",
    "    chunks = list(chunked(grupos, chunk_size))\n",
    "\n",
    "    resultados = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
    "        delayed(procesar_chunk)(chunk, periodos_list) for chunk in chunks\n",
    "    )\n",
    "\n",
    "    df_final = pd.concat(resultados, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "# --- Script principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    df_full = calcular_pendientes_parallel_optimizado(\n",
    "        df_full,\n",
    "        periodos_list=[2, 3, 6, 9, 12, 13, 15, 18],\n",
    "        n_jobs=28,\n",
    "        chunk_size=200\n",
    "    )\n",
    "\n",
    "    print(f\"Tiempo total: {time.time() - start:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adf11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral: proporción máxima permitida (ej. 0.4 = 40%)\n",
    "umbral_faltantes = 0.8\n",
    "\n",
    "# Diccionario para almacenar estadísticas\n",
    "estadisticas_columnas = []\n",
    "\n",
    "# Recorremos las columnas del DataFrame\n",
    "for col in df_full.columns:\n",
    "    total = len(df_full[col])\n",
    "    nulls = df_full[col].isnull().sum()\n",
    "    nans = df_full[col].isna().sum()\n",
    "    infs = np.isinf(df_full[col]).sum()\n",
    "    \n",
    "    total_faltantes = nulls + infs  # NaN está incluido en nulls/isna\n",
    "    \n",
    "    porcentaje = total_faltantes / total\n",
    "    \n",
    "    estadisticas_columnas.append({\n",
    "        'columna': col,\n",
    "        'nulls': nulls,\n",
    "        'NaNs': nans,\n",
    "        'infs': infs,\n",
    "        'porcentaje_faltantes': porcentaje\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_faltantes = pd.DataFrame(estadisticas_columnas)\n",
    "\n",
    "# Filtrar columnas que superen el umbral\n",
    "columnas_a_eliminar = df_faltantes[df_faltantes['porcentaje_faltantes'] > umbral_faltantes]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(f\"\\nSe eliminarán {len(columnas_a_eliminar)} columnas con más del {umbral_faltantes*100:.0f}% de valores faltantes o infinitos:\")\n",
    "for _, row in columnas_a_eliminar.iterrows():\n",
    "    print(f\"- {row['columna']}: {row['porcentaje_faltantes']*100:.2f}% (nulls={row['nulls']}, infs={row['infs']})\")\n",
    "\n",
    "# Eliminar columnas del DataFrame\n",
    "df_full = df_full.drop(columns=columnas_a_eliminar['columna'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_resultado una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_full['MES_PROBLEMATICO'] = df_full['PERIODO'].apply(lambda x: True if x in [201906, 201908] else False)\n",
    "df_full['PLAN_PRECIOS_CUIDADOS'] = df_full['PLAN_PRECIOS_CUIDADOS'].map({1 : True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame resultante en un archivo parquet\n",
    "df_full.to_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
