{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fb8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\NeuralProphet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5880116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_28572\\2628659266.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n",
      "   PERIODO  CUSTOMER_ID  PRODUCT_ID    CLASE\n",
      "0   201701        10348       20654  0.00253\n",
      "1   201701        10223       20654  0.00760\n",
      "2   201701        10392       20654  0.00000\n",
      "3   201701        10082       20654  0.00000\n",
      "4   201701        10416       20654  0.00317\n",
      "PERIODO          int64\n",
      "CUSTOMER_ID      int64\n",
      "PRODUCT_ID       int64\n",
      "CLASE          float64\n",
      "dtype: object\n",
      "Número de filas: 100000, Número de columnas: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select periodo,customer_id,product_id,clase from L_DATOS_ENTRENAMIENTO where rownum <= 100000\"\n",
    "df = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_full = pd.concat(df, ignore_index=True)\n",
    "conn.close()\n",
    "print(df_full.shape)\n",
    "# Imprimir las primeras filas del DataFrame completo\n",
    "print(df_full.head())\n",
    "# Imprimir los tipos de datos de las columnas del DataFrame completo\n",
    "print(df_full.dtypes)\n",
    "# Imprimir el número de filas y columnas del DataFrame completo\n",
    "print(f\"Número de filas: {df_full.shape[0]}, Número de columnas: {df_full.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [50.]% of the data.\n",
      "WARNING - (NP.df_utils._infer_frequency) - Dataframe has multiple frequencies. It will be resampled according to given freq MS. Ignore message if actual frequency is any of the following:  SM, BM, CBM, SMS, BMS, CBMS, BQ, BQS, BA, or, BAS.\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 2\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 1000\n",
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (1) is too small than the required number for the learning rate finder (200). The results might not be optimal.\n",
      "Finding best initial lr: 100%|██████████| 200/200 [00:01<00:00, 197.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: 100%|██████████| 1000/1000 [00:00<00:00, 66526.62it/s, loss=1.2e-07, v_num=2, MAE=0.0438, RMSE=0.0541, Loss=1.2e-7, RegLoss=0.000]  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuralProphet' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(df_prophet, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'MS' para inicio de mes\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Guardar el modelo entrenado\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelo_neuralprophet.np\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo NeuralProphet entrenado y guardado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralProphet' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Preprocesar para NeuralProphet: seleccionar una serie temporal (por ejemplo, por customer_id y product_id)\n",
    "# Seleccionamos una combinación de CUSTOMER_ID y PRODUCT_ID que tenga varias filas\n",
    "example = df_full.groupby(['CUSTOMER_ID', 'PRODUCT_ID']).size().reset_index(name='count')\n",
    "example = example[example['count'] > 1].iloc[0]\n",
    "customer_id = example['CUSTOMER_ID']\n",
    "product_id = example['PRODUCT_ID']\n",
    "\n",
    "# Filtramos la serie temporal para esa combinación\n",
    "df_prophet = df_full[(df_full['CUSTOMER_ID'] == customer_id) & (df_full['PRODUCT_ID'] == product_id)][['PERIODO', 'CLASE']]\n",
    "df_prophet = df_prophet.rename(columns={'PERIODO': 'ds', 'CLASE': 'y'})\n",
    "\n",
    "# Si 'ds' es numérico, conviértelo a string o fecha si corresponde\n",
    "df_prophet['ds'] = pd.to_datetime(df_prophet['ds'].astype(str), format='%Y%m')\n",
    "\n",
    "# Entrenar el modelo NeuralProphet\n",
    "model = NeuralProphet()\n",
    "metrics = model.fit(df_prophet, freq='MS')  # 'MS' para inicio de mes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e241eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Guardar solo los pesos y parámetros del modelo\n",
    "torch.save(model.state_dict(), \"modelo_neuralprophet_state.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6453469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcablinski.RWD\\AppData\\Local\\Temp\\ipykernel_187824\\3968896330.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n"
     ]
    }
   ],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from L_DATOS_PREDICCION\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_pred_full = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89f9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERIODO  PRODUCT_ID  CUSTOMER_ID  TN_PREDICCION  PREDICCIONES\n",
      "0   201912       20003        10001     132.089004    135.909964\n",
      "1   201912       20027        10001      14.894868     16.940604\n",
      "2   201912       20059        10001      10.696551     15.218868\n",
      "3   201912       20063        10001      10.437913     12.136348\n",
      "4   201912       20074        10001       9.246648     10.172317\n",
      "Número de filas: 333840, Número de columnas: 5 con predicciones.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1c5075fc6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con el modelo entrenado, hacemos predicciones \n",
    "X_pred = df_pred_full[['PERIODO', 'CUSTOMER_ID', 'PRODUCT_ID']]\n",
    "predictions = model.predict(X_pred)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['PREDICCIONES'] = predictions\n",
    "# Imprimir las primeras filas del DataFrame con las predicciones\n",
    "print(df_pred_full.head())\n",
    "# Guardar el DataFrame con las predicciones en un archivo CSV\n",
    "df_pred_full.to_csv('predicciones.csv', index=False)\n",
    "# Imprimir el número de filas y columnas del DataFrame con las predicciones\n",
    "print(f\"Número de filas: {df_pred_full.shape[0]}, Número de columnas: {df_pred_full.shape[1]} con predicciones.\")\n",
    "# Guardar el modelo entrenado\n",
    "model.save_model('modelo_regresion.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2f8352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualizadas 0 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 10000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 20000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 30000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 40000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 50000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 60000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 70000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 80000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 90000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 100000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 110000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 120000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 130000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 140000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 150000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 160000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 170000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 180000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 190000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 200000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 210000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 220000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 230000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 240000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 250000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 260000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 270000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 280000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 290000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 300000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 310000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 320000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 330000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualización de la tabla L_DATOS_PREDICCION completada con las nuevas predicciones.\n"
     ]
    }
   ],
   "source": [
    "# Con el DataFrame de predicción, actualizamos la base de datos\n",
    "# el criterio es actualizar la tabla L_DATOS_PREDICCION con las nuevas predicciones\n",
    "# la columnna PREDICCIONES se debe actualizar con los nuevos valores\n",
    "# la clave primaria es (PERIODO, CUSTOMER_ID, PRODUCT_ID)\n",
    "# Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "\n",
    "# Conectar a la base de datos para actualizar los datos de predicción\n",
    "conn = cx_Oracle.connect(user=\"pc\", password=\"p201404\", dsn=\"siatchdesa\")\n",
    "# Crear un cursor para ejecutar las actualizaciones\n",
    "cursor = conn.cursor()\n",
    "# Iterar sobre las filas del DataFrame con las predicciones\n",
    "for index, row in df_pred_full.iterrows():\n",
    "    periodo = row['PERIODO']\n",
    "    customer_id = row['CUSTOMER_ID']\n",
    "    product_id = row['PRODUCT_ID']\n",
    "    prediccion = row['PREDICCIONES']\n",
    "    \n",
    "    # Actualizar la tabla L_DATOS_PREDICCION con la nueva predicción\n",
    "    update_query = \"\"\"\n",
    "        UPDATE L_DATOS_PREDICCION\n",
    "        SET TN_PREDICCION = :prediccion\n",
    "        WHERE PERIODO = :periodo AND CUSTOMER_ID = :customer_id AND PRODUCT_ID = :product_id\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, {'prediccion': prediccion, 'periodo': periodo, 'customer_id': customer_id, 'product_id': product_id})  \n",
    "    # Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "    if index % 10000 == 0:\n",
    "        conn.commit()\n",
    "        print(f\"Actualizadas {index} filas de L_DATOS_PREDICCION con las nuevas predicciones.\")\n",
    "# Confirmar los cambios en la base de datos\n",
    "conn.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "# Imprimir mensaje de finalización\n",
    "print(\"Actualización de la tabla L_DATOS_PREDICCION completada con las nuevas predicciones.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralProphet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
