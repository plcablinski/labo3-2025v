{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1dd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar de df_full las filas donde la columna A_PREDECIR sea 'N'\n",
    "#df_resultado['A_PREDECIR'] = df_resultado['A_PREDECIR'].map({'S': True, 'N': False})\n",
    "df_full = df_full[df_full['A_PREDECIR'] != 'N']\n",
    "# Eliminar de df_full la columna A_PREDECIR\n",
    "df_full = df_full.drop(columns=['A_PREDECIR'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservar las siguientes columnas\n",
    "columns_to_keep = ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1',\n",
    "       'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID',\n",
    "       'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY',\n",
    "       'CUST_REQUEST_TN', 'TN', 'STOCK_FINAL', 'TN_LAG_01', 'TN_LAG_02',\n",
    "       'TN_LAG_03', 'TN_LAG_04', 'TN_LAG_05', 'TN_LAG_06', 'TN_LAG_07',\n",
    "       'TN_LAG_08', 'TN_LAG_09', 'TN_LAG_10', 'TN_LAG_11', 'TN_LAG_12',\n",
    "       'TN_LAG_13', 'TN_LAG_14', 'TN_LAG_15', 'CLASE', 'CLASE_DELTA',\n",
    "       'ORDINAL', 'TN_DELTA_01', 'TN_DELTA_02', 'TN_DELTA_03', 'TN_DELTA_04',\n",
    "       'TN_DELTA_05', 'TN_DELTA_06', 'TN_DELTA_07', 'TN_DELTA_08',\n",
    "       'TN_DELTA_09', 'TN_DELTA_10', 'TN_DELTA_11', 'TN_DELTA_12',\n",
    "       'TN_DELTA_13', 'TN_DELTA_14', 'TN_DELTA_15', 'ANTIG_CLIENTE',\n",
    "       'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER', 'A_PREDECIR']\n",
    "# Filtrar el DataFrame para conservar solo las columnas deseadas y el periodo hasta 201910\n",
    "df_full = df_full[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un DataFrame de Polars\n",
    "df_full = pl.from_pandas(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamiento y cálculo de media y desvío SOLO para TN\n",
    "group_stats = (\n",
    "    df_full.group_by([\"CUSTOMER_ID\", \"PRODUCT_ID\"])\n",
    "    .agg([\n",
    "        pl.col(\"TN\").mean().alias(\"TN_MEAN\"),\n",
    "        pl.col(\"TN\").std().alias(\"TN_STD\")\n",
    "    ])\n",
    ")\n",
    "# Agrupamiento y cálculo de media y desvío SOLO para CLASE_DELTA\n",
    "group_stats_clase = (\n",
    "    df_full.group_by([\"CUSTOMER_ID\", \"PRODUCT_ID\"])\n",
    "    .agg([\n",
    "        pl.col(\"CLASE_DELTA\").mean().alias(\"CLASE_DELTA_MEAN\"),\n",
    "        pl.col(\"CLASE_DELTA\").std().alias(\"CLASE_DELTA_STD\")\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lo mismo para CLASE_DELTA usando group_stats_clase y CLASE_DELTA_MEAN y CLASE_DELTA_STD\n",
    "df_norm = (df_full\n",
    "    .join(group_stats_clase, on=[\"CUSTOMER_ID\", \"PRODUCT_ID\"], how=\"left\")\n",
    "    .with_columns([\n",
    "        # CLASE_DELTA Z-Scores usando CLASE_DELTA_MEAN y CLASE_DELTA_STD\n",
    "        pl.when(pl.col(\"CLASE_DELTA_STD\") > 0)\n",
    "        .then((pl.col(\"CLASE_DELTA\") - pl.col(\"CLASE_DELTA_MEAN\")) / pl.col(\"CLASE_DELTA_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CLASE_DELTA_ZSCORE\"),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acce7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join con el DataFrame original y cálculo de TODOS los Z-Scores usando TN_MEAN y TN_STD\n",
    "df_norm = (df_norm\n",
    "    .join(group_stats, on=[\"CUSTOMER_ID\", \"PRODUCT_ID\"], how=\"left\")\n",
    "    .with_columns([\n",
    "        # TN_ZSCORE\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_ZSCORE\"),\n",
    "        \n",
    "        # CUST_REQUEST_TN_ZSCORE usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"CUST_REQUEST_TN\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CUST_REQUEST_TN_ZSCORE\"),\n",
    "        \n",
    "        # TN_LAG Z-Scores (1-15) usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_01\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_01_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_02\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_02_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_03\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_03_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_04\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_04_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_05\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_05_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_06\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_06_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_07\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_07_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_08\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_08_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_09\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_09_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_10\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_10_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_11\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_11_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_12\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_12_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_13\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_13_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_14\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_14_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_15\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_15_ZSCORE\"),\n",
    "        \n",
    "        # CLASE y CLASE_DELTA Z-Scores usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"CLASE\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CLASE_ZSCORE\"),\n",
    "\n",
    "        # TN_DELTA Z-Scores (1-15) usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_01\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_01_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_02\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_02_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_03\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_03_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_04\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_04_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_05\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_05_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_06\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_06_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_07\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_07_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_08\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_08_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_09\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_09_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_10\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_10_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_11\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_11_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_12\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_12_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_13\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_13_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_14\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_14_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_15\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_15_ZSCORE\"),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de todas las columnas Z-Score para aplicar las correcciones\n",
    "zscore_columns = [\n",
    "    \"TN_ZSCORE\", \"CUST_REQUEST_TN_ZSCORE\",\n",
    "    \"TN_LAG_01_ZSCORE\", \"TN_LAG_02_ZSCORE\", \"TN_LAG_03_ZSCORE\", \"TN_LAG_04_ZSCORE\", \"TN_LAG_05_ZSCORE\",\n",
    "    \"TN_LAG_06_ZSCORE\", \"TN_LAG_07_ZSCORE\", \"TN_LAG_08_ZSCORE\", \"TN_LAG_09_ZSCORE\", \"TN_LAG_10_ZSCORE\",\n",
    "    \"TN_LAG_11_ZSCORE\", \"TN_LAG_12_ZSCORE\", \"TN_LAG_13_ZSCORE\", \"TN_LAG_14_ZSCORE\", \"TN_LAG_15_ZSCORE\",\n",
    "    \"CLASE_ZSCORE\", \"CLASE_DELTA_ZSCORE\",\n",
    "    \"TN_DELTA_01_ZSCORE\", \"TN_DELTA_02_ZSCORE\", \"TN_DELTA_03_ZSCORE\", \"TN_DELTA_04_ZSCORE\", \"TN_DELTA_05_ZSCORE\",\n",
    "    \"TN_DELTA_06_ZSCORE\", \"TN_DELTA_07_ZSCORE\", \"TN_DELTA_08_ZSCORE\", \"TN_DELTA_09_ZSCORE\", \"TN_DELTA_10_ZSCORE\",\n",
    "    \"TN_DELTA_11_ZSCORE\", \"TN_DELTA_12_ZSCORE\", \"TN_DELTA_13_ZSCORE\", \"TN_DELTA_14_ZSCORE\", \"TN_DELTA_15_ZSCORE\",  \n",
    "]\n",
    "\n",
    "# Aplicar correcciones para null, NaN e infinito a todas las columnas Z-Score\n",
    "for col in zscore_columns:\n",
    "    df_norm = df_norm.with_columns([\n",
    "        pl.when(pl.col(col).is_null() | pl.col(col).is_nan() | pl.col(col).is_infinite())\n",
    "        .then(0)\n",
    "        .otherwise(pl.col(col))\n",
    "        .alias(col)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas originales para las que se calcularon los Z-Scores\n",
    "df_norm = df_norm.drop([\"TN\", \"CUST_REQUEST_TN\",     \n",
    "    \"TN_LAG_01\", \"TN_LAG_02\", \"TN_LAG_03\", \"TN_LAG_04\", \"TN_LAG_05\",\n",
    "    \"TN_LAG_06\", \"TN_LAG_07\", \"TN_LAG_08\", \"TN_LAG_09\", \"TN_LAG_10\",\n",
    "    \"TN_LAG_11\", \"TN_LAG_12\", \"TN_LAG_13\", \"TN_LAG_14\", \"TN_LAG_15\",\n",
    "    \"CLASE\", \"CLASE_DELTA\",\n",
    "    \"TN_DELTA_01\", \"TN_DELTA_02\", \"TN_DELTA_03\", \"TN_DELTA_04\", \"TN_DELTA_05\",\n",
    "    \"TN_DELTA_06\", \"TN_DELTA_07\", \"TN_DELTA_08\", \"TN_DELTA_09\", \"TN_DELTA_10\",\n",
    "    \"TN_DELTA_11\", \"TN_DELTA_12\", \"TN_DELTA_13\", \"TN_DELTA_14\", \"TN_DELTA_15\"\n",
    "])\n",
    "\n",
    "# Convertir de nuevo a DataFrame de Pandas\n",
    "df_norm = df_norm.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full, group_stats, group_stats_clase\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cálculo de features por grupo ---\n",
    "def calcular_pendientes_grupo(group, periodos_list):\n",
    "    group = group.sort_values(by='PERIODO').copy()\n",
    "    n = len(group)\n",
    "    y_series = pd.Series(group['TN_ZSCORE'].values)\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for cant in periodos_list:\n",
    "        x = np.arange(cant)\n",
    "        rolling = y_series.rolling(window=cant)\n",
    "\n",
    "        # Medidas estadísticas\n",
    "        mean_vals = rolling.mean().values\n",
    "        std_vals = rolling.std().values\n",
    "        median_vals = rolling.median().values\n",
    "        min_vals = rolling.min().values\n",
    "        max_vals = rolling.max().values\n",
    "        ewma_vals = y_series.ewm(span=cant, adjust=False).mean().values\n",
    "\n",
    "        new_cols[f'TN_MEAN_ZSCORE_{cant}'] = mean_vals\n",
    "        new_cols[f'TN_STD_ZSCORE_{cant}'] = std_vals\n",
    "        new_cols[f'TN_MEDIAN_ZSCORE_{str(cant).zfill(2)}'] = median_vals\n",
    "        new_cols[f'TN_MIN_ZSCORE_{str(cant).zfill(2)}'] = min_vals\n",
    "        new_cols[f'TN_MAX_ZSCORE_{str(cant).zfill(2)}'] = max_vals\n",
    "        new_cols[f'TN_EWMA_ZSCORE_{str(cant).zfill(2)}'] = ewma_vals\n",
    "\n",
    "        # Pendiente de regresión lineal\n",
    "        if n >= cant:\n",
    "            y_rolling = np.lib.stride_tricks.sliding_window_view(y_series.values, window_shape=cant)\n",
    "            X = np.vstack([x, np.ones(cant)]).T\n",
    "            XTX_inv_XT = np.linalg.pinv(X)\n",
    "            betas = XTX_inv_XT @ y_rolling.T\n",
    "            pendientes = np.full(n, np.nan)\n",
    "            pendientes[cant - 1:] = betas[0]\n",
    "        else:\n",
    "            pendientes = np.full(n, np.nan)\n",
    "        new_cols[f'PENDIENTE_TENDENCIA_ZSCORE_{cant}'] = pendientes\n",
    "\n",
    "        # Medidas de variabilidad respecto a la media\n",
    "        abs_diff = np.abs(y_series.values - mean_vals)\n",
    "        residuals = y_series.values - mean_vals\n",
    "        res_std = pd.Series(residuals).rolling(window=cant).std().values\n",
    "        cv_vals = std_vals / np.where(mean_vals == 0, np.nan, mean_vals)\n",
    "\n",
    "        new_cols[f'TN_ABS_DIFF_MEAN_ZSCORE_{cant}'] = abs_diff\n",
    "        new_cols[f'TN_RESIDUAL_STD_ZSCORE_{cant}'] = res_std\n",
    "        new_cols[f'TN_CV_ZSCORE_{cant}'] = cv_vals\n",
    "\n",
    "    df_features = pd.DataFrame(new_cols, index=group.index)\n",
    "    group = pd.concat([group, df_features], axis=1)\n",
    "    return group\n",
    "\n",
    "# --- Procesar un chunk de grupos ---\n",
    "def procesar_chunk(chunk, periodos_list):\n",
    "    return pd.concat([calcular_pendientes_grupo(g, periodos_list) for g in chunk], ignore_index=True)\n",
    "\n",
    "# --- Paralelización eficiente ---\n",
    "def calcular_pendientes_parallel_optimizado(df, periodos_list, n_jobs=28, chunk_size=100):\n",
    "    df = df.copy()  # conserva todas las columnas originales\n",
    "    grupos = [group for _, group in df.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])]\n",
    "    chunks = list(chunked(grupos, chunk_size))\n",
    "\n",
    "    resultados = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
    "        delayed(procesar_chunk)(chunk, periodos_list) for chunk in chunks\n",
    "    )\n",
    "\n",
    "    df_final = pd.concat(resultados, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "# --- Script principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    df_resultado = calcular_pendientes_parallel_optimizado(\n",
    "        df_norm,\n",
    "        periodos_list=[2, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 34],\n",
    "        n_jobs=28,\n",
    "        chunk_size=200\n",
    "    )\n",
    "\n",
    "    print(f\"Tiempo total: {time.time() - start:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145acd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_norm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_resultado una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_resultado['MES_PROBLEMATICO'] = df_resultado['PERIODO'].apply(lambda x: True if x in [201906, 201908] else False)\n",
    "df_resultado['PLAN_PRECIOS_CUIDADOS'] = df_resultado['PLAN_PRECIOS_CUIDADOS'].map({1 : True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizar tipos de datos numéricos\n",
    "for col in df_resultado.select_dtypes(include=['int64']).columns:\n",
    "    df_resultado[col] = pd.to_numeric(df_resultado[col], downcast='integer')\n",
    "for col in df_resultado.select_dtypes(include=['float64']).columns:\n",
    "    df_resultado[col] = pd.to_numeric(df_resultado[col], downcast='float')\n",
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame resultante en un archivo parquet\n",
    "df_resultado.to_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
