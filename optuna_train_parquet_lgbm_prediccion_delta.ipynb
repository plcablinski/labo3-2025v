{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f2f3c0",
   "metadata": {},
   "source": [
    "params = {}\n",
    "# Train the model with sample weights\n",
    "model = lgb.train(params, train_data, valid_sets=[test_data], sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d6f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/envs/LaboIII/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca73795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de df_full después de la unión con df_pendientes:\n",
      "['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1', 'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID', 'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY', 'CUST_REQUEST_TN', 'TN', 'STOCK_FINAL', 'MEDIA_MOVIL_3M_CLI_PROD', 'MEDIA_MOVIL_6M_CLI_PROD', 'MEDIA_MOVIL_12M_CLI_PROD', 'DESVIO_MOVIL_3M_CLI_PROD', 'DESVIO_MOVIL_6M_CLI_PROD', 'DESVIO_MOVIL_12M_CLI_PROD', 'MEDIA_MOVIL_3M_PROD', 'MEDIA_MOVIL_6M_PROD', 'MEDIA_MOVIL_12M_PROD', 'DESVIO_MOVIL_3M_PROD', 'DESVIO_MOVIL_6M_PROD', 'DESVIO_MOVIL_12M_PROD', 'MEDIA_MOVIL_3M_CLI', 'MEDIA_MOVIL_6M_CLI', 'MEDIA_MOVIL_12M_CLI', 'DESVIO_MOVIL_3M_CLI', 'DESVIO_MOVIL_6M_CLI', 'DESVIO_MOVIL_12M_CLI', 'TN_LAG_01', 'TN_LAG_02', 'TN_LAG_03', 'TN_LAG_04', 'TN_LAG_05', 'TN_LAG_06', 'TN_LAG_07', 'TN_LAG_08', 'TN_LAG_09', 'TN_LAG_10', 'TN_LAG_11', 'TN_LAG_12', 'TN_LAG_13', 'TN_LAG_14', 'TN_LAG_15', 'CLASE', 'CLASE_DELTA', 'ORDINAL', 'TN_DELTA_01', 'TN_DELTA_02', 'TN_DELTA_03', 'TN_DELTA_04', 'TN_DELTA_05', 'TN_DELTA_06', 'TN_DELTA_07', 'TN_DELTA_08', 'TN_DELTA_09', 'TN_DELTA_10', 'TN_DELTA_11', 'TN_DELTA_12', 'TN_DELTA_13', 'TN_DELTA_14', 'TN_DELTA_15', 'ANTIG_CLIENTE', 'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER', 'MEDIA_PROD_PER', 'MEDIA_PROD', 'MEDIA_PER', 'A_PREDECIR', 'PENDIENTE_TENDENCIA_3', 'TN_EWMA_03', 'TN_MEDIAN_03', 'TN_MIN_03', 'TN_MAX_03', 'PENDIENTE_TENDENCIA_6', 'TN_EWMA_06', 'TN_MEDIAN_06', 'TN_MIN_06', 'TN_MAX_06', 'PENDIENTE_TENDENCIA_9', 'TN_EWMA_09', 'TN_MEDIAN_09', 'TN_MIN_09', 'TN_MAX_09', 'PENDIENTE_TENDENCIA_12', 'TN_EWMA_12', 'TN_MEDIAN_12', 'TN_MIN_12', 'TN_MAX_12']\n"
     ]
    }
   ],
   "source": [
    "# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet\n",
    "df_pendientes = pd.read_parquet('./data/l_vm_completa_train_pendientes.parquet', engine='fastparquet')\n",
    "# Reunir los DataFrames df_full y df_pendientes por PRODUCT_ID, CUSTOMER_ID y PERIODO, agregar las \n",
    "# columnas de df_pendientes a df_full\n",
    "df_full = df_full.merge(df_pendientes, on=['PRODUCT_ID', 'CUSTOMER_ID', 'PERIODO'], how='left', suffixes=('', '_features'))\n",
    "# Imprimir las columnas de df_full\n",
    "print(\"Columnas de df_full después de la unión con df_pendientes:\")\n",
    "print(df_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2661c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_full una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_full['MES_PROBLEMATICO'] = df_full['PERIODO'].apply(lambda x: 1 if x in [201906, 201908] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e06b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "# Variables categóricas\n",
    "# categorical_features = ['ANIO','MES','TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','CUSTOMER_ID','PRODUCT_ID','PLAN_PRECIOS_CUIDADOS']\n",
    "categorical_features = ['ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','PLAN_PRECIOS_CUIDADOS','MES_PROBLEMATICO']\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_full[col] = df_full[col].astype('category')\n",
    "# Hacer que A_PREDECIR sea boolean si es 'S' vale True, si es 'N' False\n",
    "df_full['A_PREDECIR'] = df_full['A_PREDECIR'].map({'S': True, 'N': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e06cb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables predictoras y objetivo\n",
    "# filtrar que en X el periodo sea menor o igual a 201910\n",
    "# En x eliminar la columna 'CLASE' y 'CLASE_DELTA'\n",
    "X = df_full[df_full['PERIODO'] <= 201910].drop(columns=['CLASE', 'CLASE_DELTA']) \n",
    "# Filtrar en y que el periodo sea menor o igual a 201910\n",
    "y = df_full[df_full['PERIODO'] <= 201910]['CLASE_DELTA']\n",
    "# Eliminar df_full para liberar memoria\n",
    "del df_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec1811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los periodos de validación 201910\n",
    "#periodos_valid = [201910]\n",
    "periodos_valid = [201910]\n",
    "\n",
    "# Separar train y cinco conjuntos de validación respetando la secuencia temporal\n",
    "X_train = X[X['PERIODO'] < periodos_valid[0]]\n",
    "y_train = y[X['PERIODO'] < periodos_valid[0]]\n",
    "X_val_list = [X[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_val_list = [y[X['PERIODO'] == p] for p in periodos_valid]\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe33b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15346065, 95)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a403e26",
   "metadata": {},
   "source": [
    "## Optimización con Linear Trees\n",
    "\n",
    "Se ha incluido el parámetro `linear_tree` en la optimización de hiperparámetros:\n",
    "\n",
    "### ¿Qué es `linear_tree`?\n",
    "- **Función**: Ajusta modelos de regresión lineal en las hojas de los árboles en lugar de usar valores constantes\n",
    "- **Beneficios**: Mejor generalización y reducción de overfitting para datos con relaciones lineales\n",
    "- **Impacto**: Puede mejorar significativamente la precisión en problemas de series temporales\n",
    "\n",
    "### Para datos de ventas/demanda:\n",
    "✅ **Ventajas**:\n",
    "- Captura mejor las tendencias temporales lineales\n",
    "- Reduce overfitting en patrones estacionales\n",
    "- Mejora extrapolación para períodos futuros\n",
    "\n",
    "⚠️ **Consideraciones**:\n",
    "- Aumenta ligeramente el tiempo de entrenamiento\n",
    "- Requiere más memoria\n",
    "- Menos efectivo si las relaciones son altamente no lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c6bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import os\n",
    "\n",
    "# === Usamos solo el primer período de validación ===\n",
    "X_val = X_val_list[0]\n",
    "y_val = y_val_list[0]\n",
    "\n",
    "# Nota: Los datasets se crearán dentro de la función objective \n",
    "# para permitir cambios en linear_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340dd66",
   "metadata": {},
   "source": [
    "### ⚠️ Nota importante sobre `linear_tree`\n",
    "\n",
    "**Problema**: LightGBM no permite cambiar `linear_tree` después de que el Dataset ha sido construido.\n",
    "\n",
    "**Solución**: Los datasets se crean dentro de la función `objective` para cada trial, permitiendo que `linear_tree` se configure correctamente para cada combinación de hiperparámetros.\n",
    "\n",
    "**Impacto en rendimiento**: Crear datasets en cada trial añade un pequeño overhead, pero es necesario para la optimización de `linear_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:06:45,821] Using an existing study with name 'mae_delta_lgbm_regression_todos_los_productos_con_pendientes' instead of creating a new one.\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   0%|          | 1/200 [00:08<27:36,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:06:54,055] Trial 34 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   0%|          | 1/200 [00:20<27:36,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:07:05,949] Trial 35 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   1%|          | 2/200 [00:20<34:42, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.0527923\n",
      "[100]\tvalid_0's l1: 0.0527923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   2%|▏         | 3/200 [01:07<1:30:01, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 0.0510455\n",
      "Trial 36: MAE = 0.05105\n",
      "[I 2025-06-24 21:07:53,725] Trial 36 finished with value: 0.05104549603832977 and parameters: {'num_leaves': 370, 'n_estimators': 711, 'min_child_weight': 1.0685028142788315, 'learning_rate': 0.22467611669985885, 'feature_fraction': 0.9037155372016138, 'bagging_fraction': 0.5057419955500141, 'bagging_freq': 4, 'min_data_in_leaf': 31, 'max_depth': 12, 'reg_alpha': 0.15639155655987336, 'reg_lambda': 0.8190107862315558, 'min_gain_to_split': 0.4767697073621683, 'linear_tree': False}. Best is trial 1 with value: 0.05041219522232905.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   2%|▏         | 3/200 [01:20<1:30:01, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:08:06,534] Trial 37 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   2%|▏         | 4/200 [01:20<1:11:01, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   2%|▎         | 5/200 [01:35<1:02:02, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:08:21,088] Trial 38 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.0504122:   3%|▎         | 6/200 [01:45<51:32, 15.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 21:08:30,882] Trial 39 pruned. Trial was pruned at iteration 0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure required packages are installed\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',  # alias de l1\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 1024, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 24),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "        'linear_tree': trial.suggest_categorical('linear_tree', [True, False]),  # Nuevo parámetro\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False,\n",
    "        'bagging_seed': 42,\n",
    "        'feature_fraction_seed': 42\n",
    "    }\n",
    "\n",
    "    # Crear datasets dentro de la función para permitir cambios en linear_tree\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, categorical_feature=categorical_features)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=2000,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=100),\n",
    "            LightGBMPruningCallback(trial, 'l1')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    best_score = model.best_score['valid_0']['l1']\n",
    "    print(f\"Trial {trial.number}: MAE = {best_score:.5f}\")\n",
    "    return best_score\n",
    "\n",
    "# Optuna\n",
    "storage_url = \"sqlite:///./modelos/optuna.db\"\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name=\"mae_delta_lgbm_regression_todos_los_productos_con_pendientes\",\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "# Mostrar mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los mejores hiperparámetros del estudio de la base de datos SQLite\n",
    "storage_url = \"sqlite:///./modelos/optuna.db\"\n",
    "study = optuna.load_study(\n",
    "    study_name=\"mae_delta_lgbm_regression_todos_los_productos_con_pendientes\",\n",
    "    storage=storage_url\n",
    ")\n",
    "best_params = study.best_params\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento final\n",
    "best_params = study.best_params\n",
    "best_params['objective'] = 'regression'\n",
    "best_params['metric'] = 'mae'\n",
    "best_params['verbose'] = -1\n",
    "\n",
    "model_reg = lgb.train(\n",
    "    best_params,\n",
    "    train_data,\n",
    "    num_boost_round=50000,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=500),\n",
    "        lgb.log_evaluation(period=500)\n",
    "    ]\n",
    ")\n",
    "\n",
    "os.makedirs('./modelos', exist_ok=True)\n",
    "model_reg.save_model('./modelos/lgbm_model_reg_todos_los_productos.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de cada variable\n",
    "importancia = model_reg.feature_importance(importance_type='gain')\n",
    "nombres = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado por importancia\n",
    "df_importancia = pd.DataFrame({'feature': nombres, 'importance': importancia})\n",
    "df_importancia = df_importancia.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "print(df_importancia.head(50))\n",
    "\n",
    "\n",
    "# Si quieres visualizarlo gráficamente:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df_importancia['feature'], df_importancia['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Importancia de variables LightGBM')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c421266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entreno nuevamente el modelo con los mejores hiperparámetros y el conjunto completo de datos\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')\n",
    "# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet\n",
    "df_pendientes = pd.read_parquet('./data/l_vm_completa_train_pendientes.parquet', engine='fastparquet')\n",
    "# Reunir los DataFrames df_full y df_pendientes por PRODUCT_ID, CUSTOMER_ID y PERIODO, agregar las \n",
    "# columnas de df_pendientes a df_full\n",
    "df_full = df_full.merge(df_pendientes, on=['PRODUCT_ID', 'CUSTOMER_ID', 'PERIODO'], how='left', suffixes=('', '_features'))\n",
    "# Agregar a df_full una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_full['MES_PROBLEMATICO'] = df_full['PERIODO'].apply(lambda x: 1 if x in [201906, 201908] else 0)\n",
    "# Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "# Variables categóricas\n",
    "# categorical_features = ['ANIO','MES','TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','CUSTOMER_ID','PRODUCT_ID','PLAN_PRECIOS_CUIDADOS']\n",
    "categorical_features = ['ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','PLAN_PRECIOS_CUIDADOS','MES_PROBLEMATICO','A_PREDECIR']\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_full[col] = df_full[col].astype('category')\n",
    "# Variables predictoras y objetivo\n",
    "# filtrar que en X el periodo sea menor o igual a 201910\n",
    "# En x eliminar la columna 'CLASE' y 'CLASE_DELTA'\n",
    "X = df_full[df_full['PERIODO'] <= 201910].drop(columns=['CLASE', 'CLASE_DELTA']) \n",
    "# Filtrar en y que el periodo sea menor o igual a 201910\n",
    "y = df_full[df_full['PERIODO'] <= 201910]['CLASE_DELTA']\n",
    "# Eliminar df_full para liberar memoria\n",
    "del df_full\n",
    "gc.collect()\n",
    "# Separar train y cinco conjuntos de validación respetando la secuencia temporal\n",
    "X_train = X\n",
    "y_train = y\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528be593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los mejores hiperparámetros del estudio de la base de datos SQLite\n",
    "storage_url = \"sqlite:///./modelos/optuna.db\"\n",
    "study1 = optuna.load_study(\n",
    "    study_name=\"mae_delta_lgbm_regression_todos_los_productos_con_pendientes\",\n",
    "    storage=storage_url\n",
    ")\n",
    "best_params1 = study1.best_params\n",
    "study1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "\n",
    "# Entrenamiento final\n",
    "best_params = study1.best_params\n",
    "best_params['objective'] = 'regression'\n",
    "best_params['metric'] = 'mae'\n",
    "best_params['verbose'] = -1\n",
    "\n",
    "model_reg = lgb.train(\n",
    "    best_params,\n",
    "    train_data,\n",
    "    num_boost_round=250\n",
    ")\n",
    "\n",
    "os.makedirs('./modelos', exist_ok=True)\n",
    "model_reg.save_model('./modelos/lgbm_model_reg_todos_los_productos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "gc.collect()\n",
    "df_pred_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')\n",
    "df_pred_full = df_pred_full[df_pred_full['PERIODO'] == 201910].drop(columns=['CLASE', 'CLASE_DELTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ce89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pendientes = pd.read_parquet('./data/l_vm_completa_train_pendientes.parquet', engine='fastparquet')\n",
    "df_pendientes = df_pendientes[df_pendientes['PERIODO'] == 201910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e18359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pred_full = df_pred_full.merge(df_pendientes, on=['PRODUCT_ID', 'CUSTOMER_ID', 'PERIODO'], how='left', suffixes=('', '_features'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores únicos de A_PREDECIR\n",
    "print(\"Valores únicos de A_PREDECIR en df_pred_full:\")\n",
    "print(df_pred_full['A_PREDECIR'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo los que tengan la columna A_PREDECIR con valor 1\n",
    "df_pred_full = df_pred_full[df_pred_full['A_PREDECIR'] == 'S']\n",
    "# Hacer que A_PREDECIR sea boolean si es 'S' vale True, si es 'N' False\n",
    "df_pred_full['A_PREDECIR'] = df_pred_full['A_PREDECIR'].map({'S': True, 'N': False})\n",
    "\n",
    "# Agregar a df_pred_full una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_pred_full['MES_PROBLEMATICO'] = df_pred_full['PERIODO'].apply(lambda x: 1 if x in [201906, 201908] else 0)\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_pred_full[col] = df_pred_full[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar del dataframe df_pred_full la columna 'PREDICCIONES'\n",
    "if 'PREDICCIONES' in df_pred_full.columns:\n",
    "    df_pred_full.drop(columns=['PREDICCIONES'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not df_pred_full.empty:\n",
    "\tpredictions = model_reg.predict(df_pred_full)\n",
    "\tdf_pred_full['PREDICCIONES'] = predictions\n",
    "else:\n",
    "\tprint(\"df_pred_full está vacío, no se generaron predicciones.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostar las columnas de df_pred_full\n",
    "print(\"Columnas de df_pred_full después de las predicciones:\")\n",
    "print(df_pred_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cada reregistro de df_pred_full le agrego la columna que TN + PREDICCIONES\n",
    "df_pred_full['TN_PREDICCIONES'] = df_pred_full['TN'] + 0.7 * df_pred_full['PREDICCIONES']\n",
    "df_pred_full['TN_PREDICCIONES'] = np.where(\n",
    "    df_pred_full['TN_PREDICCIONES'] <= df_pred_full['TN_MIN_12'] ,\n",
    "    df_pred_full['TN_MIN_12'],\n",
    "    np.where(\n",
    "        df_pred_full['TN_PREDICCIONES'] >= df_pred_full['TN_MAX_12'],\n",
    "        df_pred_full['TN_MAX_12'],\n",
    "        df_pred_full['TN_PREDICCIONES']\n",
    "    )\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Dataframe que contenga por cada PRODUCT_ID la suma de las predicciones y la suma de la clase observada\n",
    "df_final = df_pred_full.groupby('PRODUCT_ID').agg({'PREDICCIONES': 'sum', 'TN_PREDICCIONES': 'sum'}).reset_index()\n",
    "# Los valore de TN_PREDICCIONES deben ser cero o mayores a cero, si no es así, los cambio a cero\n",
    "df_final['TN_PREDICCIONES'] = df_final['TN_PREDICCIONES'].clip(lower=0)\n",
    "df_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123da34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En df_final, solo dejar las columnas PRODUCT_ID, TN_PREDICCIONES que deben llamarse product_id y tn\n",
    "df_final = df_final.rename(columns={'PRODUCT_ID': 'product_id', 'TN_PREDICCIONES': 'tn'})\n",
    "# Eliminar el indice y PREDICCIONES\n",
    "df_final = df_final[['product_id', 'tn']]   \n",
    "df_final\n",
    "# Guardar el DataFrame df_final en un archivo CSV\n",
    "df_final.to_csv('./modelos/lgbm_model_reg_todos_los_productos.csv', index=False)\n",
    "df_final.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
