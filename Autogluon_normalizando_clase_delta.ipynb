{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d80a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c2e2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables predictoras y objetivo\n",
    "# filtrar que en X el periodo sea menor o igual a 201910\n",
    "# En x eliminar la columna 'CLASE_ZSCORE' y 'CLASE_DELTA_ZSCORE' si existen\n",
    "cols_to_drop = [col for col in ['CLASE_ZSCORE', 'CLASE_DELTA_ZSCORE'] if col in df_full.columns]\n",
    "X = df_full[df_full['PERIODO'] <= 201910].drop(columns=cols_to_drop)\n",
    "# Filtrar en y que el periodo sea menor o igual a 201910 y que la columna exista\n",
    "y = df_full[df_full['PERIODO'] <= 201910]['CLASE_DELTA_ZSCORE']\n",
    "# Eliminar df_full para liberar memoria\n",
    "del df_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd36925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los periodos de validaci칩n \n",
    "periodos_valid = [201909, 201910]\n",
    "\n",
    "# Separar train y cinco conjuntos de validaci칩n respetando la secuencia temporal\n",
    "X_train = X[X['PERIODO'] < periodos_valid[0]]\n",
    "y_train = y[X['PERIODO'] < periodos_valid[0]]\n",
    "X_val_list = [X[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_val_list = [y[X['PERIODO'] == p] for p in periodos_valid]\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1a4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Dataset de entrenamiento\n",
    "df_train = X_train.copy()\n",
    "df_train['CLASE_DELTA_ZSCORE'] = y_train\n",
    "\n",
    "# Dataset de validaci칩n\n",
    "df_val = X_val_list[0].copy()\n",
    "df_val['CLASE_DELTA_ZSCORE'] = y_val_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250628_050549\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.23\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Apr 17 19:20:47 UTC 2\n",
      "CPU Count:          28\n",
      "Memory Avail:       95.35 GB / 125.58 GB (75.9%)\n",
      "Disk Space Avail:   328.07 GB / 543.17 GB (60.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 25200s\n",
      "AutoGluon will save models to \"/home/pablo/Documentos/labo3-2025v/AutogluonModels/ag-20250628_050549\"\n",
      "Train Data Rows:    14804223\n",
      "Train Data Columns: 178\n",
      "Tuning Data Rows:    541842\n",
      "Tuning Data Columns: 178\n",
      "Label Column:       CLASE_DELTA_ZSCORE\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    87033.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10405.59 MB (12.0% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 12.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 14): ['TN_RESIDUAL_STD_ZSCORE_18', 'TN_RESIDUAL_STD_ZSCORE_21', 'TN_RESIDUAL_STD_ZSCORE_24', 'TN_RESIDUAL_STD_ZSCORE_27', 'TN_RESIDUAL_STD_ZSCORE_30', 'TN_MEAN_ZSCORE_34', 'TN_STD_ZSCORE_34', 'TN_MEDIAN_ZSCORE_34', 'TN_MIN_ZSCORE_34', 'TN_MAX_ZSCORE_34', 'PENDIENTE_TENDENCIA_ZSCORE_34', 'TN_ABS_DIFF_MEAN_ZSCORE_34', 'TN_RESIDUAL_STD_ZSCORE_34', 'TN_CV_ZSCORE_34']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['TN_MEDIAN_ZSCORE_02']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['TN_MEDIAN_ZSCORE_02']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  :   3 | ['PLAN_PRECIOS_CUIDADOS', 'A_PREDECIR', 'MES_PROBLEMATICO']\n",
      "\t\t('float', []) : 144 | ['MES_SIN', 'MES_COS', 'STOCK_FINAL', 'CLASE_DELTA_MEAN', 'CLASE_DELTA_STD', ...]\n",
      "\t\t('int', [])   :  16 | ['PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 144 | ['MES_SIN', 'MES_COS', 'STOCK_FINAL', 'CLASE_DELTA_MEAN', 'CLASE_DELTA_STD', ...]\n",
      "\t\t('int', [])       :  16 | ['PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', ...]\n",
      "\t\t('int', ['bool']) :   3 | ['PLAN_PRECIOS_CUIDADOS', 'A_PREDECIR', 'MES_PROBLEMATICO']\n",
      "\t80.4s = Fit runtime\n",
      "\t163 features in original data used to generate 163 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9468.94 MB (10.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 88.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {'linear_tree': True, 'ag_args': {'name_suffix': 'LinearTree'}}, {'num_leaves': 31, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'ag_args': {'name_suffix': 'Default'}}],\n",
      "\t'XGB': [{}],\n",
      "\t'CAT': [{}],\n",
      "\t'NN_TORCH': [{'num_epochs': 20, 'learning_rate': 0.001, 'ag_args': {'name_suffix': 'DL'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 16736.92s of the 25111.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 0.252046\n",
      "[2000]\tvalid_set's l1: 0.249979\n",
      "[3000]\tvalid_set's l1: 0.248599\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='CLASE_DELTA_ZSCORE',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error'\n",
    ").fit(\n",
    "    train_data=df_train,\n",
    "    tuning_data=df_val,\n",
    "    presets='best_quality',\n",
    "    time_limit= 25200,  # 7 horas m치ximo\n",
    "    use_bag_holdout=True,\n",
    "    hyperparameters={\n",
    "        'GBM': [\n",
    "            {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
    "            {'linear_tree': True, 'ag_args': {'name_suffix': 'LinearTree'}},\n",
    "            {'num_leaves': 31, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'ag_args': {'name_suffix': 'Default'}}\n",
    "        ],\n",
    "        'XGB': [{}],\n",
    "        'CAT': [{}],\n",
    "        'NN_TORCH': [{\n",
    "            'num_epochs': 20,           # controla duraci칩n\n",
    "            'learning_rate': 1e-3,\n",
    "            'ag_args': {'name_suffix': 'DL'},\n",
    "        }]\n",
    "    },\n",
    "    ag_args_ensemble={\n",
    "        'fold_fitting_strategy': 'sequential_local'  # mejora uso de memoria\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae010ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20250627_202659\")\n",
    "\n",
    "# predictor.fit_extra(\n",
    "#     hyperparameters='default',\n",
    "#     time_limit=32400,\n",
    "#     ag_args_fit={\"ag.max_memory_usage_ratio\": 2.0},\n",
    "#     excluded_model_types=[\"KNN\", \"NN_TORCH\", \"CATBOOST\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08426fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar MAE y MedAE en el leaderboard\n",
    "lb = predictor.leaderboard(data=df_val,extra_metrics=['mean_absolute_error', 'median_absolute_error'], silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50559ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar feature importance sobre el conjunto de validaci칩n\n",
    "importancia = predictor.feature_importance(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar entrenamiento + validaci칩n\n",
    "df_full = pd.concat([df_train, df_val], axis=0)\n",
    "del df_train, df_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31acb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenar el mejor modelo con TODOS los datos disponibles\n",
    "predictor_full = predictor.refit_full(train_data=df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los modelos disponibles (el mejor ahora tiene el sufijo '_FULL')\n",
    "print(\"Modelos disponibles luego del refit completo:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "# Eliminar modelos intermedios para liberar espacio\n",
    "predictor.delete_models(models_to_keep='best', dry_run=False)\n",
    "\n",
    "# Confirmar que solo queda el modelo reentrenado\n",
    "print(\"\\nModelos restantes despu칠s de eliminar los intermedios:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "\n",
    "# (Opcional) Guardar el predictor final si quer칠s usarlo luego sin volver a cargar todo\n",
    "predictor.save('./data/modelo_final_autogluon')\n",
    "\n",
    "# ---  Liberar memoria ---\n",
    "del df_full\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "df_pred_full = pd.read_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet')\n",
    "# Dejo solo los datos del periodo 201910 y que A_PREDECIR sea True\n",
    "# Filtrar solo los datos del periodo 201910 y donde A_PREDECIR sea True\n",
    "df_pred_full = df_pred_full[\n",
    "    (df_pred_full['PERIODO'] == 201910) & (df_pred_full['A_PREDECIR'] == True)\n",
    "].drop(columns=['CLASE_ZSCORE', 'CLASE_DELTA_ZSCORE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar las predicciones usando el predictor original\n",
    "predictions = predictor.predict(df_pred_full)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['CLASE_DELTA_ZSCORE'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir la lista de columas del DataFrame con las predicciones\n",
    "print(\"Columnas del DataFrame con las predicciones:\")\n",
    "print(df_pred_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dernormalizar la columna CLASE_DELTA_ZSCORE\n",
    "df_pred_full['CLASE_DELTA'] = df_pred_full['CLASE_DELTA_ZSCORE'] * df_pred_full['CLASE_DELTA_STD'] + df_pred_full['CLASE_DELTA_MEAN']\n",
    "df_pred_full['TN'] = df_pred_full['TN_ZSCORE'] * df_pred_full['TN_STD'] + df_pred_full['TN_MEAN']\n",
    "# Agregar la columna TN_PREDICT que sea la suma de TN y CLASE_DELTA y si es menor que cero, poner cero\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN'] + df_pred_full['CLASE_DELTA']\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN_PREDICT'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d822ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Dataframe que contenga por cada PRODUCT_ID la suma de TN_PREDICT\n",
    "df_final = df_pred_full.groupby('PRODUCT_ID').agg({'TN_PREDICT': 'sum'}).reset_index()\n",
    "df_final = df_final.rename(columns={'PRODUCT_ID': 'product_id', 'TN_PREDICT': 'tn'})\n",
    "# Guardar el DataFrame df_final en un archivo CSV\n",
    "df_final.to_csv('./modelos/autoglun_normalizando_clase_delta.csv', index=False)\n",
    "df_final.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
