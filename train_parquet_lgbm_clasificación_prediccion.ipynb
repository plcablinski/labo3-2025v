{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e06b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "# Variables categóricas\n",
    "# categorical_features = ['ANIO','MES','TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','CUSTOMER_ID','PRODUCT_ID','PLAN_PRECIOS_CUIDADOS']\n",
    "categorical_features = ['ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','PLAN_PRECIOS_CUIDADOS']\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_full[col] = df_full[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff018be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los campos del DataFrame\n",
    "print(\"Campos del DataFrame:\")\n",
    "print(df_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras y objetivo\n",
    "# filtrar que en X el periodo sea menor o igual a 201910\n",
    "# En x eliminar la columna 'CLASE' y 'CLASE_DELTA'\n",
    "X = df_full[df_full['PERIODO'] <= 201910].drop(columns=['CLASE', 'CLASE_DELTA']) \n",
    "# Filtrar en y que el periodo sea menor o igual a 201910\n",
    "y = df_full[df_full['PERIODO'] <= 201910]['CLASE']\n",
    "# Agrega una columna 'CLASE_BIN' que sea 1 si 'CLASE' es mayor a 0, y 0 en caso contrario para clasificación binaria\n",
    "# El tipo es cero o uno por lo que se convierte a int del menor tamaño posible\n",
    "df_full['CLASE_BIN'] = (df_full['CLASE'] > 0).astype('int8')\n",
    "y_bin = df_full[df_full['PERIODO'] <= 201910]['CLASE_BIN']\n",
    "\n",
    "# Eliminar df_full para liberar memoria\n",
    "del df_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los periodos de validación 201909, 201910\n",
    "periodos_valid = [201910]\n",
    "\n",
    "# Separar train y cinco conjuntos de validación respetando la secuencia temporal\n",
    "X_train = X[X['PERIODO'] < periodos_valid[0]]\n",
    "y_train = y[X['PERIODO'] < periodos_valid[0]]\n",
    "y_bin_train = y_bin[X['PERIODO'] < periodos_valid[0]]\n",
    "\n",
    "X_val_list = [X[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_val_list = [y[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_bin_val_list = [y_bin[X['PERIODO'] == p] for p in periodos_valid]\n",
    "\n",
    "del X, y, y_bin\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0715d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hacer un try-except para cargar el modelo de LightGBM para clasificación binaria\n",
    "try:\n",
    "    model_clasif = lgb.Booster(model_file='./modelos/lgbm_model_clasif.txt')\n",
    "    print(\"Modelo de clasificación binaria cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    model_clasif = None\n",
    "\n",
    "# Entrenar solo si el modelo no existe\n",
    "# Entrenar el modelo LightGBM para clasificación binaria donde la variable objetivo es 'CLASE' \n",
    "# si 0 o distinta de 0 usando early stopping sobre el conjunto de validación\n",
    "if model_clasif is None:\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 1023,\n",
    "        'learning_rate': 0.005,  # Valor inicial\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # Crear el dataset de LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, y_bin_train,  categorical_feature=categorical_features)\n",
    "    lgb_val_list = [lgb.Dataset(X_val, y_bin_val_list, categorical_feature=categorical_features) for X_val, y_bin_val_list in zip(X_val_list, y_bin_val_list)]    \n",
    "\n",
    "    # Entrenar el modelo con learning rate decay\n",
    "    model_clasif = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_val_list,\n",
    "        valid_names=[f'valid_{i+1}' for i in range(len(lgb_val_list))],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=200),\n",
    "            lgb.log_evaluation(period=200)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    model_clasif.save_model('lgbm_model_clasif.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer un try-except para cargar el modelo de LightGBM para regresión\n",
    "try:\n",
    "    model_reg = lgb.Booster(model_file='./modelos/lgbm_model_reg.txt')\n",
    "    print(\"Modelo de regresión cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    model_reg = None\n",
    "\n",
    "if model_reg is None:\n",
    "    # Crear los datasets de LightGBM\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "    val_data_list = [lgb.Dataset(X_val_list[i], label=y_val_list[i], categorical_feature=categorical_features) for i in range(len(periodos_valid))]\n",
    "\n",
    "    def mape_sum_lgb(y_pred, dataset):\n",
    "        y_true = dataset.get_label()\n",
    "        # Reemplazar valores negativos en y_pred por cero\n",
    "        y_pred = np.where(y_pred < 0, 0, y_pred)\n",
    "        # Evitar división por cero\n",
    "        denom = np.sum(np.abs(y_true))\n",
    "        if denom == 0:\n",
    "            return 'mape_sum', 0.0, False\n",
    "        mape = np.sum(np.abs(y_true - y_pred)) / denom\n",
    "        return 'mape_sum', mape, False  # False indica que menor es mejor\n",
    "\n",
    "    # Definir parámetros para regresión\n",
    "    params = { \n",
    "        'objective': 'regression',\n",
    "        'metric': ['rmse','mae'],\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 511,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "\n",
    "    # Entrenar el modelo con la métrica personalizada\n",
    "    model_reg = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=val_data_list,\n",
    "        valid_names=[f'validation_{p}' for p in periodos_valid],\n",
    "        feval=mape_sum_lgb,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(period=500)]\n",
    "    )\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    model_reg.save_model('lgbm_model_reg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de cada variable\n",
    "importancia = model_reg.feature_importance(importance_type='gain')\n",
    "nombres = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado por importancia\n",
    "df_importancia = pd.DataFrame({'feature': nombres, 'importance': importancia})\n",
    "df_importancia = df_importancia.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "print(df_importancia)\n",
    "\n",
    "# Si quieres visualizarlo gráficamente:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df_importancia['feature'], df_importancia['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Importancia de variables LightGBM')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREDICCIÓN Y EVALUACIÓN por periodo ---\n",
    "for i, (X_val, y_val, periodo) in enumerate(zip(X_val_list, y_val_list, periodos_valid)):\n",
    "    proba_no_cero = model_clasif.predict(X_val)\n",
    "    umbral = 0.25\n",
    "    pred_bin = (proba_no_cero > umbral)\n",
    "    pred_reg = np.zeros(len(X_val))\n",
    "    if pred_bin.sum() > 0:\n",
    "        pred_reg[pred_bin] = model_reg.predict(X_val[pred_bin])\n",
    "    y_val_real = y_val.values\n",
    "    # WAPE solo en no-cero\n",
    "    mask_nocero = y_val_real != 0\n",
    "    if mask_nocero.sum() > 0:\n",
    "        wape_nocero = np.sum(np.abs(y_val_real[mask_nocero] - pred_reg[mask_nocero])) / np.sum(np.abs(y_val_real[mask_nocero]))\n",
    "        print(f\"WAPE (no-cero) periodo {periodo}: {wape_nocero:.4f}\")\n",
    "    else:\n",
    "        print(f\"WAPE (no-cero) periodo {periodo}: N/A (no hay valores no-cero)\")\n",
    "    # También puedes seguir mostrando el WAPE global\n",
    "    wape = np.sum(np.abs(y_val_real - pred_reg)) / np.sum(np.abs(y_val_real))\n",
    "    print(f\"WAPE global periodo {periodo}: {wape:.4f}\")\n",
    "    print(f\"Valores distintos de cero en pred_reg: {(pred_reg != 0).sum()} de {len(pred_reg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armar listado de las 100 predicioones con mayor diferencia entre predicción y valor real con product_id, customer_id \n",
    "df_val = X_val_list[0].copy()\n",
    "df_val['CLASE_REAL'] = y_val_list[0].values\n",
    "df_val['CLASE_PRED'] = pred_reg\n",
    "df_val['DIF'] = np.abs(df_val['CLASE_REAL'] - df_val['CLASE_PRED'])\n",
    "df_val = df_val.sort_values(by='DIF', ascending=False).head(50)\n",
    "df_val[['PRODUCT_ID', 'CUSTOMER_ID', 'CLASE_REAL', 'CLASE_PRED', 'DIF']]\n",
    "# Agrupar las diferencias por PRODUCT_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dif_product = df_val.groupby('PRODUCT_ID')['DIF'].sum().reset_index()\n",
    "print(\"Diferencias promedio por PRODUCT_ID:\")   \n",
    "df_dif_product.sort_values(by='DIF', ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1dbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar las diferencias por CUSTOMER_ID\n",
    "df_dif_customer = df_val.groupby('CUSTOMER_ID')['DIF'].sum().reset_index()\n",
    "print(\"Diferencias promedio por CUSTOMER_ID:\")\n",
    "df_dif_customer.sort_values(by='DIF', ascending=False).head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from L_VM_COMPLETA where periodo = 201912\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_pred_full = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_pred_full[col] = df_pred_full[col].astype('category')\n",
    "\n",
    "# Con el modelo entrenado, hacemos predicciones \n",
    "X_pred = df_pred_full[['PERIODO','CUSTOMER_ID','PRODUCT_ID',\n",
    "'TN_DELTA_01','TN_DELTA_02','TN_DELTA_03','TN_DELTA_06','TN_DELTA_12']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(X_pred)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['PREDICCIONES'] = predictions\n",
    "# Imprimir las primeras filas del DataFrame con las predicciones\n",
    "print(df_pred_full.head())\n",
    "# Guardar el DataFrame con las predicciones en un archivo CSV\n",
    "df_pred_full.to_csv('predicciones.csv', index=False)\n",
    "# Imprimir el número de filas y columnas del DataFrame con las predicciones\n",
    "print(f\"Número de filas: {df_pred_full.shape[0]}, Número de columnas: {df_pred_full.shape[1]} con predicciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el DataFrame de predicción, actualizamos la base de datos\n",
    "# el criterio es actualizar la tabla L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones\n",
    "# la columnna PREDICCIONES se debe actualizar con los nuevos valores\n",
    "# la clave primaria es (PERIODO, CUSTOMER_ID, PRODUCT_ID)\n",
    "# Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "\n",
    "# Conectar a la base de datos para actualizar los datos de predicción\n",
    "conn = cx_Oracle.connect(user=\"pc\", password=\"p201404\", dsn=\"siatchdesa\")\n",
    "# Crear un cursor para ejecutar las actualizaciones\n",
    "cursor = conn.cursor()\n",
    "update_query = \"\"\"\n",
    "    UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "    SET PREDICCION = NULL\n",
    "\"\"\"\n",
    "cursor.execute(update_query)\n",
    "# Hacer commit para aplicar el cambio de NULL\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imprimir mensaje de inicio de actualización\n",
    "print(\"Iniciando actualización de la tabla L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "\n",
    "# Iterar sobre las filas del DataFrame con las predicciones\n",
    "for index, row in df_pred_full.iterrows():\n",
    "    periodo = row['PERIODO']\n",
    "    customer_id = row['CUSTOMER_ID']\n",
    "    product_id = row['PRODUCT_ID']\n",
    "    prediccion = row['TN'] + row['PREDICCIONES']\n",
    "   # prediccion = row['PREDICCIONES']\n",
    "    \n",
    "    # Actualizar la tabla L_DATOS_PREDICCION con la nueva predicción\n",
    "    update_query = \"\"\"\n",
    "        UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "        SET PREDICCION = :prediccion\n",
    "        WHERE PERIODO = :periodo AND CUSTOMER_ID = :customer_id AND PRODUCT_ID = :product_id\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, {'prediccion': prediccion, 'periodo': periodo, 'customer_id': customer_id, 'product_id': product_id})  \n",
    "    # Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "    if index % 10000 == 0:\n",
    "        conn.commit()\n",
    "        print(f\"Actualizadas {index} filas de L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "# Confirmar los cambios en la base de datos\n",
    "conn.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "# Imprimir mensaje de finalización\n",
    "print(\"Actualización de la tabla  completada con las nuevas predicciones.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python31017",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
