{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d6f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e06b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12254054 entries, 0 to 12254053\n",
      "Data columns (total 55 columns):\n",
      " #   Column                     Dtype   \n",
      "---  ------                     -----   \n",
      " 0   PERIODO                    int32   \n",
      " 1   ANIO                       int16   \n",
      " 2   MES                        int8    \n",
      " 3   MES_SIN                    float32 \n",
      " 4   MES_COS                    float32 \n",
      " 5   TRIMESTRE                  category\n",
      " 6   ID_CAT1                    category\n",
      " 7   ID_CAT2                    category\n",
      " 8   ID_CAT3                    category\n",
      " 9   ID_BRAND                   category\n",
      " 10  SKU_SIZE                   category\n",
      " 11  CUSTOMER_ID                category\n",
      " 12  PRODUCT_ID                 category\n",
      " 13  PLAN_PRECIOS_CUIDADOS      category\n",
      " 14  CUST_REQUEST_QTY           int8    \n",
      " 15  CUST_REQUEST_TN            float32 \n",
      " 16  TN                         float32 \n",
      " 17  STOCK_FINAL                float32 \n",
      " 18  MEDIA_MOVIL_3M_CLI_PROD    float32 \n",
      " 19  MEDIA_MOVIL_6M_CLI_PROD    float32 \n",
      " 20  MEDIA_MOVIL_12M_CLI_PROD   float32 \n",
      " 21  DESVIO_MOVIL_3M_CLI_PROD   float32 \n",
      " 22  DESVIO_MOVIL_6M_CLI_PROD   float32 \n",
      " 23  DESVIO_MOVIL_12M_CLI_PROD  float32 \n",
      " 24  MEDIA_MOVIL_3M_PROD        float32 \n",
      " 25  MEDIA_MOVIL_6M_PROD        float32 \n",
      " 26  MEDIA_MOVIL_12M_PROD       float32 \n",
      " 27  DESVIO_MOVIL_3M_PROD       float32 \n",
      " 28  DESVIO_MOVIL_6M_PROD       float32 \n",
      " 29  DESVIO_MOVIL_12M_PROD      float32 \n",
      " 30  MEDIA_MOVIL_3M_CLI         float32 \n",
      " 31  MEDIA_MOVIL_6M_CLI         float32 \n",
      " 32  MEDIA_MOVIL_12M_CLI        float32 \n",
      " 33  DESVIO_MOVIL_3M_CLI        float32 \n",
      " 34  DESVIO_MOVIL_6M_CLI        float32 \n",
      " 35  DESVIO_MOVIL_12M_CLI       float32 \n",
      " 36  TN_LAG_01                  float32 \n",
      " 37  TN_LAG_02                  float32 \n",
      " 38  TN_LAG_03                  float32 \n",
      " 39  TN_LAG_06                  float32 \n",
      " 40  TN_LAG_12                  float32 \n",
      " 41  CLASE                      float32 \n",
      " 42  CLASE_DELTA                float32 \n",
      " 43  ORDINAL                    int8    \n",
      " 44  TN_DELTA_01                float32 \n",
      " 45  TN_DELTA_02                float32 \n",
      " 46  TN_DELTA_03                float32 \n",
      " 47  TN_DELTA_06                float32 \n",
      " 48  TN_DELTA_12                float32 \n",
      " 49  ANTIG_CLIENTE              int8    \n",
      " 50  ANTIG_PRODUCTO             int8    \n",
      " 51  CANT_PROD_CLI_PER          int16   \n",
      " 52  MEDIA_PROD_PER             float32 \n",
      " 53  MEDIA_PROD                 float32 \n",
      " 54  MEDIA_PER                  float32 \n",
      "dtypes: category(9), float32(38), int16(2), int32(1), int8(5)\n",
      "memory usage: 2.0 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Optimizar tipos de datos numéricos\n",
    "for col in df_full.select_dtypes(include=['int64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='integer')\n",
    "for col in df_full.select_dtypes(include=['float64']).columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], downcast='float')\n",
    "# Variables categóricas\n",
    "# categorical_features = ['ANIO','MES','TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','CUSTOMER_ID','PRODUCT_ID','PLAN_PRECIOS_CUIDADOS']\n",
    "categorical_features = ['TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','CUSTOMER_ID','PRODUCT_ID','PLAN_PRECIOS_CUIDADOS']\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_full[col] = df_full[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e06cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variables predictoras y objetivo\n",
    "# filtrar que en X el periodo sea menor o igual a 201910\n",
    "# En x eliminar la columna 'CLASE' y 'CLASE_DELTA'\n",
    "X = df_full[df_full['PERIODO'] <= 201910].drop(columns=['CLASE', 'CLASE_DELTA']) \n",
    "# Filtrar en y que el periodo sea menor o igual a 201910\n",
    "y = df_full[df_full['PERIODO'] <= 201910]['CLASE']\n",
    "# Agrega una columna 'CLASE_BIN' que sea 1 si 'CLASE' es mayor a 0, y 0 en caso contrario para clasificación binaria\n",
    "df_full['CLASE_BIN'] = (df_full['CLASE'] > 0).astype(int)\n",
    "y_bin = df_full[df_full['PERIODO'] <= 201910]['CLASE_BIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec1811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los periodos de validación 201909, 201910\n",
    "periodos_valid = [201910]\n",
    "\n",
    "# Separar train y cinco conjuntos de validación respetando la secuencia temporal\n",
    "X_train = X[X['PERIODO'] < periodos_valid[0]]\n",
    "y_train = y[X['PERIODO'] < periodos_valid[0]]\n",
    "y_bin_train = y_bin[X['PERIODO'] < periodos_valid[0]]\n",
    "\n",
    "X_val_list = [X[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_val_list = [y[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_bin_val_list = [y_bin[X['PERIODO'] == p] for p in periodos_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0715d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_1's binary_logloss: 0.127507\n",
      "[400]\tvalid_1's binary_logloss: 0.112478\n",
      "[600]\tvalid_1's binary_logloss: 0.110691\n",
      "[800]\tvalid_1's binary_logloss: 0.110447\n",
      "[1000]\tvalid_1's binary_logloss: 0.110414\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo LightGBM para clasificación binaria donde la variable objetivo es 'CLASE' \n",
    "# si 0 o distinta de 0 usando early stopping sobre el conjunto de validación\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 255,\n",
    "    'learning_rate': 0.01,  # Valor inicial\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "# Callback para decay exponencial del learning rate\n",
    "def learning_rate_decay(current_round):\n",
    "    initial_lr = 0.01\n",
    "    decay_rate = 0.99  # Ajusta este valor según lo que desees\n",
    "    return initial_lr * (decay_rate ** current_round)\n",
    "\n",
    "# Crear el dataset de LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, y_bin_train,  categorical_feature=categorical_features)\n",
    "lgb_val_list = [lgb.Dataset(X_val, y_bin_val_list, categorical_feature=categorical_features) for X_val, y_bin_val_list in zip(X_val_list, y_bin_val_list)]    \n",
    "\n",
    "# Entrenar el modelo con learning rate decay\n",
    "model_clasif = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=lgb_val_list,\n",
    "    valid_names=[f'valid_{i+1}' for i in range(len(lgb_val_list))],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=200),\n",
    "        lgb.log_evaluation(period=200),\n",
    "        lgb.reset_parameter(learning_rate=learning_rate_decay)\n",
    "    ]\n",
    ")# Guardar el modelo entrenado\n",
    "model_clasif.save_model('lgbm_model_clasif.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Crear los datasets de LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "val_data_list = [lgb.Dataset(X_val_list[i], label=y_val_list[i], categorical_feature=categorical_features) for i in range(len(periodos_valid))]\n",
    "\n",
    "# Definir parámetros para regresión\n",
    "params = { \n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 1024,\n",
    "    'learning_rate': 0.001,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenar el modelo con validación múltiple y early stopping\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=val_data_list,\n",
    "    valid_names=[f'validation_{p}' for p in periodos_valid],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(period=500)]\n",
    ")\n",
    "\n",
    "print(\"Modelo de regresión entrenado con cinco conjuntos de validación (uno por cada periodo 201906-201910).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de cada variable\n",
    "importancia = model.feature_importance(importance_type='gain')\n",
    "nombres = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado por importancia\n",
    "import pandas as pd\n",
    "df_importancia = pd.DataFrame({'feature': nombres, 'importance': importancia})\n",
    "df_importancia = df_importancia.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "print(df_importancia)\n",
    "\n",
    "# Si quieres visualizarlo gráficamente:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df_importancia['feature'], df_importancia['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Importancia de variables LightGBM')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02240a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el modelo entrenado\n",
    "model.save_model('modelo_regresion_lgbm_lags_delta_promedio_desvio.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from L_VM_COMPLETA where periodo = 201912\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_pred_full = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_pred_full[col] = df_pred_full[col].astype('category')\n",
    "\n",
    "# Con el modelo entrenado, hacemos predicciones \n",
    "X_pred = df_pred_full[['PERIODO','CUSTOMER_ID','PRODUCT_ID',\n",
    "'TN_DELTA_01','TN_DELTA_02','TN_DELTA_03','TN_DELTA_06','TN_DELTA_12']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(X_pred)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['PREDICCIONES'] = predictions\n",
    "# Imprimir las primeras filas del DataFrame con las predicciones\n",
    "print(df_pred_full.head())\n",
    "# Guardar el DataFrame con las predicciones en un archivo CSV\n",
    "df_pred_full.to_csv('predicciones.csv', index=False)\n",
    "# Imprimir el número de filas y columnas del DataFrame con las predicciones\n",
    "print(f\"Número de filas: {df_pred_full.shape[0]}, Número de columnas: {df_pred_full.shape[1]} con predicciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el DataFrame de predicción, actualizamos la base de datos\n",
    "# el criterio es actualizar la tabla L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones\n",
    "# la columnna PREDICCIONES se debe actualizar con los nuevos valores\n",
    "# la clave primaria es (PERIODO, CUSTOMER_ID, PRODUCT_ID)\n",
    "# Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "\n",
    "# Conectar a la base de datos para actualizar los datos de predicción\n",
    "conn = cx_Oracle.connect(user=\"pc\", password=\"p201404\", dsn=\"siatchdesa\")\n",
    "# Crear un cursor para ejecutar las actualizaciones\n",
    "cursor = conn.cursor()\n",
    "update_query = \"\"\"\n",
    "    UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "    SET PREDICCION = NULL\n",
    "\"\"\"\n",
    "cursor.execute(update_query)\n",
    "# Hacer commit para aplicar el cambio de NULL\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imprimir mensaje de inicio de actualización\n",
    "print(\"Iniciando actualización de la tabla L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "\n",
    "# Iterar sobre las filas del DataFrame con las predicciones\n",
    "for index, row in df_pred_full.iterrows():\n",
    "    periodo = row['PERIODO']\n",
    "    customer_id = row['CUSTOMER_ID']\n",
    "    product_id = row['PRODUCT_ID']\n",
    "    prediccion = row['TN'] + row['PREDICCIONES']\n",
    "   # prediccion = row['PREDICCIONES']\n",
    "    \n",
    "    # Actualizar la tabla L_DATOS_PREDICCION con la nueva predicción\n",
    "    update_query = \"\"\"\n",
    "        UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "        SET PREDICCION = :prediccion\n",
    "        WHERE PERIODO = :periodo AND CUSTOMER_ID = :customer_id AND PRODUCT_ID = :product_id\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, {'prediccion': prediccion, 'periodo': periodo, 'customer_id': customer_id, 'product_id': product_id})  \n",
    "    # Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "    if index % 10000 == 0:\n",
    "        conn.commit()\n",
    "        print(f\"Actualizadas {index} filas de L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "# Confirmar los cambios en la base de datos\n",
    "conn.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "# Imprimir mensaje de finalización\n",
    "print(\"Actualización de la tabla  completada con las nuevas predicciones.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oracle_parquet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
