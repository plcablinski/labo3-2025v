{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del df, df_full, X, y, X_train, y_train, X_val_list, y_val_list\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6306ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from PC.L_VW_N_COMPLETA WHERE PERIODO <= 201910\" \n",
    "df = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_full = pd.concat(df, ignore_index=True)\n",
    "conn.close()\n",
    "print(df_full.shape)\n",
    "# Imprimir los tipos de datos de las columnas del DataFrame completo\n",
    "print(df_full.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame completo en un archivo CSV\n",
    "df_full.to_csv(\"df_full.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas\n",
    "# categorical_features = ['CUSTOMER_ID','PRODUCT_ID','ANIO','MES','TRIMESTRE','ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','SKU_SIZE','PLAN_PRECIOS_CUIDADOS']\n",
    "categorical_features = ['ID_CAT1','ID_CAT2','ID_CAT3','ID_BRAND','PLAN_PRECIOS_CUIDADOS','MES_PROBLEMATICO']\n",
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_full[col] = df_full[col].astype('category')\n",
    "# Asegurarse de que las variables predictoras y objetivo estén en el formato correcto\n",
    "# Imprimir los tipos de datos de las columnas del DataFrame completo\n",
    "print(df_full.dtypes)\n",
    "# Imprimir los nombre de columnas del DataFrame \n",
    "print(df_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando este código como base para un modelo de regresión con LightGBM\n",
    "# definir las variables predictoras y la variable objetivo indicando al modelo que las variables categóricas son de tipo 'category'\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = df_full[['ORDINAL', 'PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', 'ID_CAT2',\n",
    "       'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID', 'PRODUCT_ID',\n",
    "       'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY', 'N_CUST_REQUEST_TN',\n",
    "       'N_TN', 'N_STOCK_FINAL', 'N_MEDIA_MOVIL_3M', 'VOLAT_REL_3M',\n",
    "       'N_TN_LAG_01', 'N_TN_LAG_02', 'N_TN_LAG_03', 'N_TN_LAG_06',\n",
    "       'N_TN_LAG_12', 'N_TN_DELTA_01',\n",
    "       'N_TN_DELTA_02', 'N_TN_DELTA_03', 'N_TN_DELTA_06', 'N_TN_DELTA_12','MES_PROBLEMATICO']]\n",
    "y = df_full['N_CLASE_DELTA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c21070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los periodos de validación 201909, 201910\n",
    "periodos_valid = [201909,201910]\n",
    "\n",
    "\n",
    "# Separar train y cinco conjuntos de validación respetando la secuencia temporal\n",
    "X_train = X[X['PERIODO'] < periodos_valid[0]]\n",
    "y_train = y[X['PERIODO'] < periodos_valid[0]]\n",
    "\n",
    "X_val_list = [X[X['PERIODO'] == p] for p in periodos_valid]\n",
    "y_val_list = [y[X['PERIODO'] == p] for p in periodos_valid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Solo selecciona las variables numéricas para la correlación\n",
    "X_numericas = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calcula la matriz de correlación\n",
    "corr_matrix = X_numericas.corr()\n",
    "\n",
    "\n",
    "# Visualiza la matriz de correlación como un mapa de calor\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de correlación entre variables numéricas\")\n",
    "plt.show()\n",
    "\n",
    "# Opcional: muestra pares de variables con correlación fuerte\n",
    "umbral = 0.7\n",
    "correlaciones_fuertes = corr_matrix.abs().unstack().sort_values(ascending=False)\n",
    "correlaciones_fuertes = correlaciones_fuertes[(correlaciones_fuertes < 1) & (correlaciones_fuertes > umbral)]\n",
    "print(\"Pares de variables con correlación fuerte (> 0.7):\")\n",
    "print(correlaciones_fuertes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Crear los datasets de LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "val_data_list = [lgb.Dataset(X_val_list[i], label=y_val_list[i], categorical_feature=categorical_features) for i in range(len(periodos_valid))]\n",
    "\n",
    "# Definir parámetros para regresión\n",
    "params = { \n",
    "    'objective': 'regression',\n",
    "    'metric':['mae', 'rmse'],  # Monitorea ambas métricas\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 4095,\n",
    "    'learning_rate': 0.0001,\n",
    "    'feature_fraction': 0.95,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenar el modelo con validación múltiple y early stopping\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=50000,\n",
    "    valid_sets=val_data_list,\n",
    "    valid_names=[f'validation_{p}' for p in periodos_valid],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=2000), lgb.log_evaluation(period=500)]\n",
    ")\n",
    "\n",
    "print(\"Modelo de regresión entrenado con cinco conjuntos de validación (uno por cada periodo 201906-201910).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de cada variable\n",
    "importancia = model.feature_importance(importance_type='gain')\n",
    "nombres = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado por importancia\n",
    "import pandas as pd\n",
    "df_importancia = pd.DataFrame({'feature': nombres, 'importance': importancia})\n",
    "df_importancia = df_importancia.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "print(df_importancia)\n",
    "\n",
    "# Si quieres visualizarlo gráficamente:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df_importancia['feature'], df_importancia['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Importancia de variables LightGBM')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02240a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el modelo entrenado\n",
    "model.save_model('standarizacion_L_VW_N_COMPLETA.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from PC.L_VW_N_COMPLETA where periodo = 201912\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_pred_full = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las variables categóricas a tipo 'category'\n",
    "for col in categorical_features:\n",
    "    df_pred_full[col] = df_pred_full[col].astype('category')\n",
    "\n",
    "# Con el modelo entrenado, hacemos predicciones \n",
    "X_pred = df_pred_full[['ORDINAL', 'PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', 'ID_CAT2',\n",
    "       'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID', 'PRODUCT_ID',\n",
    "       'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY', 'N_CUST_REQUEST_TN',\n",
    "       'N_TN', 'N_STOCK_FINAL', 'N_MEDIA_MOVIL_3M', 'VOLAT_REL_3M',\n",
    "       'N_TN_LAG_01', 'N_TN_LAG_02', 'N_TN_LAG_03', 'N_TN_LAG_06',\n",
    "       'N_TN_LAG_12', 'N_TN_DELTA_01',\n",
    "       'N_TN_DELTA_02', 'N_TN_DELTA_03', 'N_TN_DELTA_06', 'N_TN_DELTA_12']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(X_pred)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['PREDICCIONES'] = predictions\n",
    "# Imprimir las primeras filas del DataFrame con las predicciones\n",
    "print(df_pred_full.head())\n",
    "# Guardar el DataFrame con las predicciones en un archivo CSV\n",
    "df_pred_full.to_csv('predicciones.csv', index=False)\n",
    "# Imprimir el número de filas y columnas del DataFrame con las predicciones\n",
    "print(f\"Número de filas: {df_pred_full.shape[0]}, Número de columnas: {df_pred_full.shape[1]} con predicciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select product_id,desvio_tn, media_tn from PC.L_PRODUCTOS join PC.L_PRODUCTOS_A_PREDECIR using(product_id) order by 1\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_desvios_productos = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()\n",
    "medias = df_desvios_productos.set_index('PRODUCT_ID')['MEDIA_TN'].to_dict()\n",
    "desvios = df_desvios_productos.set_index('PRODUCT_ID')['DESVIO_TN'].to_dict()\n",
    "print(desvios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos para actualizar los datos de predicción\n",
    "conn = cx_Oracle.connect(user=\"pc\", password=\"p201404\", dsn=\"siatchdesa\")\n",
    "# Crear un cursor para ejecutar las actualizaciones\n",
    "cursor = conn.cursor()\n",
    "update_query = \"\"\"\n",
    "    UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "    SET PREDICCION = NULL\n",
    "\"\"\"\n",
    "cursor.execute(update_query)\n",
    "# Hacer commit para aplicar el cambio de NULL\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imprimir mensaje de inicio de actualización\n",
    "print(\"Iniciando actualización de la tabla L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "\n",
    "# Iterar sobre las filas del DataFrame con las predicciones\n",
    "for index, row in df_pred_full.iterrows():\n",
    "    periodo = row['PERIODO']\n",
    "    customer_id = row['CUSTOMER_ID']\n",
    "    product_id = row['PRODUCT_ID']\n",
    "    # Invierto la standarizacion de TN tomando la media de TN del dataframe de desvios con los productos\n",
    "    tn_media = medias[product_id]\n",
    "    desvio_tn = desvios[product_id]\n",
    "    # La TN se calcula como la media de TN del dataframe de desvios con los productos\n",
    "    tn = row['N_TN'] * desvio_tn + tn_media\n",
    "    # La predicción se calcula como la suma de TN y las predicciones * desvio_tn del dataframe de desvios con los productos\n",
    "    prediccion = tn + row['PREDICCIONES'] * desvio_tn\n",
    "    # Actualizar la tabla L_DATOS_PREDICCION con la nueva predicción\n",
    "    update_query = \"\"\"\n",
    "        UPDATE L_VM_COMPLETA_PREDICCIONES\n",
    "        SET PREDICCION = :prediccion\n",
    "        WHERE PERIODO = :periodo AND CUSTOMER_ID = :customer_id AND PRODUCT_ID = :product_id\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, {'prediccion': prediccion, 'periodo': periodo, 'customer_id': customer_id, 'product_id': product_id})  \n",
    "    # Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "    if index % 10000 == 0:\n",
    "        conn.commit()\n",
    "        print(f\"Actualizadas {index} filas de L_VM_COMPLETA_PREDICCIONES con las nuevas predicciones.\")\n",
    "# Confirmar los cambios en la base de datos\n",
    "conn.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "# Imprimir mensaje de finalización\n",
    "print(\"Actualización de la tabla  completada con las nuevas predicciones.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
