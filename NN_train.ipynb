{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet('./data/train_val_NN_TORCH.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'CLASE_DELTA_LOG1P_Z'\n",
    "\n",
    "# Columnas categóricas a embeddings\n",
    "cat_cols = ['ID_CAT1', 'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE',\n",
    "            'CUSTOMER_RANK_BIN', 'PRODUCT_RANK_BIN']\n",
    "\n",
    "# Codificación para embeddings\n",
    "for col in cat_cols:\n",
    "    df_full[col] = df_full[col].astype('category').cat.codes\n",
    "\n",
    "# Excluir columnas que no deben ir al modelo\n",
    "excluir = ['PERIODO', 'CUSTOMER_ID', 'PRODUCT_ID', 'CLASE_DELTA_LOG1P_Z', 'ORDINAL']\n",
    "\n",
    "# Features numéricas normalizadas\n",
    "feature_cols = [col for col in df_full.columns if col.endswith('_Z') and col not in excluir]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No los incluyas en ninguna de estas dos listas\n",
    "assert 'CUSTOMER_ID' not in feature_cols\n",
    "assert 'CUSTOMER_ID' not in cat_cols\n",
    "assert 'PRODUCT_ID' not in feature_cols\n",
    "assert 'PRODUCT_ID' not in cat_cols\n",
    "assert 'PERIODO' not in feature_cols\n",
    "assert 'PERIODO' not in cat_cols\n",
    "assert 'CLASE_DELTA_LOG1P_Z' not in feature_cols\n",
    "assert 'CLASE_DELTA_LOG1P_Z' not in cat_cols\n",
    "assert 'ORDINAL' not in feature_cols\n",
    "assert 'ORDINAL' not in cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c143415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar conjuntos\n",
    "df_train = df_full[df_full['PERIODO'] <= 201908].copy()\n",
    "df_val = df_full[(df_full['PERIODO'] >= 201909) & (df_full['PERIODO'] <= 201910)].copy()\n",
    "df_pred = df_full[df_full['PERIODO'] == 201912].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df, cat_cols, num_cols, target_col=None):\n",
    "        self.cat_data = torch.tensor(df[cat_cols].values, dtype=torch.long)\n",
    "        self.num_data = torch.tensor(df[num_cols].values, dtype=torch.float32)\n",
    "        self.has_target = target_col is not None\n",
    "        if self.has_target:\n",
    "            self.y = torch.tensor(df[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "        else:\n",
    "            self.y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cat_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_target:\n",
    "            return self.cat_data[idx], self.num_data[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.cat_data[idx], self.num_data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch.nn as nn\n",
    "\n",
    "class WeightedMAELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super(WeightedMAELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        weights = 1.0 + torch.abs(y_true)\n",
    "        loss = weights * torch.abs(y_pred - y_true)\n",
    "        return loss.mean() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" class NonlinearWeightedMSELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        error = pred - target\n",
    "        weights = 1.0 + self.alpha * torch.abs(target)\n",
    "        return torch.mean(weights * error ** 2)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch.nn.functional as F\n",
    "\n",
    "class CustomWeightedLoss(nn.Module):\n",
    "    def __init__(self, tn_index: int, alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.tn_index = tn_index\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, preds, targets, x_num):\n",
    "        tn_values = x_num[:, self.tn_index]\n",
    "        weights = 1 + self.alpha * tn_values.abs()\n",
    "        loss = (weights * (preds - targets).pow(2)).mean()\n",
    "        return loss \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50723c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELossMulti(nn.Module):\n",
    "    def __init__(self, penalty_indices, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.penalty_indices = penalty_indices\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, preds, targets, x_num):\n",
    "        penalty = 1 + self.alpha * sum(x_num[:, i].abs() for i in self.penalty_indices)\n",
    "        error = (preds.squeeze() - targets.squeeze()) ** 2\n",
    "        return (penalty * error).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad019ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_cols = ['TN_Z', 'TN_LAG_01_Z', 'TN_LAG_02_Z', 'TN_LAG_03_Z', 'TN_LAG_04_Z','TN_LAG_05_Z','TN_LAG_06_Z','TN_LAG_07_Z',\n",
    "'TN_LAG_08_Z','TN_LAG_09_Z','TN_LAG_10_Z','TN_LAG_11_Z','TN_LAG_12_Z']\n",
    "penalty_indices = [feature_cols.index(col) for col in penalty_cols]\n",
    "print(penalty_cols)\n",
    "print(penalty_indices)\n",
    "loss_fn = WeightedMSELossMulti(penalty_indices=penalty_cols, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c637b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(col in df_train.columns for col in cat_cols), \"Faltan columnas categóricas\"\n",
    "assert all(col in df_train.columns for col in feature_cols), \"Faltan columnas numéricas\"\n",
    "assert target_col in df_train.columns, \"Falta la variable objetivo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd112c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = TabularDataset(df_train, cat_cols, feature_cols, target_col)\n",
    "val_dataset = TabularDataset(df_val, cat_cols, feature_cols, target_col)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TabularNNImproved(nn.Module):\n",
    "    def __init__(self, embedding_sizes, num_numerical, hidden_sizes=[512, 512, 256, 128], dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(ni, nf) for ni, nf in embedding_sizes\n",
    "        ])\n",
    "        embedding_dim = sum([nf for _, nf in embedding_sizes])\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Total input size after embedding + numerical\n",
    "        input_size = embedding_dim + num_numerical\n",
    "\n",
    "        # Hidden layers\n",
    "        layers = []\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_size = h\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(input_size, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = torch.cat([x, x_num], dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Detectar si hay GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Definir tamaños de embedding\n",
    "embedding_sizes = [\n",
    "    (df_full[col].nunique() + 1, min(50, (df_full[col].nunique() + 1) // 2))\n",
    "    for col in cat_cols\n",
    "]\n",
    "\n",
    "# Crear el modelo\n",
    "model = TabularNNImproved(\n",
    "    embedding_sizes=embedding_sizes,\n",
    "    num_numerical=len(feature_cols),\n",
    "    hidden_sizes=[4096,2048,1024,512, 512, 256, 128],\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_data=[torch.zeros(1, len(cat_cols), dtype=torch.long).to(device),\n",
    "                           torch.zeros(1, len(feature_cols)).to(device)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8314c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, train_loader, val_loader, n_epochs=20, lr=1e-3, alpha=0.5, patience=3, penalty_indices=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #criterion = CustomWeightedLoss(tn_index=7, alpha=0.5)\n",
    "    criterion = WeightedMSELossMulti(penalty_indices=penalty_indices,alpha=0.5)\n",
    "    #criterion = NonlinearWeightedMSELoss(alpha=0.5)  # podés ajustar alpha  #WeightedMSELoss(alpha=alpha)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for cats, conts, y in train_loader:\n",
    "            cats, conts, y = cats.to(device), conts.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(cats, conts)\n",
    "            loss = criterion(y_pred, y, conts)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * y.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for cats, conts, y in val_loader:\n",
    "                cats, conts, y = cats.to(device), conts.to(device), y.to(device)\n",
    "                y_pred = model(cats, conts)\n",
    "                loss = criterion(y_pred, y, conts)\n",
    "                val_loss += loss.item() * y.size(0)\n",
    "\n",
    "                y_true_list.append(y.cpu().numpy())\n",
    "                y_pred_list.append(y_pred.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        y_true = np.concatenate(y_true_list)\n",
    "        y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"🔴 Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # Restaurar el mejor modelo\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Retornar valores verdaderos y predichos del último paso\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b6b5a",
   "metadata": {},
   "source": [
    "# Búsqueda de hiperparámetros (Grid Search)\n",
    "Probamos distintas combinaciones de hiperparámetros y seleccionamos la que da mejor MAE en validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from itertools import product\n",
    "\n",
    "# Definir el espacio de búsqueda\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'hidden_sizes': [\n",
    "        [1024, 512, 256],\n",
    "        [2048, 1024, 512, 256]\n",
    "    ],\n",
    "    'alpha': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "# Generar todas las combinaciones\n",
    "param_combinations = list(product(\n",
    "    param_grid['lr'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['hidden_sizes'],\n",
    "    param_grid['alpha']\n",
    "))\n",
    "\n",
    "results = []\n",
    "for lr, dropout, hidden_sizes, alpha in param_combinations:\n",
    "    # Crear modelo\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    # Entrenar modelo (menos épocas para grid search)\n",
    "    y_true_gs, y_pred_gs = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        n_epochs=8, lr=lr, alpha=alpha, patience=2\n",
    "    )\n",
    "    mae = mean_absolute_error(y_true_gs, y_pred_gs)\n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'dropout': dropout,\n",
    "        'hidden_sizes': hidden_sizes,\n",
    "        'alpha': alpha,\n",
    "        'mae': mae\n",
    "    })\n",
    "    print(f\"Params: lr={lr}, dropout={dropout}, hidden_sizes={hidden_sizes}, alpha={alpha} -> MAE={mae:.4f}\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.enabled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040764c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Definir el espacio de búsqueda\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'hidden_sizes': [\n",
    "        [1024, 512, 256],\n",
    "        [2048, 1024, 512, 256]\n",
    "    ],\n",
    "    'alpha': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "# Generar todas las combinaciones posibles\n",
    "param_combinations = list(product(\n",
    "    param_grid['lr'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['hidden_sizes'],\n",
    "    param_grid['alpha']\n",
    "))\n",
    "\n",
    "results = []\n",
    "best_mae = float('inf')\n",
    "\n",
    "# Loop de entrenamiento por combinación\n",
    "for lr, dropout, hidden_sizes, alpha in param_combinations:\n",
    "    print(f\"\\n🔧 Entrenando con: lr={lr}, dropout={dropout}, hidden_sizes={hidden_sizes}, alpha={alpha}\")\n",
    "\n",
    "    # Crear modelo y mover a dispositivo\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    # Entrenamiento corto para tuning\n",
    "    y_true_gs, y_pred_gs = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        n_epochs=8, lr=lr, alpha=alpha, patience=2,penalty_indices=penalty_indices\n",
    "    )\n",
    "\n",
    "    mae = mean_absolute_error(y_true_gs, y_pred_gs)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'dropout': dropout,\n",
    "        'hidden_sizes': hidden_sizes,\n",
    "        'alpha': alpha,\n",
    "        'mae': mae\n",
    "    })\n",
    "\n",
    "    print(f\"✅ MAE = {mae:.4f}\")\n",
    "\n",
    "    # Guardar modelo si es el mejor\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        torch.save(model.state_dict(), f\"best_model_mae{mae:.4f}_lr{lr}_do{dropout}_a{alpha}.pth\")\n",
    "        print(\"💾 Modelo guardado (mejor hasta ahora)\")\n",
    "\n",
    "    # Limpiar memoria GPU\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Convertir a DataFrame y mostrar top 5\n",
    "results_df = pd.DataFrame(results).sort_values(by='mae')\n",
    "print(\"\\n📊 Mejores combinaciones:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Guardar resultados a disco\n",
    "results_df.to_csv(\"gridsearch_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar las 3 mejores combinación de cara a un ensemble\n",
    "results.sort(key=lambda x: x['mae'])\n",
    "print(\"\\nResultados ordenados por MAE:\")\n",
    "for res in results:\n",
    "    print(f\"Params: lr={res['lr']}, dropout={res['dropout']}, hidden_sizes={res['hidden_sizes']}, alpha={res['alpha']} -> MAE={res['mae']:.4f}\")\n",
    "#best_params = min(results, key=lambda x: x['mae'])\n",
    "#print(\"Mejores hiperparámetros encontrados:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11892c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 🔧 Tus parámetros finales para los 3 mejores modelos\n",
    "model_configs = [\n",
    "    {\n",
    "        \"name\": \"modelo_m1\",\n",
    "        \"hidden_sizes\": [1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.001,\n",
    "        \"alpha\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"modelo_m2\",\n",
    "        \"hidden_sizes\": [2048, 1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.0005,\n",
    "        \"alpha\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"modelo_m3\",\n",
    "        \"hidden_sizes\": [1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.0005,\n",
    "        \"alpha\": 0.3\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "# 📦 Dataset completo ya procesado\n",
    "# Usamos el mismo dataset de entrenamiento ya creado\n",
    "# Concatenar train_dataset y val_dataset\n",
    "train_val_dataset = ConcatDataset([train_dataset, val_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5155bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_full = DataLoader(train_val_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d59636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🧠 Función de pérdida personalizada\n",
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae = torch.nn.L1Loss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        base_loss = self.mae(preds, targets)\n",
    "        penalty = torch.mean(torch.abs(targets))  # o cualquier criterio adicional\n",
    "        return (1 - self.alpha) * base_loss + self.alpha * penalty\n",
    "\n",
    "# 🚂 Función de entrenamiento final sin validación\n",
    "def train_final_model(model, train_loader, n_epochs=20, lr=0.001, alpha=0.3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = CustomLoss(alpha=alpha)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for X_cat, X_num, y_batch in train_loader:\n",
    "            X_cat, X_num, y_batch = X_cat.to(device), X_num.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_cat, X_num)\n",
    "            #loss = loss_fn(preds.squeeze(), y_batch)\n",
    "            loss = loss_fn(preds.squeeze(), y_batch.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"[{model.__class__.__name__}] Epoch {epoch+1}/{n_epochs} | Train Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ⚙️ Entrenamiento de los 3 modelos\n",
    "for cfg in model_configs:\n",
    "    print(f\"\\n🔵 Entrenando {cfg['name']}...\")\n",
    "\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=cfg[\"hidden_sizes\"],\n",
    "        dropout=cfg[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    model = train_final_model(\n",
    "        model,\n",
    "        train_loader=train_loader_full,\n",
    "        n_epochs=20,\n",
    "        lr=cfg[\"lr\"],\n",
    "        alpha=cfg[\"alpha\"]\n",
    "    )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{cfg['name']}.pth\")\n",
    "    print(f\"✅ Modelo {cfg['name']} guardado.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b12318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 📌 Filtrar periodo 201912\n",
    "df_pred = df_full[df_full[\"PERIODO\"] == 201912].copy()\n",
    "print(df_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🚧 Preparar inputs\n",
    "X_cat_pred = torch.tensor(df_pred[cat_cols].values, dtype=torch.long)\n",
    "X_num_pred = torch.tensor(df_pred[numerical_cols].values, dtype=torch.float)\n",
    "\n",
    "# 📦 Dataset y DataLoader sin target\n",
    "pred_dataset = TensorDataset(X_cat_pred, X_num_pred)\n",
    "pred_loader = DataLoader(pred_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# 📁 Modelos a cargar\n",
    "model_paths = [\n",
    "    (\"modelo_m1\", [1024, 512, 256]),\n",
    "    (\"modelo_m2\", [2048, 1024, 512, 256]),\n",
    "    (\"modelo_m3\", [1024, 512, 256]),\n",
    "]\n",
    "\n",
    "# 🧠 Clase del modelo: asegurate de tener TabularNNImproved definido\n",
    "\n",
    "# 📤 Función para predecir\n",
    "def predict_model(path, hidden_sizes):\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(numerical_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"{path}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_cat_batch, X_num_batch in pred_loader:\n",
    "            X_cat_batch = X_cat_batch.to(device)\n",
    "            X_num_batch = X_num_batch.to(device)\n",
    "            outputs = model(X_cat_batch, X_num_batch).squeeze().cpu().numpy()\n",
    "            preds.extend(outputs)\n",
    "    return np.array(preds)\n",
    "\n",
    "# 🔁 Predecir con los 3 modelos\n",
    "preds_dict = {}\n",
    "for name, h_sizes in model_paths:\n",
    "    print(f\"📡 Prediciendo con {name}...\")\n",
    "    preds_dict[name] = predict_model(name, h_sizes)\n",
    "\n",
    "# 🔀 Ensemble (promedio)\n",
    "ensemble_pred = np.mean(np.stack(list(preds_dict.values()), axis=0), axis=0)\n",
    "\n",
    "# ✅ Guardar predicciones\n",
    "df_pred[\"PRED_LOG1P_Z\"] = ensemble_pred\n",
    "\n",
    "# (Opcional) si querés ver distribución\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ensemble_pred, bins=100)\n",
    "plt.title(\"Distribución de predicciones (log1p z-score)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
