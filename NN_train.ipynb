{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet('./data/train_val_NN_TORCH.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'CLASE_DELTA_LOG1P_Z'\n",
    "\n",
    "# Columnas categ√≥ricas a embeddings\n",
    "cat_cols = ['ID_CAT1', 'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE',\n",
    "            'CUSTOMER_RANK_BIN', 'PRODUCT_RANK_BIN']\n",
    "\n",
    "# Codificaci√≥n para embeddings\n",
    "for col in cat_cols:\n",
    "    df_full[col] = df_full[col].astype('category').cat.codes\n",
    "\n",
    "# Excluir columnas que no deben ir al modelo\n",
    "excluir = ['PERIODO', 'CUSTOMER_ID', 'PRODUCT_ID', 'CLASE_DELTA_LOG1P_Z', 'ORDINAL']\n",
    "\n",
    "# Features num√©ricas normalizadas\n",
    "feature_cols = [col for col in df_full.columns if col.endswith('_Z') and col not in excluir]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No los incluyas en ninguna de estas dos listas\n",
    "assert 'CUSTOMER_ID' not in feature_cols\n",
    "assert 'CUSTOMER_ID' not in cat_cols\n",
    "assert 'PRODUCT_ID' not in feature_cols\n",
    "assert 'PRODUCT_ID' not in cat_cols\n",
    "assert 'PERIODO' not in feature_cols\n",
    "assert 'PERIODO' not in cat_cols\n",
    "assert 'CLASE_DELTA_LOG1P_Z' not in feature_cols\n",
    "assert 'CLASE_DELTA_LOG1P_Z' not in cat_cols\n",
    "assert 'ORDINAL' not in feature_cols\n",
    "assert 'ORDINAL' not in cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c143415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar conjuntos\n",
    "df_train = df_full[df_full['PERIODO'] <= 201908].copy()\n",
    "df_val = df_full[(df_full['PERIODO'] >= 201909) & (df_full['PERIODO'] <= 201910)].copy()\n",
    "df_pred = df_full[df_full['PERIODO'] == 201912].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df, cat_cols, num_cols, target_col=None):\n",
    "        self.cat_data = torch.tensor(df[cat_cols].values, dtype=torch.long)\n",
    "        self.num_data = torch.tensor(df[num_cols].values, dtype=torch.float32)\n",
    "        self.has_target = target_col is not None\n",
    "        if self.has_target:\n",
    "            self.y = torch.tensor(df[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "        else:\n",
    "            self.y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cat_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_target:\n",
    "            return self.cat_data[idx], self.num_data[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.cat_data[idx], self.num_data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch.nn as nn\n",
    "\n",
    "class WeightedMAELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super(WeightedMAELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        weights = 1.0 + torch.abs(y_true)\n",
    "        loss = weights * torch.abs(y_pred - y_true)\n",
    "        return loss.mean() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" class NonlinearWeightedMSELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        error = pred - target\n",
    "        weights = 1.0 + self.alpha * torch.abs(target)\n",
    "        return torch.mean(weights * error ** 2)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch.nn.functional as F\n",
    "\n",
    "class CustomWeightedLoss(nn.Module):\n",
    "    def __init__(self, tn_index: int, alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.tn_index = tn_index\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, preds, targets, x_num):\n",
    "        tn_values = x_num[:, self.tn_index]\n",
    "        weights = 1 + self.alpha * tn_values.abs()\n",
    "        loss = (weights * (preds - targets).pow(2)).mean()\n",
    "        return loss \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50723c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELossMulti(nn.Module):\n",
    "    def __init__(self, penalty_indices, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.penalty_indices = penalty_indices\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, preds, targets, x_num):\n",
    "        penalty = 1 + self.alpha * sum(x_num[:, i].abs() for i in self.penalty_indices)\n",
    "        error = (preds.squeeze() - targets.squeeze()) ** 2\n",
    "        return (penalty * error).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad019ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_cols = ['TN_Z', 'TN_LAG_01_Z', 'TN_LAG_02_Z', 'TN_LAG_03_Z', 'TN_LAG_04_Z','TN_LAG_05_Z','TN_LAG_06_Z','TN_LAG_07_Z',\n",
    "'TN_LAG_08_Z','TN_LAG_09_Z','TN_LAG_10_Z','TN_LAG_11_Z','TN_LAG_12_Z']\n",
    "penalty_indices = [feature_cols.index(col) for col in penalty_cols]\n",
    "print(penalty_cols)\n",
    "print(penalty_indices)\n",
    "loss_fn = WeightedMSELossMulti(penalty_indices=penalty_cols, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c637b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(col in df_train.columns for col in cat_cols), \"Faltan columnas categ√≥ricas\"\n",
    "assert all(col in df_train.columns for col in feature_cols), \"Faltan columnas num√©ricas\"\n",
    "assert target_col in df_train.columns, \"Falta la variable objetivo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd112c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = TabularDataset(df_train, cat_cols, feature_cols, target_col)\n",
    "val_dataset = TabularDataset(df_val, cat_cols, feature_cols, target_col)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TabularNNImproved(nn.Module):\n",
    "    def __init__(self, embedding_sizes, num_numerical, hidden_sizes=[512, 512, 256, 128], dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(ni, nf) for ni, nf in embedding_sizes\n",
    "        ])\n",
    "        embedding_dim = sum([nf for _, nf in embedding_sizes])\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Total input size after embedding + numerical\n",
    "        input_size = embedding_dim + num_numerical\n",
    "\n",
    "        # Hidden layers\n",
    "        layers = []\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_size = h\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(input_size, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = torch.cat([x, x_num], dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Detectar si hay GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Definir tama√±os de embedding\n",
    "embedding_sizes = [\n",
    "    (df_full[col].nunique() + 1, min(50, (df_full[col].nunique() + 1) // 2))\n",
    "    for col in cat_cols\n",
    "]\n",
    "\n",
    "# Crear el modelo\n",
    "model = TabularNNImproved(\n",
    "    embedding_sizes=embedding_sizes,\n",
    "    num_numerical=len(feature_cols),\n",
    "    hidden_sizes=[4096,2048,1024,512, 512, 256, 128],\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_data=[torch.zeros(1, len(cat_cols), dtype=torch.long).to(device),\n",
    "                           torch.zeros(1, len(feature_cols)).to(device)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8314c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, train_loader, val_loader, n_epochs=20, lr=1e-3, alpha=0.5, patience=3, penalty_indices=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #criterion = CustomWeightedLoss(tn_index=7, alpha=0.5)\n",
    "    criterion = WeightedMSELossMulti(penalty_indices=penalty_indices,alpha=0.5)\n",
    "    #criterion = NonlinearWeightedMSELoss(alpha=0.5)  # pod√©s ajustar alpha  #WeightedMSELoss(alpha=alpha)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for cats, conts, y in train_loader:\n",
    "            cats, conts, y = cats.to(device), conts.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(cats, conts)\n",
    "            loss = criterion(y_pred, y, conts)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * y.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for cats, conts, y in val_loader:\n",
    "                cats, conts, y = cats.to(device), conts.to(device), y.to(device)\n",
    "                y_pred = model(cats, conts)\n",
    "                loss = criterion(y_pred, y, conts)\n",
    "                val_loss += loss.item() * y.size(0)\n",
    "\n",
    "                y_true_list.append(y.cpu().numpy())\n",
    "                y_pred_list.append(y_pred.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        y_true = np.concatenate(y_true_list)\n",
    "        y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | MAE: {mae:.4f} | R¬≤: {r2:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"üî¥ Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # Restaurar el mejor modelo\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Retornar valores verdaderos y predichos del √∫ltimo paso\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b6b5a",
   "metadata": {},
   "source": [
    "# B√∫squeda de hiperpar√°metros (Grid Search)\n",
    "Probamos distintas combinaciones de hiperpar√°metros y seleccionamos la que da mejor MAE en validaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from itertools import product\n",
    "\n",
    "# Definir el espacio de b√∫squeda\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'hidden_sizes': [\n",
    "        [1024, 512, 256],\n",
    "        [2048, 1024, 512, 256]\n",
    "    ],\n",
    "    'alpha': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "# Generar todas las combinaciones\n",
    "param_combinations = list(product(\n",
    "    param_grid['lr'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['hidden_sizes'],\n",
    "    param_grid['alpha']\n",
    "))\n",
    "\n",
    "results = []\n",
    "for lr, dropout, hidden_sizes, alpha in param_combinations:\n",
    "    # Crear modelo\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    # Entrenar modelo (menos √©pocas para grid search)\n",
    "    y_true_gs, y_pred_gs = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        n_epochs=8, lr=lr, alpha=alpha, patience=2\n",
    "    )\n",
    "    mae = mean_absolute_error(y_true_gs, y_pred_gs)\n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'dropout': dropout,\n",
    "        'hidden_sizes': hidden_sizes,\n",
    "        'alpha': alpha,\n",
    "        'mae': mae\n",
    "    })\n",
    "    print(f\"Params: lr={lr}, dropout={dropout}, hidden_sizes={hidden_sizes}, alpha={alpha} -> MAE={mae:.4f}\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.enabled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040764c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Definir el espacio de b√∫squeda\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'hidden_sizes': [\n",
    "        [1024, 512, 256],\n",
    "        [2048, 1024, 512, 256]\n",
    "    ],\n",
    "    'alpha': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "# Generar todas las combinaciones posibles\n",
    "param_combinations = list(product(\n",
    "    param_grid['lr'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['hidden_sizes'],\n",
    "    param_grid['alpha']\n",
    "))\n",
    "\n",
    "results = []\n",
    "best_mae = float('inf')\n",
    "\n",
    "# Loop de entrenamiento por combinaci√≥n\n",
    "for lr, dropout, hidden_sizes, alpha in param_combinations:\n",
    "    print(f\"\\nüîß Entrenando con: lr={lr}, dropout={dropout}, hidden_sizes={hidden_sizes}, alpha={alpha}\")\n",
    "\n",
    "    # Crear modelo y mover a dispositivo\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    # Entrenamiento corto para tuning\n",
    "    y_true_gs, y_pred_gs = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        n_epochs=8, lr=lr, alpha=alpha, patience=2,penalty_indices=penalty_indices\n",
    "    )\n",
    "\n",
    "    mae = mean_absolute_error(y_true_gs, y_pred_gs)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'dropout': dropout,\n",
    "        'hidden_sizes': hidden_sizes,\n",
    "        'alpha': alpha,\n",
    "        'mae': mae\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ MAE = {mae:.4f}\")\n",
    "\n",
    "    # Guardar modelo si es el mejor\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        torch.save(model.state_dict(), f\"best_model_mae{mae:.4f}_lr{lr}_do{dropout}_a{alpha}.pth\")\n",
    "        print(\"üíæ Modelo guardado (mejor hasta ahora)\")\n",
    "\n",
    "    # Limpiar memoria GPU\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Convertir a DataFrame y mostrar top 5\n",
    "results_df = pd.DataFrame(results).sort_values(by='mae')\n",
    "print(\"\\nüìä Mejores combinaciones:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Guardar resultados a disco\n",
    "results_df.to_csv(\"gridsearch_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar las 3 mejores combinaci√≥n de cara a un ensemble\n",
    "results.sort(key=lambda x: x['mae'])\n",
    "print(\"\\nResultados ordenados por MAE:\")\n",
    "for res in results:\n",
    "    print(f\"Params: lr={res['lr']}, dropout={res['dropout']}, hidden_sizes={res['hidden_sizes']}, alpha={res['alpha']} -> MAE={res['mae']:.4f}\")\n",
    "#best_params = min(results, key=lambda x: x['mae'])\n",
    "#print(\"Mejores hiperpar√°metros encontrados:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11892c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# üîß Tus par√°metros finales para los 3 mejores modelos\n",
    "model_configs = [\n",
    "    {\n",
    "        \"name\": \"modelo_m1\",\n",
    "        \"hidden_sizes\": [1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.001,\n",
    "        \"alpha\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"modelo_m2\",\n",
    "        \"hidden_sizes\": [2048, 1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.0005,\n",
    "        \"alpha\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"modelo_m3\",\n",
    "        \"hidden_sizes\": [1024, 512, 256],\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 0.0005,\n",
    "        \"alpha\": 0.3\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "# üì¶ Dataset completo ya procesado\n",
    "# Usamos el mismo dataset de entrenamiento ya creado\n",
    "# Concatenar train_dataset y val_dataset\n",
    "train_val_dataset = ConcatDataset([train_dataset, val_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5155bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_full = DataLoader(train_val_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d59636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üß† Funci√≥n de p√©rdida personalizada\n",
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae = torch.nn.L1Loss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        base_loss = self.mae(preds, targets)\n",
    "        penalty = torch.mean(torch.abs(targets))  # o cualquier criterio adicional\n",
    "        return (1 - self.alpha) * base_loss + self.alpha * penalty\n",
    "\n",
    "# üöÇ Funci√≥n de entrenamiento final sin validaci√≥n\n",
    "def train_final_model(model, train_loader, n_epochs=20, lr=0.001, alpha=0.3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = CustomLoss(alpha=alpha)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for X_cat, X_num, y_batch in train_loader:\n",
    "            X_cat, X_num, y_batch = X_cat.to(device), X_num.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_cat, X_num)\n",
    "            #loss = loss_fn(preds.squeeze(), y_batch)\n",
    "            loss = loss_fn(preds.squeeze(), y_batch.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"[{model.__class__.__name__}] Epoch {epoch+1}/{n_epochs} | Train Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ‚öôÔ∏è Entrenamiento de los 3 modelos\n",
    "for cfg in model_configs:\n",
    "    print(f\"\\nüîµ Entrenando {cfg['name']}...\")\n",
    "\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(feature_cols),\n",
    "        hidden_sizes=cfg[\"hidden_sizes\"],\n",
    "        dropout=cfg[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    model = train_final_model(\n",
    "        model,\n",
    "        train_loader=train_loader_full,\n",
    "        n_epochs=20,\n",
    "        lr=cfg[\"lr\"],\n",
    "        alpha=cfg[\"alpha\"]\n",
    "    )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{cfg['name']}.pth\")\n",
    "    print(f\"‚úÖ Modelo {cfg['name']} guardado.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b12318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# üìå Filtrar periodo 201912\n",
    "df_pred = df_full[df_full[\"PERIODO\"] == 201912].copy()\n",
    "print(df_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üöß Preparar inputs\n",
    "X_cat_pred = torch.tensor(df_pred[cat_cols].values, dtype=torch.long)\n",
    "X_num_pred = torch.tensor(df_pred[numerical_cols].values, dtype=torch.float)\n",
    "\n",
    "# üì¶ Dataset y DataLoader sin target\n",
    "pred_dataset = TensorDataset(X_cat_pred, X_num_pred)\n",
    "pred_loader = DataLoader(pred_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# üìÅ Modelos a cargar\n",
    "model_paths = [\n",
    "    (\"modelo_m1\", [1024, 512, 256]),\n",
    "    (\"modelo_m2\", [2048, 1024, 512, 256]),\n",
    "    (\"modelo_m3\", [1024, 512, 256]),\n",
    "]\n",
    "\n",
    "# üß† Clase del modelo: asegurate de tener TabularNNImproved definido\n",
    "\n",
    "# üì§ Funci√≥n para predecir\n",
    "def predict_model(path, hidden_sizes):\n",
    "    model = TabularNNImproved(\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        num_numerical=len(numerical_cols),\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"{path}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_cat_batch, X_num_batch in pred_loader:\n",
    "            X_cat_batch = X_cat_batch.to(device)\n",
    "            X_num_batch = X_num_batch.to(device)\n",
    "            outputs = model(X_cat_batch, X_num_batch).squeeze().cpu().numpy()\n",
    "            preds.extend(outputs)\n",
    "    return np.array(preds)\n",
    "\n",
    "# üîÅ Predecir con los 3 modelos\n",
    "preds_dict = {}\n",
    "for name, h_sizes in model_paths:\n",
    "    print(f\"üì° Prediciendo con {name}...\")\n",
    "    preds_dict[name] = predict_model(name, h_sizes)\n",
    "\n",
    "# üîÄ Ensemble (promedio)\n",
    "ensemble_pred = np.mean(np.stack(list(preds_dict.values()), axis=0), axis=0)\n",
    "\n",
    "# ‚úÖ Guardar predicciones\n",
    "df_pred[\"PRED_LOG1P_Z\"] = ensemble_pred\n",
    "\n",
    "# (Opcional) si quer√©s ver distribuci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ensemble_pred, bins=100)\n",
    "plt.title(\"Distribuci√≥n de predicciones (log1p z-score)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
