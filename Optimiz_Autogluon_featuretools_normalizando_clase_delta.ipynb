{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Rutas de entrada y salida\n",
    "input_path = './data/l_vm_completa_normalizada_fe.parquet'\n",
    "output_train = './data/df_train.parquet'\n",
    "output_val = './data/df_val.parquet'\n",
    "\n",
    "# Periodos para división\n",
    "periodo_train_max = 201908\n",
    "periodos_val = [201909, 201910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Leer datos completos (solo una vez) y filtrar por los periodos necesarios\n",
    "print(\"Leyendo y filtrando datos...\")\n",
    "df = pd.read_parquet(input_path, engine='fastparquet')\n",
    "\n",
    "# Filtrar en dos partes directamente sin copias innecesarias\n",
    "df_train = df[df['PERIODO'] <= periodo_train_max]\n",
    "df_val = df[df['PERIODO'].isin(periodos_val)]\n",
    "\n",
    "# Liberar el DataFrame original\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "# Guardar a disco\n",
    "print(\"Guardando conjuntos en disco...\")\n",
    "df_train.to_parquet(output_train, index=False)\n",
    "df_val.to_parquet(output_val, index=False)\n",
    "\n",
    "# Liberar memoria final\n",
    "del df_train, df_val\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Proceso completado.\")\n",
    "print(f\" - df_train → {output_train}\")\n",
    "print(f\" - df_val   → {output_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4332906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(output_train, engine='fastparquet')\n",
    "df_val = pd.read_parquet(output_val, engine='fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d7896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna CLASE_ZCORE de df_train y df_val\n",
    "df_train.drop(columns=['CLASE_ZSCORE'], inplace=True)\n",
    "df_val.drop(columns=['CLASE_ZSCORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2cec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas que contienen 'CLASE' en df_train:\n",
      "['CLASE_DELTA_ZSCORE']\n",
      "Columnas que contienen 'CLASE' en df_val:\n",
      "['CLASE_DELTA_ZSCORE']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las columnas del DataFrame de entrenamiento que contengan CLASE\n",
    "print(\"Columnas que contienen 'CLASE' en df_train:\")\n",
    "clase_columns = [col for col in df_train.columns if 'CLASE' in col]\n",
    "print(clase_columns)\n",
    "print(\"Columnas que contienen 'CLASE' en df_val:\")\n",
    "clase_columns = [col for col in df_val.columns if 'CLASE' in col]\n",
    "print(clase_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f6e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.23\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #28~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri May 23 10:31:01 UTC 2\n",
      "CPU Count:          28\n",
      "Memory Avail:       107.71 GB / 125.58 GB (85.8%)\n",
      "Disk Space Avail:   218.72 GB / 543.17 GB (40.3%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 7200s\n",
      "AutoGluon will save models to \"/home/pablo/Documentos/labo3-2025v/AutogluonModels/model_fast_20250630_0123\"\n",
      "Train Data Rows:    6730977\n",
      "Train Data Columns: 423\n",
      "Tuning Data Rows:    525116\n",
      "Tuning Data Columns: 423\n",
      "Label Column:       CLASE_DELTA_ZSCORE\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    98421.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11231.08 MB (11.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 11.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 2): ['MESES_SIN_COMPRAR_PRODUCT_CUSTOMER_ID_x_TN_LAG_01_ZSCORE', 'TN_MEDIAN_ZSCORE_02']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 2 | ['MESES_SIN_COMPRAR_PRODUCT_CUSTOMER_ID_x_TN_LAG_01_ZSCORE', 'TN_MEDIAN_ZSCORE_02']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  :   2 | ['PLAN_PRECIOS_CUIDADOS', 'MES_PROBLEMATICO']\n",
      "\t\t('float', []) : 381 | ['MES_SIN', 'MES_COS', 'CUST_REQUEST_QTY_SQRT', 'CUST_REQUEST_QTY_LOG1P', 'ORDINAL_SQRT', ...]\n",
      "\t\t('int', [])   :  38 | ['PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 381 | ['MES_SIN', 'MES_COS', 'CUST_REQUEST_QTY_SQRT', 'CUST_REQUEST_QTY_LOG1P', 'ORDINAL_SQRT', ...]\n",
      "\t\t('int', [])       :  38 | ['PERIODO', 'ANIO', 'MES', 'TRIMESTRE', 'ID_CAT1', ...]\n",
      "\t\t('int', ['bool']) :   2 | ['PLAN_PRECIOS_CUIDADOS', 'MES_PROBLEMATICO']\n",
      "\t91.1s = Fit runtime\n",
      "\t421 features in original data used to generate 421 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11175.72 MB (11.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 97.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'ag_args': {'name_suffix': 'Linear Tree'}, 'linear_tree': True, 'early_stopping_rounds': 10}, {'ag_args': {'name_suffix': 'Extra Trees'}, 'extra_trees': True, 'early_stopping_rounds': 10}, {'ag_args': {'name_suffix': 'QuickDefault'}, 'num_leaves': 31, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'early_stopping_rounds': 10}],\n",
      "}\n",
      "Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLinear Tree_BAG_L1 ... Training model for up to 7102.63s of the 7102.63s of remaining time.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# === Configuración general ===\n",
    "label_column = 'CLASE_DELTA_ZSCORE'\n",
    "output_path = f\"AutogluonModels/model_fast_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "# === Entrenamiento ===\n",
    "predictor = TabularPredictor(\n",
    "    label=label_column,\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    path=output_path\n",
    ").fit(\n",
    "    train_data=df_train,\n",
    "    tuning_data=df_val,\n",
    "    use_bag_holdout=True,\n",
    "    presets='medium_quality',               # Entrenamiento rápido pero razonable\n",
    "    time_limit=7200,\n",
    "    num_bag_folds=3,                        # Reduce cantidad de folds\n",
    "    num_bag_sets=1,                         # Una sola pasada\n",
    "    auto_stack=False,                       # Apagar stacking para acelerar\n",
    "    ag_args_ensemble={'fold_fitting_strategy': 'parallel_local'},\n",
    "    hyperparameters={\n",
    "        'GBM': [\n",
    "             {\n",
    "                'ag_args': {'name_suffix': 'Linear Tree'},\n",
    "                'linear_tree': True,               \n",
    "                'early_stopping_rounds': 10,\n",
    "            },\n",
    "            {\n",
    "                'ag_args': {'name_suffix': 'Extra Trees'},\n",
    "                'extra_trees': True,               \n",
    "                'early_stopping_rounds': 10,\n",
    "            },\n",
    "            {\n",
    "                'ag_args': {'name_suffix': 'QuickDefault'},\n",
    "                'num_leaves': 31,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,                \n",
    "                'early_stopping_rounds': 10,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    verbosity=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit_extra(\n",
    "    time_limit=3600,\n",
    "    ag_args_ensemble={'fold_fitting_strategy': 'sequential_local', 'num_bag_folds': 1},\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': [{\n",
    "            'num_epochs': 8,\n",
    "            'learning_rate': 0.01,\n",
    "            'dropout_prob': 0.1,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 256,\n",
    "            'hidden_size': 128,\n",
    "            'ag_args': {'name_suffix': 'NN_LightFast'},\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }]\n",
    "    },\n",
    "    fit_weighted_ensemble=True,\n",
    "    verbosity=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit_extra(\n",
    "    time_limit=1800,  \n",
    "    ag_args_ensemble={'fold_fitting_strategy': 'parallel_local'},\n",
    "    fit_weighted_ensemble=True,\n",
    "    hyperparameters={\n",
    "        'CAT': [{\n",
    "            'iterations': 500,\n",
    "            'depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'early_stopping_rounds': 20,\n",
    "            'ag_args': {'name_suffix': 'CAT_Custom'}\n",
    "}]\n",
    "    },\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6187325",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit_extra(\n",
    "    time_limit=1800,  \n",
    "    ag_args_ensemble={'fold_fitting_strategy': 'parallel_local'},\n",
    "    fit_weighted_ensemble=True,\n",
    "    hyperparameters={\n",
    "        'XGB': [{\n",
    "            'n_estimators': 150,\n",
    "            'early_stopping_rounds': 10,\n",
    "            'learning_rate': 0.05,\n",
    "            'booster': 'gbtree',\n",
    "            'ag_args': {'name_suffix': 'XGB_Quick'}\n",
    "        }]\n",
    "    },\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import datetime\n",
    "gc.collect()\n",
    "# === Configuración general ===\n",
    "label_column = 'CLASE_DELTA_ZSCORE'\n",
    "output_path = f\"AutogluonModels/model_gbm_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "# === Entrenamiento ===\n",
    "predictor = TabularPredictor(\n",
    "    label=label_column,\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    path=output_path\n",
    ").fit(\n",
    "    train_data=df_train,\n",
    "    tuning_data=df_val,\n",
    "    use_bag_holdout=True,\n",
    "    presets='medium_quality',\n",
    "    num_bag_folds=8,         # Mayor robustez\n",
    "    num_bag_sets=2,          # Mejor estimación out-of-fold\n",
    "    auto_stack=True,         # Activar stacking desde el inicio\n",
    "    time_limit=10800,\n",
    "    ag_args_ensemble={'fold_fitting_strategy': 'parallel_local'},\n",
    "    hyperparameters={\n",
    "        'GBM': [\n",
    "            {\n",
    "                'ag_args': {'name_suffix': 'XT'},\n",
    "                'extra_trees': True,\n",
    "                'time_limit': 600,\n",
    "                'early_stopping_rounds': 20,\n",
    "            },\n",
    "            {\n",
    "                'ag_args': {'name_suffix': 'LinearTree'},\n",
    "                'linear_tree': True,\n",
    "                'time_limit': 600,\n",
    "                'early_stopping_rounds': 20,\n",
    "            },\n",
    "            {\n",
    "                'ag_args': {'name_suffix': 'Default'},\n",
    "                'num_leaves': 31,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'time_limit': 600,\n",
    "                'early_stopping_rounds': 20,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2503094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Cargar modelo ya entrenado ===\n",
    "# #predictor = TabularPredictor.load(\"AutogluonModels/model_gbm\")\n",
    "\n",
    "# predictor.fit_extra(\n",
    "#     time_limit=10800,  # Tiempo total disponible para todos los modelos nuevos\n",
    "#     ag_args_ensemble={'fold_fitting_strategy': 'parallel_local'},\n",
    "#     fit_weighted_ensemble=True,  # Activar Weighted Ensemble\n",
    "#     hyperparameters={\n",
    "#         'XGB': [{\n",
    "#             'n_estimators': 1000,\n",
    "#             'early_stopping_rounds': 25,\n",
    "#             'learning_rate': 0.03,\n",
    "#             'booster': 'gbtree',\n",
    "#             'ag_args': {'name_suffix': 'XGB_Custom'}\n",
    "#         }],\n",
    "#         'CAT': [{\n",
    "#             'ag_args_fit': {'time_limit': 1200},\n",
    "#             'ag_args': {'name_suffix': 'CAT_Custom'}\n",
    "#         }],\n",
    "#         'NN_TORCH': [{\n",
    "#             'num_epochs': 50,\n",
    "#             'learning_rate': 0.003,\n",
    "#             'layers': [1024, 512, 256],\n",
    "#             'dropout_prob': 0.3,\n",
    "#             'weight_decay': 1e-5,\n",
    "#             'batch_size': 2048,\n",
    "#             'ag_args': {'name_suffix': 'DeepCustom'},\n",
    "#             'ag_args_fit': {'num_gpus': 1}\n",
    "#         }]\n",
    "#     },\n",
    "#     verbosity=2\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e022d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(\"AutogluonModels/model_fast_20250629_2217\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08426fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar MAE y MedAE en el leaderboard\n",
    "lb = predictor.leaderboard(data = df_val, extra_metrics=['mean_absolute_error', 'median_absolute_error', 'r2'], silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e187548",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.feature_importance(data=df_val, model='CatBoostCAT_Custom_BAG_L1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = predictor._trainer.load_model(best_model)\n",
    "weights = getattr(ensemble_model, 'weights', None)\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50559ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar feature importance sobre el conjunto de validación\n",
    "importancia = predictor.feature_importance(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d197fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce344269",
   "metadata": {},
   "source": [
    "✅ Paso 1: Calcular errores de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predicciones y error absoluto\n",
    "df_val['y_true'] = df_val['CLASE_DELTA_ZSCORE']\n",
    "df_val['y_pred'] = predictor.predict(df_val)\n",
    "df_val['error_abs'] = abs(df_val['y_true'] - df_val['y_pred'])\n",
    "df_val['error_signed'] = df_val['y_pred'] - df_val['y_true']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47114e7",
   "metadata": {},
   "source": [
    "📊 Paso 2: Histogramas de error absoluto y error signado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df_val['error_abs'], bins=50, kde=True)\n",
    "plt.title('Distribución del Error Absoluto')\n",
    "plt.xlabel('|y_pred - y_true|')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df_val['error_signed'], bins=50, kde=True)\n",
    "plt.title('Distribución del Error Signado')\n",
    "plt.xlabel('y_pred - y_true')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18881d9e",
   "metadata": {},
   "source": [
    "📈 Paso 3: Error vs. Valor real (dispersión)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df_val['y_true'], y=df_val['error_signed'], alpha=0.3)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Error Signado vs. Valor Real')\n",
    "plt.xlabel('Valor real')\n",
    "plt.ylabel('Error (pred - real)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c603b",
   "metadata": {},
   "source": [
    "🧩 Paso 4: Promedio de error por grupo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_errores_producto = df_val.groupby('PRODUCT_ID')['error_abs'].mean().sort_values(ascending=False).head(20)\n",
    "top_errores_producto.plot(kind='bar', figsize=(10,4), title='Top 20 PRODUCT_ID con mayor error promedio')\n",
    "plt.ylabel('Error Absoluto Medio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_errores_producto = df_val.groupby('CUSTOMER_ID')['error_abs'].mean().sort_values(ascending=False).head(20)\n",
    "top_errores_producto.plot(kind='bar', figsize=(10,4), title='Top 20 CUSTOMER_ID con mayor error promedio')\n",
    "plt.ylabel('Error Absoluto Medio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar entrenamiento + validación\n",
    "df_full = pd.concat([df_train, df_val], axis=0)\n",
    "del df_train, df_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31acb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenar el mejor modelo con TODOS los datos disponibles\n",
    "predictor_full = predictor.refit_full(train_data=df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los modelos disponibles (el mejor ahora tiene el sufijo '_FULL')\n",
    "print(\"Modelos disponibles luego del refit completo:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "# Eliminar modelos intermedios para liberar espacio\n",
    "predictor.delete_models(models_to_keep='best', dry_run=False)\n",
    "\n",
    "# Confirmar que solo queda el modelo reentrenado\n",
    "print(\"\\nModelos restantes después de eliminar los intermedios:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "\n",
    "# (Opcional) Guardar el predictor final si querés usarlo luego sin volver a cargar todo\n",
    "predictor.save('./data/modelo_final_autogluon')\n",
    "\n",
    "# ---  Liberar memoria ---\n",
    "del df_full\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "df_pred_full = pd.read_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet')\n",
    "# Dejo solo los datos del periodo 201910 y que A_PREDECIR sea True\n",
    "# Filtrar solo los datos del periodo 201910 y donde A_PREDECIR sea True\n",
    "df_pred_full = df_pred_full[\n",
    "    (df_pred_full['PERIODO'] == 201910) & (df_pred_full['A_PREDECIR'] == True)\n",
    "].drop(columns=['CLASE_ZSCORE', 'CLASE_DELTA_ZSCORE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar las predicciones usando el predictor original\n",
    "predictions = predictor.predict(df_pred_full)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['CLASE_DELTA_ZSCORE'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir la lista de columas del DataFrame con las predicciones\n",
    "print(\"Columnas del DataFrame con las predicciones:\")\n",
    "print(df_pred_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dernormalizar la columna CLASE_DELTA_ZSCORE\n",
    "df_pred_full['CLASE_DELTA'] = df_pred_full['CLASE_DELTA_ZSCORE'] * df_pred_full['CLASE_DELTA_STD'] + df_pred_full['CLASE_DELTA_MEAN']\n",
    "df_pred_full['TN'] = df_pred_full['TN_ZSCORE'] * df_pred_full['TN_STD'] + df_pred_full['TN_MEAN']\n",
    "# Agregar la columna TN_PREDICT que sea la suma de TN y CLASE_DELTA y si es menor que cero, poner cero\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN'] + df_pred_full['CLASE_DELTA']\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN_PREDICT'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d822ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Dataframe que contenga por cada PRODUCT_ID la suma de TN_PREDICT\n",
    "df_final = df_pred_full.groupby('PRODUCT_ID').agg({'TN_PREDICT': 'sum'}).reset_index()\n",
    "df_final = df_final.rename(columns={'PRODUCT_ID': 'product_id', 'TN_PREDICT': 'tn'})\n",
    "# Guardar el DataFrame df_final en un archivo CSV\n",
    "df_final.to_csv('./modelos/autoglun_normalizando_clase_delta.csv', index=False)\n",
    "df_final.shape\n",
    "\n",
    "# Para instalar AutoGluon con soporte para `autogluon.core.space` en conda, ejecuta:\n",
    "# \n",
    "# conda install -c conda-forge autogluon\n",
    "# \n",
    "# O si prefieres usar pip dentro de tu entorno conda:\n",
    "# \n",
    "# pip install autogluon\n",
    "# \n",
    "# Luego podrás usar:\n",
    "# from autogluon.core import space as ag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
