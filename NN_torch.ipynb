{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Rutas de entrada y salida\n",
    "input_path = './data/l_vm_completa_normalizada_fe.parquet'\n",
    "output_train = './data/df_train.parquet'\n",
    "output_val = './data/df_val.parquet'\n",
    "\n",
    "# Periodos para divisi√≥n\n",
    "periodo_train_max = 201908\n",
    "periodos_val = [201909, 201910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4257dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_limpio = './data/df_train_limpio.parquet'\n",
    "output_val_limpio = './data/df_val_limpio.parquet'\n",
    "\n",
    "df_train_limpio = pd.read_parquet(output_train_limpio, engine='fastparquet')\n",
    "df_val_limpio = pd.read_parquet(output_val_limpio, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data for TabularNeuralNetTorchModel has: 6730977 examples, 380 features (380 vector, 0 embedding)\n",
      "Training on GPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=380, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training tabular neural network for up to 40 epochs...\n",
      "Epoch 1 (Update 3286).\tTrain loss: 0.3348, Val mean_absolute_error: -0.2515, Best Epoch: 1\n",
      "Epoch 2 (Update 6572).\tTrain loss: 0.3095, Val mean_absolute_error: -0.2561, Best Epoch: 1\n",
      "Epoch 3 (Update 9858).\tTrain loss: 0.3022, Val mean_absolute_error: -0.2468, Best Epoch: 3\n",
      "Epoch 4 (Update 13144).\tTrain loss: 0.2976, Val mean_absolute_error: -0.2477, Best Epoch: 3\n",
      "Epoch 5 (Update 16430).\tTrain loss: 0.2948, Val mean_absolute_error: -0.2563, Best Epoch: 3\n",
      "Epoch 6 (Update 19716).\tTrain loss: 0.293, Val mean_absolute_error: -0.2444, Best Epoch: 6\n",
      "Epoch 7 (Update 23002).\tTrain loss: 0.291, Val mean_absolute_error: -0.2481, Best Epoch: 6\n",
      "Epoch 8 (Update 26288).\tTrain loss: 0.2896, Val mean_absolute_error: -0.2481, Best Epoch: 6\n",
      "Epoch 9 (Update 29574).\tTrain loss: 0.2883, Val mean_absolute_error: -0.2468, Best Epoch: 6\n",
      "Epoch 10 (Update 32860).\tTrain loss: 0.2882, Val mean_absolute_error: -0.244, Best Epoch: 10\n",
      "Epoch 11 (Update 36146).\tTrain loss: 0.2872, Val mean_absolute_error: -0.2458, Best Epoch: 10\n",
      "Epoch 12 (Update 39432).\tTrain loss: 0.2868, Val mean_absolute_error: -0.2525, Best Epoch: 10\n",
      "Epoch 13 (Update 42718).\tTrain loss: 0.2863, Val mean_absolute_error: -0.2557, Best Epoch: 10\n",
      "Epoch 14 (Update 46004).\tTrain loss: 0.286, Val mean_absolute_error: -0.2539, Best Epoch: 10\n",
      "Epoch 15 (Update 49290).\tTrain loss: 0.2849, Val mean_absolute_error: -0.2517, Best Epoch: 10\n",
      "Epoch 16 (Update 52576).\tTrain loss: 0.2849, Val mean_absolute_error: -0.2506, Best Epoch: 10\n",
      "Epoch 17 (Update 55862).\tTrain loss: 0.2848, Val mean_absolute_error: -0.2503, Best Epoch: 10\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='CLASE_DELTA_ZSCORE',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    verbosity=4,\n",
    "    path='AutogluonModels/nn_gpu_full_train'\n",
    ").fit(\n",
    "    train_data=df_train_limpio,         # tus 7 millones\n",
    "    tuning_data=df_val_limpio,          # tus 0.5 millones separados temporalmente\n",
    "    time_limit=7200,                    # 2 horas (ajustable seg√∫n complejidad)\n",
    "    use_bag_holdout=False,              # obligatorio si us√°s tuning_data\n",
    "    presets='medium',                   # no activa stacking ni mezcla datos\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': [{\n",
    "            'num_epochs': 40,\n",
    "            'learning_rate': 0.005,\n",
    "            'dropout_prob': 0.1,\n",
    "            'batch_size': 2048,         # mayor batch para mejor uso de GPU\n",
    "            'hidden_size': 256,         # red m√°s potente\n",
    "            'ag_args': {'name_suffix': 'GPU_Full'},\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea892c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='CLASE_DELTA_ZSCORE',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    verbosity=4,\n",
    "    path='AutogluonModels/nn_lightfast_test_15min'\n",
    ").fit(\n",
    "    train_data=df_entrenamiento_total,\n",
    "    time_limit=900,  # 15 minutos = 900 segundos\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {\n",
    "            'num_epochs': 5,              # reducir epochs acelera bastante\n",
    "            'learning_rate': 0.01,\n",
    "            'dropout_prob': 0.1,\n",
    "            'batch_size': 1024,           # m√°s batch size = mejor para GPU\n",
    "            'hidden_size': 64,            # red m√°s chica = m√°s r√°pida\n",
    "            'ag_args': {'name_suffix': 'GPU_15min'},\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }\n",
    "    },\n",
    "    presets='medium_quality',\n",
    "    use_bag_holdout=False  # sin bagging ni tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9368a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label='CLASE_DELTA_ZSCORE',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    verbosity=4,\n",
    "    path='AutogluonModels/nn_lightfast_test'\n",
    ").fit(\n",
    "    train_data=df_entrenamiento_total,\n",
    "    time_limit=1800,  # 30 minutos\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {\n",
    "            'num_epochs': 10,\n",
    "            'learning_rate': 0.01,\n",
    "            'dropout_prob': 0.1,\n",
    "            'batch_size': 512,\n",
    "            'hidden_size': 128,\n",
    "            'ag_args': {'name_suffix': 'GPU_Basic'},\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }\n",
    "    },\n",
    "    presets='medium_quality',\n",
    "    use_bag_holdout=False  # sin bagging, directo\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" target_col = 'CLASE_DELTA_ZSCORE'  # ajust√° si tu columna objetivo es otra\n",
    "\n",
    "hyperparameters = {\n",
    "    'NN_TORCH': [\n",
    "        {'ag_args': {'name_suffix': 'LightFast'}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "predictor_nn_lightfast = TabularPredictor(\n",
    "    label='CLASE_DELTA_ZSCORE',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    verbosity=3,\n",
    "    path='AutogluonModels/nn_lightfast_retrain'\n",
    ").fit(\n",
    "    train_data=df_train_limpio,\n",
    "    tuning_data=df_val_limpio,\n",
    "    time_limit=7200,\n",
    "    # hyperparameters={\n",
    "    #     'NN_TORCH': [{\n",
    "    #         'num_epochs': 8,\n",
    "    #         'learning_rate': 0.01,\n",
    "    #         'dropout_prob': 0.1,\n",
    "    #         'weight_decay': 1e-5,\n",
    "    #         'batch_size': 256,\n",
    "    #         'hidden_size': 128,\n",
    "    #         'ag_args': {'name_suffix': 'NN_LightFast'},\n",
    "    #         'ag_args_fit': {'num_gpus': 1}\n",
    "    #     }]\n",
    "    # },\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {}\n",
    "    },\n",
    "    hyperparameter_tune_kwargs='auto',\n",
    "    presets='best_quality',\n",
    "    use_bag_holdout=False\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" target_col = 'CLASE_DELTA_ZSCORE'  # Ajust√° si es necesario\n",
    "\n",
    "df_entrenamiento_total = pd.concat([df_train_limpio, df_val_limpio], axis=0)\n",
    "del df_train_limpio, df_val_limpio\n",
    "gc.collect()\n",
    "\n",
    "predictor_nn_lightfast = TabularPredictor(\n",
    "    label=target_col,\n",
    "    problem_type='regression',\n",
    "    eval_metric='mean_absolute_error',\n",
    "    verbosity=3,\n",
    "    path='AutogluonModels/nn_lightfast_retrain'\n",
    ").fit(\n",
    "    train_data=df_entrenamiento_total,\n",
    "    #train_data=df_train_limpio,\n",
    "    #tuning_data=df_val_limpio,\n",
    "    time_limit=7200,\n",
    "    presets='best_quality',\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {\n",
    "            'ag_args': {'name_suffix': 'NN_LightFast'},\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }\n",
    "    },\n",
    "    hyperparameter_tune_kwargs='auto',\n",
    "    use_bag_holdout=True\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50069cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3. Evaluaci√≥n del modelo ===\n",
    "\n",
    "lb = predictor_nn_lightfast.leaderboard(df_val_limpio, extra_metrics=['mean_absolute_error', 'median_absolute_error', 'r2'], silent=False)\n",
    "\n",
    "# === 4. Importancia de caracter√≠sticas ===\n",
    "\n",
    "feature_importance = predictor_nn_lightfast.feature_importance(df_val_limpio)\n",
    "\n",
    "# === 5. Guardado del modelo ya est√° hecho con `path=...` ===\n",
    "\n",
    "print(\"‚úÖ Reentrenamiento completado y modelo guardado en 'AutogluonModels/nn_lightfast_retrain'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce344269",
   "metadata": {},
   "source": [
    "‚úÖ Paso 1: Calcular errores de predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predicciones y error absoluto\n",
    "df_val['y_true'] = df_val['CLASE_DELTA_ZSCORE']\n",
    "df_val['y_pred'] = predictor.predict(df_val)\n",
    "df_val['error_abs'] = abs(df_val['y_true'] - df_val['y_pred'])\n",
    "df_val['error_signed'] = df_val['y_pred'] - df_val['y_true']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47114e7",
   "metadata": {},
   "source": [
    "üìä Paso 2: Histogramas de error absoluto y error signado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df_val['error_abs'], bins=50, kde=True)\n",
    "plt.title('Distribuci√≥n del Error Absoluto')\n",
    "plt.xlabel('|y_pred - y_true|')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df_val['error_signed'], bins=50, kde=True)\n",
    "plt.title('Distribuci√≥n del Error Signado')\n",
    "plt.xlabel('y_pred - y_true')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18881d9e",
   "metadata": {},
   "source": [
    "üìà Paso 3: Error vs. Valor real (dispersi√≥n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df_val['y_true'], y=df_val['error_signed'], alpha=0.3)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Error Signado vs. Valor Real')\n",
    "plt.xlabel('Valor real')\n",
    "plt.ylabel('Error (pred - real)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c603b",
   "metadata": {},
   "source": [
    "üß© Paso 4: Promedio de error por grupo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_errores_producto = df_val.groupby('PRODUCT_ID')['error_abs'].mean().sort_values(ascending=False).head(20)\n",
    "top_errores_producto.plot(kind='bar', figsize=(10,4), title='Top 20 PRODUCT_ID con mayor error promedio')\n",
    "plt.ylabel('Error Absoluto Medio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_errores_producto = df_val.groupby('CUSTOMER_ID')['error_abs'].mean().sort_values(ascending=False).head(20)\n",
    "top_errores_producto.plot(kind='bar', figsize=(10,4), title='Top 20 CUSTOMER_ID con mayor error promedio')\n",
    "plt.ylabel('Error Absoluto Medio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_train_limpio, df_val_limpio], ignore_index=True)\n",
    "del df_train_limpio, df_val_limpio\n",
    "gc.collect()\n",
    "predictor_full = predictor_nn_lightfast.refit_full(train_data=df_full)\n",
    "predictor_full.save(\"AutogluonModels/nn_lightfast_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Combinar entrenamiento + validaci√≥n\n",
    "df_full = pd.concat([df_train, df_val], axis=0)\n",
    "del df_train, df_val\n",
    "gc.collect() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31acb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reentrenar el mejor modelo con TODOS los datos disponibles\n",
    "# predictor_full = predictor.refit_full(train_data=df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los modelos disponibles (el mejor ahora tiene el sufijo '_FULL')\n",
    "print(\"Modelos disponibles luego del refit completo:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "# Eliminar modelos intermedios para liberar espacio\n",
    "predictor.delete_models(models_to_keep='best', dry_run=False)\n",
    "\n",
    "# Confirmar que solo queda el modelo reentrenado\n",
    "print(\"\\nModelos restantes despu√©s de eliminar los intermedios:\")\n",
    "print(predictor.leaderboard(silent=True)['model'].tolist())\n",
    "\n",
    "# (Opcional) Guardar el predictor final si quer√©s usarlo luego sin volver a cargar todo\n",
    "predictor.save('./data/modelo_final_autogluon')\n",
    "\n",
    "# ---  Liberar memoria ---\n",
    "del df_full\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "df_pred_full = pd.read_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet')\n",
    "# Dejo solo los datos del periodo 201910 y que A_PREDECIR sea True\n",
    "# Filtrar solo los datos del periodo 201910 y donde A_PREDECIR sea True\n",
    "df_pred_full = df_pred_full[\n",
    "    (df_pred_full['PERIODO'] == 201910) & (df_pred_full['A_PREDECIR'] == True)\n",
    "].drop(columns=['CLASE_ZSCORE', 'CLASE_DELTA_ZSCORE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar las predicciones usando el predictor original\n",
    "predictions = predictor.predict(df_pred_full)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['CLASE_DELTA_ZSCORE'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir la lista de columas del DataFrame con las predicciones\n",
    "print(\"Columnas del DataFrame con las predicciones:\")\n",
    "print(df_pred_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dernormalizar la columna CLASE_DELTA_ZSCORE\n",
    "df_pred_full['CLASE_DELTA'] = df_pred_full['CLASE_DELTA_ZSCORE'] * df_pred_full['CLASE_DELTA_STD'] + df_pred_full['CLASE_DELTA_MEAN']\n",
    "df_pred_full['TN'] = df_pred_full['TN_ZSCORE'] * df_pred_full['TN_STD'] + df_pred_full['TN_MEAN']\n",
    "# Agregar la columna TN_PREDICT que sea la suma de TN y CLASE_DELTA y si es menor que cero, poner cero\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN'] + df_pred_full['CLASE_DELTA']\n",
    "df_pred_full['TN_PREDICT'] = df_pred_full['TN_PREDICT'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d822ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Dataframe que contenga por cada PRODUCT_ID la suma de TN_PREDICT\n",
    "df_final = df_pred_full.groupby('PRODUCT_ID').agg({'TN_PREDICT': 'sum'}).reset_index()\n",
    "df_final = df_final.rename(columns={'PRODUCT_ID': 'product_id', 'TN_PREDICT': 'tn'})\n",
    "# Guardar el DataFrame df_final en un archivo CSV\n",
    "df_final.to_csv('./modelos/autoglun_normalizando_clase_delta.csv', index=False)\n",
    "df_final.shape\n",
    "\n",
    "# Para instalar AutoGluon con soporte para `autogluon.core.space` en conda, ejecuta:\n",
    "# \n",
    "# conda install -c conda-forge autogluon\n",
    "# \n",
    "# O si prefieres usar pip dentro de tu entorno conda:\n",
    "# \n",
    "# pip install autogluon\n",
    "# \n",
    "# Luego podr√°s usar:\n",
    "# from autogluon.core import space as ag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
