{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "import sqlite3\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from more_itertools import chunked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1dd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_full = pd.read_parquet('./data/l_vm_completa_train.parquet', engine='fastparquet')# Abrir el archivo parquet y cargarlo en un DataFrame data/l_vm_completa_train_pendientes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba02f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservar las siguientes columnas\n",
    "columns_to_keep = ['PERIODO', 'ANIO', 'MES', 'MES_SIN', 'MES_COS', 'TRIMESTRE', 'ID_CAT1',\n",
    "       'ID_CAT2', 'ID_CAT3', 'ID_BRAND', 'SKU_SIZE', 'CUSTOMER_ID',\n",
    "       'PRODUCT_ID', 'PLAN_PRECIOS_CUIDADOS', 'CUST_REQUEST_QTY',\n",
    "       'CUST_REQUEST_TN', 'TN', 'STOCK_FINAL', 'TN_LAG_01', 'TN_LAG_02',\n",
    "       'TN_LAG_03', 'TN_LAG_04', 'TN_LAG_05', 'TN_LAG_06', 'TN_LAG_07',\n",
    "       'TN_LAG_08', 'TN_LAG_09', 'TN_LAG_10', 'TN_LAG_11', 'TN_LAG_12',\n",
    "       'TN_LAG_13', 'TN_LAG_14', 'TN_LAG_15', 'CLASE', 'CLASE_DELTA',\n",
    "       'ORDINAL', 'TN_DELTA_01', 'TN_DELTA_02', 'TN_DELTA_03', 'TN_DELTA_04',\n",
    "       'TN_DELTA_05', 'TN_DELTA_06', 'TN_DELTA_07', 'TN_DELTA_08',\n",
    "       'TN_DELTA_09', 'TN_DELTA_10', 'TN_DELTA_11', 'TN_DELTA_12',\n",
    "       'TN_DELTA_13', 'TN_DELTA_14', 'TN_DELTA_15', 'ANTIG_CLIENTE',\n",
    "       'ANTIG_PRODUCTO', 'CANT_PROD_CLI_PER', 'A_PREDECIR']\n",
    "# Filtrar el DataFrame para conservar solo las columnas deseadas y el periodo hasta 201910\n",
    "df_full = df_full[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un DataFrame de Polars\n",
    "df_full = pl.from_pandas(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209b3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamiento y cálculo de media y desvío SOLO para TN\n",
    "group_stats = (\n",
    "    df_full.group_by([\"CUSTOMER_ID\", \"PRODUCT_ID\"])\n",
    "    .agg([\n",
    "        pl.col(\"TN\").mean().alias(\"TN_MEAN\"),\n",
    "        pl.col(\"TN\").std().alias(\"TN_STD\")\n",
    "    ])\n",
    ")\n",
    "# Agrupamiento y cálculo de media y desvío SOLO para CLASE_DELTA\n",
    "group_stats_clase = (\n",
    "    df_full.group_by([\"CUSTOMER_ID\", \"PRODUCT_ID\"])\n",
    "    .agg([\n",
    "        pl.col(\"CLASE_DELTA\").mean().alias(\"CLASE_DELTA_MEAN\"),\n",
    "        pl.col(\"CLASE_DELTA\").std().alias(\"CLASE_DELTA_STD\")\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cab0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lo mismo para CLASE_DELTA usando group_stats_clase y CLASE_DELTA_MEAN y CLASE_DELTA_STD\n",
    "df_norm = (df_full\n",
    "    .join(group_stats_clase, on=[\"CUSTOMER_ID\", \"PRODUCT_ID\"], how=\"left\")\n",
    "    .with_columns([\n",
    "        # CLASE_DELTA Z-Scores usando CLASE_DELTA_MEAN y CLASE_DELTA_STD\n",
    "        pl.when(pl.col(\"CLASE_DELTA_STD\") > 0)\n",
    "        .then((pl.col(\"CLASE_DELTA\") - pl.col(\"CLASE_DELTA_MEAN\")) / pl.col(\"CLASE_DELTA_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CLASE_DELTA_ZSCORE\"),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acce7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join con el DataFrame original y cálculo de TODOS los Z-Scores usando TN_MEAN y TN_STD\n",
    "df_norm = (df_norm\n",
    "    .join(group_stats, on=[\"CUSTOMER_ID\", \"PRODUCT_ID\"], how=\"left\")\n",
    "    .with_columns([\n",
    "        # TN_ZSCORE\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_ZSCORE\"),\n",
    "        \n",
    "        # CUST_REQUEST_TN_ZSCORE usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"CUST_REQUEST_TN\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CUST_REQUEST_TN_ZSCORE\"),\n",
    "        \n",
    "        # TN_LAG Z-Scores (1-15) usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_01\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_01_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_02\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_02_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_03\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_03_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_04\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_04_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_05\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_05_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_06\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_06_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_07\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_07_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_08\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_08_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_09\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_09_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_10\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_10_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_11\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_11_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_12\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_12_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_13\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_13_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_14\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_14_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_LAG_15\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_LAG_15_ZSCORE\"),\n",
    "        \n",
    "        # CLASE y CLASE_DELTA Z-Scores usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"CLASE\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"CLASE_ZSCORE\"),\n",
    "\n",
    "        # TN_DELTA Z-Scores (1-15) usando TN_MEAN y TN_STD\n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_01\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_01_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_02\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_02_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_03\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_03_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_04\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_04_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_05\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_05_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_06\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_06_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_07\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_07_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_08\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_08_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_09\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_09_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_10\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_10_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_11\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_11_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_12\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_12_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_13\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_13_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_14\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_14_ZSCORE\"),\n",
    "        \n",
    "        pl.when(pl.col(\"TN_STD\") > 0)\n",
    "        .then((pl.col(\"TN_DELTA_15\") - pl.col(\"TN_MEAN\")) / pl.col(\"TN_STD\"))\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"TN_DELTA_15_ZSCORE\"),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de todas las columnas Z-Score para aplicar las correcciones\n",
    "zscore_columns = [\n",
    "    \"TN_ZSCORE\", \"CUST_REQUEST_TN_ZSCORE\",\n",
    "    \"TN_LAG_01_ZSCORE\", \"TN_LAG_02_ZSCORE\", \"TN_LAG_03_ZSCORE\", \"TN_LAG_04_ZSCORE\", \"TN_LAG_05_ZSCORE\",\n",
    "    \"TN_LAG_06_ZSCORE\", \"TN_LAG_07_ZSCORE\", \"TN_LAG_08_ZSCORE\", \"TN_LAG_09_ZSCORE\", \"TN_LAG_10_ZSCORE\",\n",
    "    \"TN_LAG_11_ZSCORE\", \"TN_LAG_12_ZSCORE\", \"TN_LAG_13_ZSCORE\", \"TN_LAG_14_ZSCORE\", \"TN_LAG_15_ZSCORE\",\n",
    "    \"CLASE_ZSCORE\", \"CLASE_DELTA_ZSCORE\",\n",
    "    \"TN_DELTA_01_ZSCORE\", \"TN_DELTA_02_ZSCORE\", \"TN_DELTA_03_ZSCORE\", \"TN_DELTA_04_ZSCORE\", \"TN_DELTA_05_ZSCORE\",\n",
    "    \"TN_DELTA_06_ZSCORE\", \"TN_DELTA_07_ZSCORE\", \"TN_DELTA_08_ZSCORE\", \"TN_DELTA_09_ZSCORE\", \"TN_DELTA_10_ZSCORE\",\n",
    "    \"TN_DELTA_11_ZSCORE\", \"TN_DELTA_12_ZSCORE\", \"TN_DELTA_13_ZSCORE\", \"TN_DELTA_14_ZSCORE\", \"TN_DELTA_15_ZSCORE\",  \n",
    "]\n",
    "\n",
    "# Aplicar correcciones para null, NaN e infinito a todas las columnas Z-Score\n",
    "for col in zscore_columns:\n",
    "    df_norm = df_norm.with_columns([\n",
    "        pl.when(pl.col(col).is_null() | pl.col(col).is_nan() | pl.col(col).is_infinite())\n",
    "        .then(0)\n",
    "        .otherwise(pl.col(col))\n",
    "        .alias(col)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas originales para las que se calcularon los Z-Scores\n",
    "df_norm = df_norm.drop([\"TN\", \"CUST_REQUEST_TN\",     \n",
    "    \"TN_LAG_01\", \"TN_LAG_02\", \"TN_LAG_03\", \"TN_LAG_04\", \"TN_LAG_05\",\n",
    "    \"TN_LAG_06\", \"TN_LAG_07\", \"TN_LAG_08\", \"TN_LAG_09\", \"TN_LAG_10\",\n",
    "    \"TN_LAG_11\", \"TN_LAG_12\", \"TN_LAG_13\", \"TN_LAG_14\", \"TN_LAG_15\",\n",
    "    \"CLASE\", \"CLASE_DELTA\",\n",
    "    \"TN_DELTA_01\", \"TN_DELTA_02\", \"TN_DELTA_03\", \"TN_DELTA_04\", \"TN_DELTA_05\",\n",
    "    \"TN_DELTA_06\", \"TN_DELTA_07\", \"TN_DELTA_08\", \"TN_DELTA_09\", \"TN_DELTA_10\",\n",
    "    \"TN_DELTA_11\", \"TN_DELTA_12\", \"TN_DELTA_13\", \"TN_DELTA_14\", \"TN_DELTA_15\"\n",
    "])\n",
    "\n",
    "# Convertir de nuevo a DataFrame de Pandas\n",
    "df_norm = df_norm.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41d4894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_full, group_stats, group_stats_clase\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a27aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=28)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done   5 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=28)]: Done  16 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=28)]: Done  29 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=28)]: Done  42 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=28)]: Done  57 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=28)]: Done  72 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=28)]: Done  89 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=28)]: Done 106 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=28)]: Done 125 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=28)]: Done 144 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=28)]: Done 165 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=28)]: Done 186 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=28)]: Done 209 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=28)]: Done 232 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=28)]: Done 257 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=28)]: Done 282 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=28)]: Done 309 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=28)]: Done 336 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=28)]: Done 365 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=28)]: Done 394 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=28)]: Done 425 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=28)]: Done 456 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=28)]: Done 489 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=28)]: Done 522 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=28)]: Done 557 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=28)]: Done 592 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=28)]: Done 629 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=28)]: Done 666 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=28)]: Done 705 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=28)]: Done 744 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=28)]: Done 785 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=28)]: Done 826 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=28)]: Done 869 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=28)]: Done 912 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=28)]: Done 957 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=28)]: Done 1002 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=28)]: Done 1049 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=28)]: Done 1096 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=28)]: Done 1145 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=28)]: Done 1194 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=28)]: Done 1245 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=28)]: Done 1296 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=28)]: Done 1349 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=28)]: Done 1402 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=28)]: Done 1457 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=28)]: Done 1512 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=28)]: Done 1569 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=28)]: Done 1626 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=28)]: Done 1685 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=28)]: Done 1744 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=28)]: Done 1805 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=28)]: Done 1866 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=28)]: Done 1929 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=28)]: Done 1992 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=28)]: Done 2057 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=28)]: Done 2122 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=28)]: Done 2189 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=28)]: Done 2256 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=28)]: Done 2325 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=28)]: Done 2394 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=28)]: Done 2465 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=28)]: Done 2536 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=28)]: Done 2609 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=28)]: Done 2682 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=28)]: Done 2757 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=28)]: Done 2832 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=28)]: Done 2909 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=28)]: Done 2986 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=28)]: Done 3065 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=28)]: Done 3144 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=28)]: Done 3225 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=28)]: Done 3306 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=28)]: Done 3389 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=28)]: Done 3496 out of 3496 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total: 399.14 segundos\n"
     ]
    }
   ],
   "source": [
    "# --- Cálculo de features por grupo ---\n",
    "def calcular_pendientes_grupo(group, periodos_list):\n",
    "    group = group.sort_values(by='PERIODO').copy()\n",
    "    n = len(group)\n",
    "    y_series = pd.Series(group['TN_ZSCORE'].values)\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for cant in periodos_list:\n",
    "        x = np.arange(cant)\n",
    "        rolling = y_series.rolling(window=cant)\n",
    "\n",
    "        # Medidas estadísticas\n",
    "        mean_vals = rolling.mean().values\n",
    "        std_vals = rolling.std().values\n",
    "        median_vals = rolling.median().values\n",
    "        min_vals = rolling.min().values\n",
    "        max_vals = rolling.max().values\n",
    "        ewma_vals = y_series.ewm(span=cant, adjust=False).mean().values\n",
    "\n",
    "        new_cols[f'TN_MEAN_ZSCORE_{cant}'] = mean_vals\n",
    "        new_cols[f'TN_STD_ZSCORE_{cant}'] = std_vals\n",
    "        new_cols[f'TN_MEDIAN_ZSCORE_{str(cant).zfill(2)}'] = median_vals\n",
    "        new_cols[f'TN_MIN_ZSCORE_{str(cant).zfill(2)}'] = min_vals\n",
    "        new_cols[f'TN_MAX_ZSCORE_{str(cant).zfill(2)}'] = max_vals\n",
    "        new_cols[f'TN_EWMA_ZSCORE_{str(cant).zfill(2)}'] = ewma_vals\n",
    "\n",
    "        # Pendiente de regresión lineal\n",
    "        if n >= cant:\n",
    "            y_rolling = np.lib.stride_tricks.sliding_window_view(y_series.values, window_shape=cant)\n",
    "            X = np.vstack([x, np.ones(cant)]).T\n",
    "            XTX_inv_XT = np.linalg.pinv(X)\n",
    "            betas = XTX_inv_XT @ y_rolling.T\n",
    "            pendientes = np.full(n, np.nan)\n",
    "            pendientes[cant - 1:] = betas[0]\n",
    "        else:\n",
    "            pendientes = np.full(n, np.nan)\n",
    "        new_cols[f'PENDIENTE_TENDENCIA_ZSCORE_{cant}'] = pendientes\n",
    "\n",
    "        # Medidas de variabilidad respecto a la media\n",
    "        abs_diff = np.abs(y_series.values - mean_vals)\n",
    "        residuals = y_series.values - mean_vals\n",
    "        res_std = pd.Series(residuals).rolling(window=cant).std().values\n",
    "        cv_vals = std_vals / np.where(mean_vals == 0, np.nan, mean_vals)\n",
    "\n",
    "        new_cols[f'TN_ABS_DIFF_MEAN_ZSCORE_{cant}'] = abs_diff\n",
    "        new_cols[f'TN_RESIDUAL_STD_ZSCORE_{cant}'] = res_std\n",
    "        new_cols[f'TN_CV_ZSCORE_{cant}'] = cv_vals\n",
    "\n",
    "    df_features = pd.DataFrame(new_cols, index=group.index)\n",
    "    group = pd.concat([group, df_features], axis=1)\n",
    "    return group\n",
    "\n",
    "# --- Procesar un chunk de grupos ---\n",
    "def procesar_chunk(chunk, periodos_list):\n",
    "    return pd.concat([calcular_pendientes_grupo(g, periodos_list) for g in chunk], ignore_index=True)\n",
    "\n",
    "# --- Paralelización eficiente ---\n",
    "def calcular_pendientes_parallel_optimizado(df, periodos_list, n_jobs=28, chunk_size=100):\n",
    "    df = df.copy()  # conserva todas las columnas originales\n",
    "    grupos = [group for _, group in df.groupby(['PRODUCT_ID', 'CUSTOMER_ID'])]\n",
    "    chunks = list(chunked(grupos, chunk_size))\n",
    "\n",
    "    resultados = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
    "        delayed(procesar_chunk)(chunk, periodos_list) for chunk in chunks\n",
    "    )\n",
    "\n",
    "    df_final = pd.concat(resultados, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "# --- Script principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    df_resultado = calcular_pendientes_parallel_optimizado(\n",
    "        df_norm,\n",
    "        periodos_list=[2, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 34],\n",
    "        n_jobs=28,\n",
    "        chunk_size=200\n",
    "    )\n",
    "\n",
    "    print(f\"Tiempo total: {time.time() - start:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "145acd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_norm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2761d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar a df_resultado una variable categorica MES_PROBLEMATICO que sea 1 si PERIODO es 201906 o 201908 o 201910, y 0 en caso contrario\n",
    "df_resultado['MES_PROBLEMATICO'] = df_resultado['PERIODO'].apply(lambda x: True if x in [201906, 201908] else False)\n",
    "df_resultado['PLAN_PRECIOS_CUIDADOS'] = df_resultado['PLAN_PRECIOS_CUIDADOS'].map({1 : True, 0: False})\n",
    "df_resultado['A_PREDECIR'] = df_resultado['A_PREDECIR'].map({'S': True, 'N': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizar tipos de datos numéricos\n",
    "for col in df_resultado.select_dtypes(include=['int64']).columns:\n",
    "    df_resultado[col] = pd.to_numeric(df_resultado[col], downcast='integer')\n",
    "for col in df_resultado.select_dtypes(include=['float64']).columns:\n",
    "    df_resultado[col] = pd.to_numeric(df_resultado[col], downcast='float')\n",
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed5652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame resultante en un archivo parquet\n",
    "df_resultado.to_parquet('./data/l_vm_completa_normalizada_fe.parquet', engine='fastparquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaboIII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
