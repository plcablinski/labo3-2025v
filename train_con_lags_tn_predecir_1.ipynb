{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fb8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcablinski.RWD\\AppData\\Local\\Temp\\ipykernel_238248\\2129643656.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10143267, 17)\n",
      "   PERIODO  CUSTOMER_ID  PRODUCT_ID         TN  TN_MAS_DOS  TN_LAG_01  \\\n",
      "0   201701        10001       20001   99.43861    92.46537        NaN   \n",
      "1   201702        10001       20001  198.84365    13.29728   99.43861   \n",
      "2   201703        10001       20001   92.46537   101.00563  198.84365   \n",
      "3   201704        10001       20001   13.29728   128.04792   92.46537   \n",
      "4   201705        10001       20001  101.00563   101.20711   13.29728   \n",
      "\n",
      "   TN_LAG_02  TN_LAG_03  TN_LAG_04  TN_LAG_05  TN_LAG_06  TN_LAG_07  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2   99.43861        NaN        NaN        NaN        NaN        NaN   \n",
      "3  198.84365   99.43861        NaN        NaN        NaN        NaN   \n",
      "4   92.46537  198.84365   99.43861        NaN        NaN        NaN   \n",
      "\n",
      "   TN_LAG_08  TN_LAG_09  TN_LAG_10  TN_LAG_11  TN_LAG_12  \n",
      "0        NaN        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN        NaN  \n",
      "PERIODO          int64\n",
      "CUSTOMER_ID      int64\n",
      "PRODUCT_ID       int64\n",
      "TN             float64\n",
      "TN_MAS_DOS     float64\n",
      "TN_LAG_01      float64\n",
      "TN_LAG_02      float64\n",
      "TN_LAG_03      float64\n",
      "TN_LAG_04      float64\n",
      "TN_LAG_05      float64\n",
      "TN_LAG_06      float64\n",
      "TN_LAG_07      float64\n",
      "TN_LAG_08      float64\n",
      "TN_LAG_09      float64\n",
      "TN_LAG_10      float64\n",
      "TN_LAG_11      float64\n",
      "TN_LAG_12      float64\n",
      "dtype: object\n",
      "Número de filas: 10143267, Número de columnas: 17\n"
     ]
    }
   ],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"select * from PC.L_VW_TRAIN_CON_LAGS\" \n",
    "df = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_full = pd.concat(df, ignore_index=True)\n",
    "conn.close()\n",
    "print(df_full.shape)\n",
    "# Imprimir las primeras filas del DataFrame completo\n",
    "print(df_full.head())\n",
    "# Imprimir los tipos de datos de las columnas del DataFrame completo\n",
    "print(df_full.dtypes)\n",
    "# Imprimir el número de filas y columnas del DataFrame completo\n",
    "print(f\"Número de filas: {df_full.shape[0]}, Número de columnas: {df_full.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf8d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de regresión entrenado con todo el dataset.\n"
     ]
    }
   ],
   "source": [
    "# Usando este código como base para un modelo de regresión con LightGBM\n",
    "# agregar hojas de LightGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = df_full[['PERIODO', 'CUSTOMER_ID', 'PRODUCT_ID', 'TN', 'TN_LAG_01', 'TN_LAG_02', 'TN_LAG_03', 'TN_LAG_04', 'TN_LAG_05', 'TN_LAG_06', \n",
    "             'TN_LAG_07', 'TN_LAG_08', 'TN_LAG_09', 'TN_LAG_10', 'TN_LAG_11', 'TN_LAG_12']]\n",
    "y = df_full['TN_MAS_DOS']\n",
    "\n",
    "# Crear el dataset de LightGBM\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "# Definir parámetros para regresión\n",
    "params = { \n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1 }\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "print(\"Modelo de regresión entrenado con todo el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6453469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcablinski.RWD\\AppData\\Local\\Temp\\ipykernel_238248\\1133623266.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n"
     ]
    }
   ],
   "source": [
    "# Cargo los datos sobre los que quiero hacer predicciones\n",
    "\n",
    "conn =  cx_Oracle.connect(user=\"pc\",password=\"p201404\",dsn=\"siatchdesa\")\n",
    "query = \"SELECT * FROM l_vw_PRED_CON_LAGS\" \n",
    "df_pred = pd.read_sql(query, conn, chunksize=1000000)  # Lee en chunks para no llenar la RAM\n",
    "\n",
    "# Para concatenar todos los chunks en un solo DataFrame (si tienes suficiente RAM)\n",
    "df_pred_full = pd.concat(df_pred, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89f9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERIODO  PRODUCT_ID  CUSTOMER_ID         TN  TN_LAG_01  TN_LAG_02  \\\n",
      "0   201912       20001        10001  180.21938  236.65556  176.02980   \n",
      "1   201912       20002        10001  334.03714  547.87849  430.90803   \n",
      "2   201912       20003        10001  137.98717  135.69192  196.18531   \n",
      "3   201912       20004        10001   12.94020   27.58851   37.88891   \n",
      "4   201912       20005        10001    7.66693   11.01719    7.98907   \n",
      "\n",
      "   TN_LAG_03  TN_LAG_04  TN_LAG_05  TN_LAG_06  TN_LAG_07  TN_LAG_08  \\\n",
      "0  109.05244   33.63991  144.78714   65.92436  439.90647  364.37071   \n",
      "1  213.36148  148.91108  103.12062  151.12081  264.55349  155.81927   \n",
      "2  101.61982  121.06458  105.81480   78.79703   74.71874   86.54509   \n",
      "3   20.57492    8.33349   16.04585   34.26047   27.99741   17.84712   \n",
      "4    5.66966    2.51269    5.41195    3.20851    4.25654    1.72238   \n",
      "\n",
      "   TN_LAG_09  TN_LAG_10  TN_LAG_11  TN_LAG_12  PREDICCIONES  \n",
      "0  130.54927  309.90610  386.60688  254.62373    207.263859  \n",
      "1  220.19153  270.99295  242.95842  287.14182    207.263859  \n",
      "2  125.49948  113.28408   41.70348   37.34640    207.263859  \n",
      "3   25.94769   24.01701   33.12691   13.97542     26.240151  \n",
      "4    5.66966    4.12339    3.02812    1.99727      5.889478  \n",
      "Número de filas: 333840, Número de columnas: 17 con predicciones.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x19e01a37c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con el modelo entrenado, hacemos predicciones \n",
    "X_pred = df_pred_full[['PERIODO', 'CUSTOMER_ID', 'PRODUCT_ID', 'TN', 'TN_LAG_01', 'TN_LAG_02', 'TN_LAG_03', 'TN_LAG_04', 'TN_LAG_05', 'TN_LAG_06', \n",
    "             'TN_LAG_07', 'TN_LAG_08', 'TN_LAG_09', 'TN_LAG_10', 'TN_LAG_11', 'TN_LAG_12']]\n",
    "predictions = model.predict(X_pred)\n",
    "# Agregar las predicciones al DataFrame original\n",
    "df_pred_full['PREDICCIONES'] = predictions\n",
    "# Imprimir las primeras filas del DataFrame con las predicciones\n",
    "print(df_pred_full.head())\n",
    "# Guardar el DataFrame con las predicciones en un archivo CSV\n",
    "df_pred_full.to_csv('predicciones.csv', index=False)\n",
    "# Imprimir el número de filas y columnas del DataFrame con las predicciones\n",
    "print(f\"Número de filas: {df_pred_full.shape[0]}, Número de columnas: {df_pred_full.shape[1]} con predicciones.\")\n",
    "# Guardar el modelo entrenado\n",
    "model.save_model('modelo_regresion.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f8352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando actualización de la tabla L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 0 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 10000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 20000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 30000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 40000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 50000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 60000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 70000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 80000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 90000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 100000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 110000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 120000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 130000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 140000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 150000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 160000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 170000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 180000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 190000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 200000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 210000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 220000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 230000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 240000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 250000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 260000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 270000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 280000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 290000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 300000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 310000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 320000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualizadas 330000 filas de L_DATOS_PREDICCION con las nuevas predicciones.\n",
      "Actualización de la tabla L_DATOS_PREDICCION completada con las nuevas predicciones.\n"
     ]
    }
   ],
   "source": [
    "# Con el DataFrame de predicción, actualizamos la base de datos\n",
    "# el criterio es actualizar la tabla L_DATOS_PREDICCION con las nuevas predicciones\n",
    "# la columnna PREDICCIONES se debe actualizar con los nuevos valores\n",
    "# la clave primaria es (PERIODO, CUSTOMER_ID, PRODUCT_ID)\n",
    "# Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "\n",
    "# Conectar a la base de datos para actualizar los datos de predicción\n",
    "conn = cx_Oracle.connect(user=\"pc\", password=\"p201404\", dsn=\"siatchdesa\")\n",
    "# Crear un cursor para ejecutar las actualizaciones\n",
    "cursor = conn.cursor()\n",
    "# Hacer Update L_DATOS_PREDICCION set TN_PREDICCION = NULL\n",
    "update_query = \"\"\"\n",
    "    UPDATE L_DATOS_PREDICCION\n",
    "    SET TN_PREDICCION = NULL\n",
    "\"\"\"\n",
    "cursor.execute(update_query)\n",
    "# Hacer commit para aplicar el cambio de NULL\n",
    "conn.commit()\n",
    "# Imprimir mensaje de inicio de actualización\n",
    "print(\"Iniciando actualización de la tabla L_DATOS_PREDICCION con las nuevas predicciones.\")\n",
    "\n",
    "# Iterar sobre las filas del DataFrame con las predicciones\n",
    "for index, row in df_pred_full.iterrows():\n",
    "    periodo = row['PERIODO']\n",
    "    customer_id = row['CUSTOMER_ID']\n",
    "    product_id = row['PRODUCT_ID']\n",
    "    prediccion = row['PREDICCIONES']\n",
    "    \n",
    "    # Actualizar la tabla L_DATOS_PREDICCION con la nueva predicción\n",
    "    update_query = \"\"\"\n",
    "        UPDATE L_DATOS_PREDICCION\n",
    "        SET TN_PREDICCION = :prediccion\n",
    "        WHERE PERIODO = :periodo AND CUSTOMER_ID = :customer_id AND PRODUCT_ID = :product_id\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, {'prediccion': prediccion, 'periodo': periodo, 'customer_id': customer_id, 'product_id': product_id})  \n",
    "    # Hacer commit cada 10000 filas para evitar problemas de memoria\n",
    "    if index % 10000 == 0:\n",
    "        conn.commit()\n",
    "        print(f\"Actualizadas {index} filas de L_DATOS_PREDICCION con las nuevas predicciones.\")\n",
    "# Confirmar los cambios en la base de datos\n",
    "conn.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "# Imprimir mensaje de finalización\n",
    "print(\"Actualización de la tabla L_DATOS_PREDICCION completada con las nuevas predicciones.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Series_temporales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
